{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Functions we have so far: \n",
    "- Exclusive bad (Katie - delete the words that do not make sense and finish up  )\n",
    "- Exclusive good (Katie - delete the words that do not make sense and finish up  )\n",
    "- Exclamation mark (Debbie)\n",
    "- Question mark (Debbie)\n",
    "- Capital letters (Debbie)\n",
    "- too (negative) (Vera)\n",
    "- far (positive) (Vera)\n",
    "- n\\'t (Hong)\n",
    "- positive word (Katie)\n",
    "- negative word (Katie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas==0.24.2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-0.24.2              |   py36he6710b0_0         8.5 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.5 MB\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  pandas                               1.0.1-py36h0573a6f_0 --> 0.24.2-py36he6710b0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pandas-0.24.2        | 8.5 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pandas==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py4j in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (0.10.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install py4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    bottleneck-1.3.2           |   py36heb32a55_0         124 KB\n",
      "    dask-2.11.0                |             py_0          13 KB\n",
      "    dask-core-2.11.0           |             py_0         565 KB\n",
      "    distributed-2.11.0         |           py36_0         943 KB\n",
      "    gunicorn-20.0.4            |           py36_0         125 KB\n",
      "    hypothesis-5.5.4           |             py_0         227 KB\n",
      "    nb_conda_kernels-2.2.2     |           py36_0          39 KB\n",
      "    ncurses-6.2                |       he6710b0_0         1.1 MB\n",
      "    plotly-4.5.2               |             py_0         1.6 MB\n",
      "    pytest-astropy-0.8.0       |             py_0           9 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.7 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  bottleneck                           1.3.1-py36hdd07704_0 --> 1.3.2-py36heb32a55_0\n",
      "  dask                                          2.10.1-py_0 --> 2.11.0-py_0\n",
      "  dask-core                                     2.10.1-py_0 --> 2.11.0-py_0\n",
      "  distributed        pkgs/main/noarch::distributed-2.10.0-~ --> pkgs/main/linux-64::distributed-2.11.0-py36_0\n",
      "  gunicorn                                    19.9.0-py36_0 --> 20.0.4-py36_0\n",
      "  hypothesis                                     5.4.1-py_0 --> 5.5.4-py_0\n",
      "  nb_conda_kernels                             2.1.1-py36_1 --> 2.2.2-py36_0\n",
      "  ncurses                                    6.1-he6710b0_1 --> 6.2-he6710b0_0\n",
      "  pandas                              0.24.2-py36he6710b0_0 --> 1.0.1-py36h0573a6f_0\n",
      "  plotly                                         4.4.1-py_0 --> 4.5.2-py_0\n",
      "  pytest-astropy                                 0.7.0-py_0 --> 0.8.0-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "hypothesis-5.5.4     | 227 KB    | ##################################### | 100% \n",
      "gunicorn-20.0.4      | 125 KB    | ##################################### | 100% \n",
      "plotly-4.5.2         | 1.6 MB    | ##################################### | 100% \n",
      "dask-core-2.11.0     | 565 KB    | ##################################### | 100% \n",
      "dask-2.11.0          | 13 KB     | ##################################### | 100% \n",
      "pytest-astropy-0.8.0 | 9 KB      | ##################################### | 100% \n",
      "distributed-2.11.0   | 943 KB    | ##################################### | 100% \n",
      "bottleneck-1.3.2     | 124 KB    | ##################################### | 100% \n",
      "ncurses-6.2          | 1.1 MB    | ##################################### | 100% \n",
      "nb_conda_kernels-2.2 | 39 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: / b'+ /opt/anaconda/envs/Python3/bin/python -m nb_conda_kernels.install --disable --prefix=/opt/anaconda/envs/Python3\\nDisabling nb_conda_kernels...\\nDisabled nb_conda_kernels\\n'\n",
      "/ b'Enabling nb_conda_kernels...\\nStatus: enabled\\n'\n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda upgrade --all -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - java-jdk\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.11.28         |           py36_0         153 KB\n",
      "    java-jdk-8.45.14           |                0       153.6 MB  cyclus\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       153.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  java-jdk           cyclus/linux-64::java-jdk-8.45.14-0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2019.11.~ --> pkgs/main::ca-certificates-2020.1.1-0\n",
      "  openssl            conda-forge::openssl-1.1.1d-h516909a_0 --> pkgs/main::openssl-1.1.1d-h7b6447c_4\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                       conda-forge --> pkgs/main\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "java-jdk-8.45.14     | 153.6 MB  | ##################################### | 100% \n",
      "certifi-2019.11.28   | 153 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c cyclus java-jdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - snorkel==0.9.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
      "    certifi-2019.11.28         |           py36_0         149 KB  conda-forge\n",
      "    cudatoolkit-10.0.130       |                0       261.2 MB\n",
      "    cudnn-7.6.5                |       cuda10.0_0       165.0 MB\n",
      "    libprotobuf-3.11.3         |       h8b12597_0         4.8 MB  conda-forge\n",
      "    ninja-1.10.0               |       hc9558a2_0         1.9 MB  conda-forge\n",
      "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
      "    pandas-0.24.2              |   py36hb3f55d8_1        11.1 MB  conda-forge\n",
      "    protobuf-3.11.3            |   py36he1b5a44_0         696 KB  conda-forge\n",
      "    pytorch-1.1.0              |cuda100py36he554f03_0       196.2 MB\n",
      "    scikit-learn-0.21.3        |   py36hd81dba3_0         5.0 MB\n",
      "    snorkel-0.9.0              |             py_0          85 KB  conda-forge\n",
      "    tensorboardx-1.9           |             py_0          75 KB  conda-forge\n",
      "    tqdm-4.43.0                |             py_0          47 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       648.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0\n",
      "  cudnn              pkgs/main/linux-64::cudnn-7.6.5-cuda10.0_0\n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.11.3-h8b12597_0\n",
      "  ninja              conda-forge/linux-64::ninja-1.10.0-hc9558a2_0\n",
      "  protobuf           conda-forge/linux-64::protobuf-3.11.3-py36he1b5a44_0\n",
      "  pytorch            pkgs/main/linux-64::pytorch-1.1.0-cuda100py36he554f03_0\n",
      "  snorkel            conda-forge/noarch::snorkel-0.9.0-py_0\n",
      "  tensorboardx       conda-forge/noarch::tensorboardx-1.9-py_0\n",
      "  tqdm               conda-forge/noarch::tqdm-4.43.0-py_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
      "  certifi                                         pkgs/main --> conda-forge\n",
      "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
      "  pandas             pkgs/main::pandas-1.0.1-py36h0573a6f_0 --> conda-forge::pandas-0.24.2-py36hb3f55d8_1\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  scikit-learn                        0.22.1-py36hd81dba3_0 --> 0.21.3-py36hd81dba3_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ninja-1.10.0         | 1.9 MB    | ##################################### | 100% \n",
      "protobuf-3.11.3      | 696 KB    | ##################################### | 100% \n",
      "scikit-learn-0.21.3  | 5.0 MB    | ##################################### | 100% \n",
      "pytorch-1.1.0        | 196.2 MB  | ##################################### | 100% \n",
      "certifi-2019.11.28   | 149 KB    | ##################################### | 100% \n",
      "cudnn-7.6.5          | 165.0 MB  | ##################################### | 100% \n",
      "libprotobuf-3.11.3   | 4.8 MB    | ##################################### | 100% \n",
      "ca-certificates-2019 | 145 KB    | ##################################### | 100% \n",
      "openssl-1.1.1d       | 2.1 MB    | ##################################### | 100% \n",
      "pandas-0.24.2        | 11.1 MB   | ##################################### | 100% \n",
      "snorkel-0.9.0        | 85 KB     | ##################################### | 100% \n",
      "cudatoolkit-10.0.130 | 261.2 MB  | ##################################### | 100% \n",
      "tqdm-4.43.0          | 47 KB     | ##################################### | 100% \n",
      "tensorboardx-1.9     | 75 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install snorkel==0.9.0 -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - textblob\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    textblob-0.15.3            |             py_0         595 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         595 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  textblob           conda-forge/noarch::textblob-0.15.3-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "textblob-0.15.3      | 595 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4 MB)\n",
      "Collecting thinc<7.4.0,>=7.3.0\n",
      "  Using cached thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (2.22.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl (32 kB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Using cached catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting blis<0.5.0,>=0.4.0\n",
      "  Using cached blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7 MB)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119 kB)\n",
      "Collecting wasabi<1.1.0,>=0.4.0\n",
      "  Using cached wasabi-0.6.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (45.2.0.post20200210)\n",
      "Collecting srsly<1.1.0,>=0.1.0\n",
      "  Using cached srsly-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (185 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (19 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.43.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n",
      "Installing collected packages: wasabi, cymem, murmurhash, preshed, blis, srsly, plac, thinc, catalogue, spacy\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.2.3 srsly-1.0.2 thinc-7.3.1 wasabi-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 772 kB/s eta 0:00:01    |██████▎                         | 2.4 MB 772 kB/s eta 0:00:13\n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (45.2.0.post20200210)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.43.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.2.0)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.2.5-py3-none-any.whl size=12011738 sha256=280cdd03234ea9954acafed5e9477e8e8e72efdb08520245cb81610289ffea21\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6_fqc0lk/wheels/b5/94/56/596daa677d7e91038cbddfcf32b591d0c915a1b3a3e3d3c79d\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/faculty/.cache/pip/wheels/14/27/cc/e83fe1e4beb26a2d2c776f3dfdf7a465c544f4edc7dbf67c3d/sagemaker_pyspark-1.2.8-py3-none-any.whl\n",
      "Processing /home/faculty/.cache/pip/wheels/0b/9f/11/1345c7d24df142160582b83b52f652542e8b708ebf73e13743/pyspark-2.3.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from sagemaker_pyspark) (1.18.1)\n",
      "Requirement already satisfied: py4j==0.10.7 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from pyspark==2.3.2->sagemaker_pyspark) (0.10.7)\n",
      "Installing collected packages: pyspark, sagemaker-pyspark\n",
      "  Attempting uninstall: pyspark\n",
      "    Found existing installation: pyspark 2.4.5\n",
      "    Uninstalling pyspark-2.4.5:\n",
      "      Successfully uninstalled pyspark-2.4.5\n",
      "Successfully installed pyspark-2.3.2 sagemaker-pyspark-1.2.8\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snorkel in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: scikit-learn<0.22.0,>=0.20.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (0.21.3)\n",
      "Requirement already satisfied: pandas<0.25.0,>=0.24.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (0.24.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.18.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.29.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (4.43.0)\n",
      "Requirement already satisfied: torch<1.2.0,>=1.1.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.1.0)\n",
      "Requirement already satisfied: networkx<3.0,>=2.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (2.4)\n",
      "Requirement already satisfied: tensorboardX<2.0,>=1.6 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from scikit-learn<0.22.0,>=0.20.2->snorkel) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from pandas<0.25.0,>=0.24.0->snorkel) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from pandas<0.25.0,>=0.24.0->snorkel) (2019.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from networkx<3.0,>=2.2->snorkel) (4.4.1)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from tensorboardX<2.0,>=1.6->snorkel) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from tensorboardX<2.0,>=1.6->snorkel) (3.11.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorboardX<2.0,>=1.6->snorkel) (45.2.0.post20200210)\n",
      "Requirement already satisfied: spacy in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (2.2.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (45.2.0.post20200210)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.43.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n",
      "Python 3.6.10 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!pip install snorkel\n",
    "!pip install spacy\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import set_data_path\n",
    "\n",
    "set_data_path('/path/to/spacy/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from sagemaker_pyspark import IAMRole, classpath_jars\n",
    "from sagemaker_pyspark.algorithms import KMeansSageMakerEstimator\n",
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from snorkel.labeling import LabelModel\n",
    "from snorkel.labeling.apply.spark import SparkLFApplier\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker_pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "classpath = \":\".join(sagemaker_pyspark.classpath_jars())\n",
    "spark = SparkSession.builder.config(\"spark.driver.extraClassPath\", classpath).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier,LabelModel\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from itertools import repeat\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/sh: 1: insall: not found\n"
     ]
    }
   ],
   "source": [
    "%pip install findspark\n",
    "\n",
    "import findspark\n",
    "!insall pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n",
      "<pyspark.sql.session.SparkSession object at 0x7f9887b53cc0>\n"
     ]
    }
   ],
   "source": [
    "#Spark \n",
    "\n",
    "# # Spark Environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "import pyspark\n",
    "\n",
    "number_cores = 4\n",
    "memory_gb = 16\n",
    "conf = (\n",
    "     pyspark.SparkConf()\n",
    "         .setMaster('local[{}]'.format(number_cores))\n",
    "         .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "print(sc)\n",
    "\n",
    "# # get the context\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "print(spark) \n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from snorkel.labeling.apply.spark import SparkLFApplier\n",
    "\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SQLContext \n",
    "import pandas as pd \n",
    "sqlc=SQLContext(sc) \n",
    "df=pd.read_csv('/project/development_split.csv') \n",
    "development_split=sqlc.createDataFrame(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse all from DVD releases page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = 'https://www.rottentomatoes.com/api/private/v2.0/browse?maxTomato=100&services=amazon%3Bhbo_go%3Bitunes%3Bnetflix_iw%3Bvudu%3Bamazon_prime%3Bfandango_now&certified&sortBy=release&type=dvd-streaming-all&page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get movie url\n",
    "movie_url = []\n",
    "start_page = 1 ; end_page = 1\n",
    "while start_page <= end_page:\n",
    "#     time.sleep(7)\n",
    "    url = main + str(start_page)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code !=200:\n",
    "        print('Request error')\n",
    "        break\n",
    "    file = json.loads(response.text)\n",
    "    for i in file['results']:\n",
    "        movie_url = movie_url + [i['url']]\n",
    "    start_page +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples for the url:\n",
      "\n",
      "/m/frozen_ii\n",
      "/m/playmobil_the_movie\n",
      "/m/queen_and_slim\n",
      "\n",
      "Number of movies in list: 32\n"
     ]
    }
   ],
   "source": [
    "print('Examples for the url:\\n')\n",
    "for i in range(3):\n",
    "    print(movie_url[i])\n",
    "print('\\nNumber of movies in list: {}'.format(len(movie_url)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into lists of 50 movies to do the scraping\n",
    "movie_url_split = [movie_url[i:i+50] for i in range(0,600,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_url_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reviews from the web\n",
    "reviews = []\n",
    "titles = []\n",
    "ratings = []\n",
    "for split in movie_url_split: # Loop through each split\n",
    "#     time.sleep(7)\n",
    "    for title in split: # Loop through each movie title\n",
    "        url = 'https://www.rottentomatoes.com'+title\n",
    "#         time.sleep(7)\n",
    "        response = requests.get(url)\n",
    "        # Check the request status code\n",
    "        if response.status_code != 200:\n",
    "            print('Request error')\n",
    "            break\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Get labels from each review (fresh vs. rotten)\n",
    "        fresh_rotten = soup.find_all(class_=\"review_quote\")\n",
    "        \n",
    "        # Get movie title\n",
    "        title = soup.find(class_=\"mop-ratings-wrap__title mop-ratings-wrap__title--top\").getText()\n",
    "        \n",
    "        # Get reviews\n",
    "        review = soup.find_all('blockquote')\n",
    "        for i in review:\n",
    "            j = str(i.contents[1])\n",
    "            j = j.replace(\"<p>\\n                    \\n                        \",\"\")\n",
    "            j = j.replace(\"\\n                    \\n                </p>\",\"\")\n",
    "            reviews = reviews + [j]\n",
    "            titles = titles + [title]\n",
    "        \n",
    "        # Identify labels\n",
    "        for i in fresh_rotten:\n",
    "            temp = str(i.findChildren()[2])\n",
    "            if re.search('rotten',temp):\n",
    "                ratings = ratings + ['rotten']\n",
    "            else:\n",
    "                ratings = ratings + ['fresh']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame to store the scraped data\n",
    "df = pd.DataFrame([titles,reviews,ratings],index = ['title','review','rating']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 333 entries, 0 to 333\n",
      "Data columns (total 3 columns):\n",
      "title     333 non-null object\n",
      "review    333 non-null object\n",
      "rating    333 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 10.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Clean the data (drop duplicates, check missing values etc.)\n",
    "df = df.drop_duplicates()\n",
    "df = df.replace([None],np.nan)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>A distressingly unnecessary (and fairly tediou...</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>Frozen II is the exact kind of sequel that mor...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>[A]n ultimately satisfying story of more matur...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                             review  rating\n",
       "0  Frozen II  A distressingly unnecessary (and fairly tediou...  rotten\n",
       "1  Frozen II  Frozen II is the exact kind of sequel that mor...   fresh\n",
       "2  Frozen II  [A]n ultimately satisfying story of more matur...   fresh"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV files\n",
    "# df.to_csv('web_scraping_rotten_tomatoes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Preparing TSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TSV file\n",
    "tsv_reviews = pd.read_csv('/project/reviews.tsv', sep='\\t', header=0, encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>fresh</th>\n",
       "      <th>critic</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A distinctly gallows take on contemporary fina...</td>\n",
       "      <td>3/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>PJ Nabarro</td>\n",
       "      <td>0</td>\n",
       "      <td>Patrick Nabarro</td>\n",
       "      <td>November 10, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>It's an allegory in search of a meaning that n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotten</td>\n",
       "      <td>Annalee Newitz</td>\n",
       "      <td>0</td>\n",
       "      <td>io9.com</td>\n",
       "      <td>May 23, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>... life lived in a bubble in financial dealin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Sean Axmaker</td>\n",
       "      <td>0</td>\n",
       "      <td>Stream on Demand</td>\n",
       "      <td>January 4, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Continuing along a line introduced in last yea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Daniel Kasman</td>\n",
       "      <td>0</td>\n",
       "      <td>MUBI</td>\n",
       "      <td>November 16, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>... a perverse twist on neorealism...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Cinema Scope</td>\n",
       "      <td>October 12, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review rating   fresh  \\\n",
       "0   3  A distinctly gallows take on contemporary fina...    3/5   fresh   \n",
       "1   3  It's an allegory in search of a meaning that n...    NaN  rotten   \n",
       "2   3  ... life lived in a bubble in financial dealin...    NaN   fresh   \n",
       "3   3  Continuing along a line introduced in last yea...    NaN   fresh   \n",
       "4   3             ... a perverse twist on neorealism...     NaN   fresh   \n",
       "\n",
       "           critic  top_critic         publisher               date  \n",
       "0      PJ Nabarro           0   Patrick Nabarro  November 10, 2018  \n",
       "1  Annalee Newitz           0           io9.com       May 23, 2018  \n",
       "2    Sean Axmaker           0  Stream on Demand    January 4, 2018  \n",
       "3   Daniel Kasman           0              MUBI  November 16, 2017  \n",
       "4             NaN           0      Cinema Scope   October 12, 2017  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract review and fresh columns\n",
    "tsv_reviews = pd.DataFrame(tsv_reviews, columns = ['review', 'fresh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>fresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A distinctly gallows take on contemporary fina...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's an allegory in search of a meaning that n...</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... life lived in a bubble in financial dealin...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Continuing along a line introduced in last yea...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>... a perverse twist on neorealism...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review   fresh\n",
       "0  A distinctly gallows take on contemporary fina...   fresh\n",
       "1  It's an allegory in search of a meaning that n...  rotten\n",
       "2  ... life lived in a bubble in financial dealin...   fresh\n",
       "3  Continuing along a line introduced in last yea...   fresh\n",
       "4             ... a perverse twist on neorealism...    fresh"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    5563\n",
       "fresh        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN rows in reviews\n",
    "index_name = tsv_reviews[(tsv_reviews['review'].isnull())].index\n",
    "tsv_reviews.drop(index_name, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    0\n",
       "fresh     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename fresh as 1 and rotten as 0\n",
    "tsv_reviews['fresh'].replace({'fresh':'1', 'rotten':'0'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 681 to 23827\n",
      "Data columns (total 2 columns):\n",
      "Review       5000 non-null object\n",
      "Freshness    5000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Rename columns\n",
    "tsv_reviews.rename(columns={'fresh':'Freshness','review':'Review'},inplace=True)\n",
    "tsv_reviews = tsv_reviews.sample(5000)\n",
    "#take 5000\n",
    "tsv_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Preparing CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Freshness                                             Review\n",
       "0          1   Manakamana doesn't answer any questions, yet ...\n",
       "1          1   Wilfully offensive and powered by a chest-thu...\n",
       "2          0   It would be difficult to imagine material mor...\n",
       "3          0   Despite the gusto its star brings to the role...\n",
       "4          0   If there was a good idea at the core of this ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file\n",
    "csv_reviews= pd.read_csv('/project/rotten_tomatoes_reviews.csv')\n",
    "csv_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72635</th>\n",
       "      <td>Tthe script is clunky, the acting strained. T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359595</th>\n",
       "      <td>Guts, charisma and inventiveness. That's what...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196550</th>\n",
       "      <td>As a showcasing of the evolution of such a re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120701</th>\n",
       "      <td>Many feel the film, based on Lipsky's intervi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64348</th>\n",
       "      <td>An orgy of anachronism in a sea of bad action...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "72635    Tthe script is clunky, the acting strained. T...          0\n",
       "359595   Guts, charisma and inventiveness. That's what...          1\n",
       "196550   As a showcasing of the evolution of such a re...          1\n",
       "120701   Many feel the film, based on Lipsky's intervi...          1\n",
       "64348    An orgy of anachronism in a sea of bad action...          0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 72635 to 325690\n",
      "Data columns (total 2 columns):\n",
      "Review       5000 non-null object\n",
      "Freshness    5000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Swap Freshness and Review \n",
    "columns_titles = [\"Review\",\"Freshness\"]\n",
    "csv_reviews=csv_reviews.reindex(columns=columns_titles)\n",
    "csv_reviews = csv_reviews.sample(5000)\n",
    "\n",
    "csv_reviews.head()\n",
    "csv_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping & Preparing scrapped data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>Babenco's cinematic farewell isn't perfect by ...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>This is a good film if you are looking for som...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>My Hindu Friend is a celebration of life, love...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>I wouldn't miss it; it's a film that's more th...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>...surreal, reflective (though never sentiment...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              title  \\\n",
       "0           0  My Hindu Friend (Meu amigo Hindu)   \n",
       "1           1  My Hindu Friend (Meu amigo Hindu)   \n",
       "2           2  My Hindu Friend (Meu amigo Hindu)   \n",
       "3           3  My Hindu Friend (Meu amigo Hindu)   \n",
       "4           4  My Hindu Friend (Meu amigo Hindu)   \n",
       "\n",
       "                                              review rating  \n",
       "0  Babenco's cinematic farewell isn't perfect by ...  fresh  \n",
       "1  This is a good film if you are looking for som...  fresh  \n",
       "2  My Hindu Friend is a celebration of life, love...  fresh  \n",
       "3  I wouldn't miss it; it's a film that's more th...  fresh  \n",
       "4  ...surreal, reflective (though never sentiment...  fresh  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Web Scraping Data\n",
    "web_scraping_reviews= pd.read_csv('/project/web_scraping_rotten_tomatoes.csv')\n",
    "web_scraping_reviews.head()\n",
    "\n",
    "web_scraping_reviews = web_scraping_reviews.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>2247</td>\n",
       "      <td>Crawl</td>\n",
       "      <td>A relentless thriller with all the right eleme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>2631</td>\n",
       "      <td>Between Two Ferns: The Movie</td>\n",
       "      <td>The most important thing you need to know abou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Close Enemies (Freres Ennemis)</td>\n",
       "      <td>The dramatic tension is grim and relentless as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>The Battle of Jangsari</td>\n",
       "      <td>Visceral and sentimental Korean War as fought ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>2374</td>\n",
       "      <td>Semper Fi</td>\n",
       "      <td>Contrived, undercooked and increasingly implau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                           title  \\\n",
       "2247        2247                           Crawl   \n",
       "2631        2631    Between Two Ferns: The Movie   \n",
       "45            45  Close Enemies (Freres Ennemis)   \n",
       "195          195          The Battle of Jangsari   \n",
       "2374        2374                       Semper Fi   \n",
       "\n",
       "                                                 Review Freshness  \n",
       "2247  A relentless thriller with all the right eleme...         1  \n",
       "2631  The most important thing you need to know abou...         1  \n",
       "45    The dramatic tension is grim and relentless as...         1  \n",
       "195   Visceral and sentimental Korean War as fought ...         1  \n",
       "2374  Contrived, undercooked and increasingly implau...         0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename fresh as 1 and rotten as 0\n",
    "web_scraping_reviews['rating'].replace({'fresh':'1', 'rotten':'0'}, inplace = True)\n",
    "\n",
    "#Rename Rating to Review \n",
    "web_scraping_reviews.rename(columns={'rating':'Freshness', 'review':'Review'},inplace=True)\n",
    "web_scraping_reviews.head()\n",
    "\n",
    "# Extract Review and Freshness columns\n",
    "web_scraping_reviews= pd.DataFrame(web_scraping_reviews, columns = ['Review', 'Freshness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>A relentless thriller with all the right eleme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>The most important thing you need to know abou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The dramatic tension is grim and relentless as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Visceral and sentimental Korean War as fought ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>Contrived, undercooked and increasingly implau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review Freshness\n",
       "2247  A relentless thriller with all the right eleme...         1\n",
       "2631  The most important thing you need to know abou...         1\n",
       "45    The dramatic tension is grim and relentless as...         1\n",
       "195   Visceral and sentimental Korean War as fought ...         1\n",
       "2374  Contrived, undercooked and increasingly implau...         0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_scraping_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all the data together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72635</th>\n",
       "      <td>Tthe script is clunky, the acting strained. T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359595</th>\n",
       "      <td>Guts, charisma and inventiveness. That's what...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196550</th>\n",
       "      <td>As a showcasing of the evolution of such a re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120701</th>\n",
       "      <td>Many feel the film, based on Lipsky's intervi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64348</th>\n",
       "      <td>An orgy of anachronism in a sea of bad action...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review Freshness\n",
       "72635    Tthe script is clunky, the acting strained. T...         0\n",
       "359595   Guts, charisma and inventiveness. That's what...         1\n",
       "196550   As a showcasing of the evolution of such a re...         1\n",
       "120701   Many feel the film, based on Lipsky's intervi...         1\n",
       "64348    An orgy of anachronism in a sea of bad action...         0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv_reviews.info()\n",
    "# tsv_reviews.info()\n",
    "# web_scraping_reviews.info()\n",
    "\n",
    "\n",
    "\n",
    "# Concat two files into all_reviews\n",
    "all_reviews=pd.concat([csv_reviews, tsv_reviews,web_scraping_reviews],axis=0, sort=False)\n",
    "all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into test and training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews['Freshness'] = all_reviews['Freshness'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(all_reviews,test_size=0.2,stratify = all_reviews['Freshness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 278735 to 436908\n",
      "Data columns (total 2 columns):\n",
      "Review       12000 non-null object\n",
      "Freshness    12000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 281.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000 entries, 3827 to 12525\n",
      "Data columns (total 2 columns):\n",
      "Review       3000 non-null object\n",
      "Freshness    3000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 70.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278735</th>\n",
       "      <td>...like the majority of flicks that prominent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>...\"Rocko's Modern Life: Static Cling\" offers ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16268</th>\n",
       "      <td>And then there's also much ado about an alleg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>An unsubtle, fast-moving film with plenty of j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>But once you've defined what a \"Men In Black a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "278735   ...like the majority of flicks that prominent...          0\n",
       "3405    ...\"Rocko's Modern Life: Static Cling\" offers ...          0\n",
       "16268    And then there's also much ado about an alleg...          0\n",
       "2729    An unsubtle, fast-moving film with plenty of j...          1\n",
       "3070    But once you've defined what a \"Men In Black a...          0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid off training labels \n",
    "train = train.drop('Freshness', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1770\n",
       "0    1230\n",
       "Name: Freshness, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Freshness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23248</th>\n",
       "      <td>One of those thrillers that pivots around the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>The characters, none of whom are the slightest...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>It is beautiful and painful in equal measures.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21063</th>\n",
       "      <td>Cage returns to resplendently weird form.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72132</th>\n",
       "      <td>A fast-moving swashbuckler with an Arabian Ni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Freshness\n",
       "23248  One of those thrillers that pivots around the ...          0\n",
       "4277   The characters, none of whom are the slightest...          1\n",
       "3583      It is beautiful and painful in equal measures.          1\n",
       "21063          Cage returns to resplendently weird form.          1\n",
       "72132   A fast-moving swashbuckler with an Arabian Ni...          1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From labelled test set, extract a sample to find out about which labelling functions could be written\n",
    "#Not sure how big the development split_ can be --> take sample of 1000 data points \n",
    "\n",
    "development_split = test.sample(2000,random_state=42)\n",
    "development_split.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#For finding labelling functions: \n",
    "development_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       2000\n",
       "Freshness    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_split.to_csv('development_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       2000\n",
       "Freshness    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23248</th>\n",
       "      <td>One of those thrillers that pivots around the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>The characters, none of whom are the slightest...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>It is beautiful and painful in equal measures.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21063</th>\n",
       "      <td>Cage returns to resplendently weird form.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72132</th>\n",
       "      <td>A fast-moving swashbuckler with an Arabian Ni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Freshness\n",
       "23248  One of those thrillers that pivots around the ...          0\n",
       "4277   The characters, none of whom are the slightest...          1\n",
       "3583      It is beautiful and painful in equal measures.          1\n",
       "21063          Cage returns to resplendently weird form.          1\n",
       "72132   A fast-moving swashbuckler with an Arabian Ni...          1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       820\n",
       "Freshness    820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Might have to get rid off index?\n",
    "\n",
    "development_split[development_split['Freshness'] !=1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1180\n",
       "0     820\n",
       "Name: Freshness, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split['Freshness'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_split = pd.read_csv('/project/development_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188209</td>\n",
       "      <td>A return to form with an incredibly likable c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212254</td>\n",
       "      <td>You don't have to be familiar with the Inspec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996</td>\n",
       "      <td>This five-star film takes an alternate route b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18338</td>\n",
       "      <td>A suspense film in which the violence is blunt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>223936</td>\n",
       "      <td>The Program is never less than interesting, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Review  Freshness\n",
       "0      188209   A return to form with an incredibly likable c...          1\n",
       "2      212254   You don't have to be familiar with the Inspec...          1\n",
       "3        1996  This five-star film takes an alternate route b...          1\n",
       "6       18338  A suspense film in which the violence is blunt...          1\n",
       "8      223936   The Program is never less than interesting, a...          1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43444</td>\n",
       "      <td>like a good-looking blind date who promises di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97135</td>\n",
       "      <td>When a movie features two spit takes in the f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10938</td>\n",
       "      <td>The Darkest Minds never communicates the overw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6091</td>\n",
       "      <td>Mostly, Generations spends its running length ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5574</td>\n",
       "      <td>But much like the Playmobil toys, with their p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Review  Freshness\n",
       "1       43444  like a good-looking blind date who promises di...          0\n",
       "4       97135   When a movie features two spit takes in the f...          0\n",
       "5       10938  The Darkest Minds never communicates the overw...          0\n",
       "7        6091  Mostly, Generations spends its running length ...          0\n",
       "9        5574  But much like the Playmobil toys, with their p...          0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split_fresh = development_split[development_split['Freshness'] == 1]\n",
    "development_split_rotten = development_split[development_split['Freshness'] == 0]\n",
    "development_split_fresh.head()\n",
    "development_split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1174 entries, 0 to 1998\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    1174 non-null int64\n",
      "Review        1174 non-null object\n",
      "Freshness     1174 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 36.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 826 entries, 1 to 1999\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    826 non-null int64\n",
      "Review        826 non-null object\n",
      "Freshness     826 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 25.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# fresh reviews \n",
    "development_split_fresh.info()\n",
    "# rotten reviews \n",
    "development_split_rotten.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation \n",
    "def remove_punctuation(dataframe):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in dataframe.Review.str.lower():\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a return to form with an incredibly likable cast\n",
       "1     you dont have to be familiar with the inspect...\n",
       "2    this fivestar film takes an alternate route by...\n",
       "3    a suspense film in which the violence is blunt...\n",
       "4     the program is never less than interesting an...\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from fresh reviews & turn into Series\n",
    "split_fresh= pd.Series(remove_punctuation(development_split_fresh))\n",
    "split_fresh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordList = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\\\n",
    "                \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\\\n",
    "                \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\",\\\n",
    "                \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\",\\\n",
    "                \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\",\\\n",
    "                \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\",\\\n",
    "                \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\",\\\n",
    "                \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\\\n",
    "                \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords from fresh\n",
    "\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_fresh.replace(replacements, regex=True, inplace=True)\n",
    "split_fresh.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization and Count again\n",
    "def stem_recount(df):\n",
    "    import pandas as pd\n",
    "    # Lemmatization\n",
    "    from nltk import LancasterStemmer\n",
    "    st = LancasterStemmer()\n",
    "    newdf = df.copy()\n",
    "    for i in range(0,len(df)):\n",
    "        newdf.iloc[i,0] = st.stem(str(df.iloc[i,0])) \n",
    "        # Plz make sure the word column is the first column in df when using this function\n",
    "    \n",
    "    # Recount\n",
    "    duplicate = newdf[newdf.duplicated(['index'])]\n",
    "    # Plz make sure the 'index' is the column name consisting of words\n",
    "    for i in range(0,len(newdf)):\n",
    "        if i >= len(duplicate):\n",
    "            break\n",
    "        if newdf.iloc[i,0] == duplicate.iloc[i,0]:\n",
    "            newdf.iloc[i,1] = newdf.iloc[i,1] + duplicate.iloc[i,1]\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_fresh = split_fresh.str.split(expand=True).stack().value_counts()\n",
    "common_words_fresh_df = pd.DataFrame(common_words_fresh)\n",
    "common_words_fresh_df = common_words_fresh_df.rename({0:'Occurence good review'}, axis='columns')\n",
    "new_common_words_fresh_df = common_words_fresh_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movy</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ful</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lik</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>span</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>review</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>good</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ev</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fun</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>film</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>comedy</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>way</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>best</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tim</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>much</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>us</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>direct</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>stil</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>funny</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>too</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>doesnt</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lov</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mak</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>also</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dram</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>new</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>may</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>charact</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>careen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>spar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>lyr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>titl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>distinct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>fairway</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>gelid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>wan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>inflam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>lightweight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6155</th>\n",
       "      <td>gut</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>riley</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6157</th>\n",
       "      <td>film</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6158</th>\n",
       "      <td>resolv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159</th>\n",
       "      <td>seven</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160</th>\n",
       "      <td>jump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6161</th>\n",
       "      <td>pel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6162</th>\n",
       "      <td>doubt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6163</th>\n",
       "      <td>daytoday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>craftsm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>selfacceiv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166</th>\n",
       "      <td>fasc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6167</th>\n",
       "      <td>ex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6168</th>\n",
       "      <td>formul</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6169</th>\n",
       "      <td>petit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>larson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>swag</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>wel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>hono</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>ench</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6175 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  Occurence good review\n",
       "0            film                    240\n",
       "1            movy                    149\n",
       "2              on                     88\n",
       "3           story                     86\n",
       "4             ful                     62\n",
       "5             lik                     56\n",
       "6            span                     51\n",
       "7          review                     51\n",
       "8            good                     49\n",
       "9              ev                     49\n",
       "10            fun                     46\n",
       "11           film                     45\n",
       "12         comedy                     44\n",
       "13            way                     44\n",
       "14           best                     42\n",
       "15            tim                     41\n",
       "16           much                     38\n",
       "17             us                     38\n",
       "18         direct                     36\n",
       "19           stil                     36\n",
       "20          funny                     35\n",
       "21            too                     35\n",
       "22         doesnt                     34\n",
       "23            lov                     34\n",
       "24            mak                     34\n",
       "25           also                     33\n",
       "26           dram                     33\n",
       "27            new                     33\n",
       "28            may                     32\n",
       "29        charact                     32\n",
       "...           ...                    ...\n",
       "6145       careen                      1\n",
       "6146         spar                      1\n",
       "6147          lyr                      1\n",
       "6148         titl                      1\n",
       "6149     distinct                      1\n",
       "6150      fairway                      1\n",
       "6151        gelid                      1\n",
       "6152          wan                      1\n",
       "6153       inflam                      1\n",
       "6154  lightweight                      1\n",
       "6155          gut                      1\n",
       "6156        riley                      1\n",
       "6157         film                      1\n",
       "6158       resolv                      1\n",
       "6159        seven                      1\n",
       "6160         jump                      1\n",
       "6161          pel                      1\n",
       "6162        doubt                      1\n",
       "6163     daytoday                      1\n",
       "6164      craftsm                      1\n",
       "6165   selfacceiv                      1\n",
       "6166         fasc                      1\n",
       "6167           ex                      1\n",
       "6168       formul                      1\n",
       "6169        petit                      1\n",
       "6170       larson                      1\n",
       "6171         swag                      1\n",
       "6172          wel                      1\n",
       "6173         hono                      1\n",
       "6174         ench                      1\n",
       "\n",
       "[6175 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_recount(new_common_words_fresh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>films</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doesnt</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drama</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characters</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mars</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tricky</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>battle</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lucas</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reasons</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roots</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decades</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigger</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clear</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palma</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youve</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cannot</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cute</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greatness</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fantasy</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dan</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appealing</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usual</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vision</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justice</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joyful</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creativity</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forgotten</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>819 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Occurence good review\n",
       "film                          195\n",
       "movie                         117\n",
       "one                            88\n",
       "story                          86\n",
       "full                           62\n",
       "like                           56\n",
       "spanish                        51\n",
       "review                         51\n",
       "good                           49\n",
       "even                           49\n",
       "fun                            46\n",
       "films                          45\n",
       "comedy                         44\n",
       "way                            44\n",
       "best                           42\n",
       "time                           41\n",
       "much                           38\n",
       "us                             38\n",
       "director                       36\n",
       "still                          36\n",
       "funny                          35\n",
       "too                            35\n",
       "doesnt                         34\n",
       "love                           34\n",
       "make                           34\n",
       "also                           33\n",
       "drama                          33\n",
       "new                            33\n",
       "may                            32\n",
       "characters                     32\n",
       "...                           ...\n",
       "mary                            4\n",
       "mars                            4\n",
       "tricky                          4\n",
       "battle                          4\n",
       "lucas                           4\n",
       "reasons                         4\n",
       "roots                           4\n",
       "effect                          4\n",
       "decades                         4\n",
       "bigger                          4\n",
       "clear                           4\n",
       "palma                           4\n",
       "youve                           4\n",
       "purpose                         4\n",
       "youth                           4\n",
       "results                         4\n",
       "cannot                          4\n",
       "act                             4\n",
       "cute                            4\n",
       "home                            4\n",
       "greatness                       4\n",
       "fantasy                         4\n",
       "dan                             4\n",
       "appealing                       4\n",
       "usual                           4\n",
       "vision                          4\n",
       "justice                         4\n",
       "joyful                          4\n",
       "creativity                      4\n",
       "forgotten                       4\n",
       "\n",
       "[819 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get most common words in positive reviews \n",
    "top_common_words_fresh = common_words_fresh_df[common_words_fresh_df['Occurence good review'] >=4]\n",
    "top_common_words_fresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** EXPLAIN WHY WE DONT USE LEMMATIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b> Reason for not using Lemmatization </b>\n",
    "\n",
    "<p>\n",
    "    Before counting the occurance of words in the movie review, we noticed that inflections in words may result in different occurances and thus generating bias during counting. For example, \"enjoy\" and \"enjoyed\" share the same root but would be counted separately if not using Lemmatization.\n",
    "    </p> \n",
    "    \n",
    "<p>\n",
    "    The function \"stem_recount\" takes the root of a word and recounts the occurences. However, it posed a disadvantage of mis-normalizing words into other completely different words. For example, \"movie\" was identified as \"movy\", and \"like\" was identified as \"lik\". We thought this disadvantage exceeds the benefits of correcting word inflection, so we decided to not implement it.\n",
    "    </p> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    like a goodlooking blind date who promises din...\n",
       "1     when a movie features two spit takes in the f...\n",
       "2    the darkest minds never communicates the overw...\n",
       "3    mostly generations spends its running length s...\n",
       "4    but much like the playmobil toys with their po...\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from rotten & turn into Series\n",
    "split_rotten= pd.Series(remove_punctuation(development_split_rotten))\n",
    "split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords from negative reviews\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_rotten.replace(replacements, regex=True, inplace=True)\n",
    "split_rotten.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get most common words in negative reviews \n",
    "\n",
    "common_words_rotten = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "common_words_rotten_df = pd.DataFrame(common_words_rotten)\n",
    "common_words_rotten_df = common_words_rotten_df.rename({0:'Occurence bad review'}, axis='columns')\n",
    "top_common_words_rotten = common_words_rotten_df[common_words_rotten_df['Occurence bad review'] >=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Occurence bad review\n",
       "film                    121\n",
       "movie                    94\n",
       "like                     65\n",
       "too                      56\n",
       "one                      55"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_common_words_rotten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of good and bad reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the two lists \n",
    "#--> find out which of the words in the good list only appear in the good movies (and not in the bad movies )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempts before \n",
    "#outer join --> displays words that are only in good reviews and only in bad reviews\n",
    "# top_common_words = pd.concat([top_common_words_fresh, top_common_words_rotten], axis=1)\n",
    "# top_common_words\n",
    "\n",
    "#inner join \n",
    "# top_common_words = pd.merge(top_common_words_fresh, top_common_words_rotten, left_index=True, right_index=True)\n",
    "# top_common_words\n",
    "\n",
    "top_fresh_words_exclusive = top_common_words_fresh.merge(top_common_words_rotten, indicator='i', how='outer', left_index=True,\\\n",
    "                                                         right_index=True).query('i == \"left_only\"').drop('i', 1)\n",
    "\n",
    "top_rotten_words_exclusive = top_common_words_rotten.merge(top_common_words_fresh, indicator='i', how='outer', left_index=True,\\\n",
    "                                                           right_index=True).query('i == \"left_only\"').drop('i', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolutely</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absorbing</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absurd</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absurdity</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Occurence good review  Occurence bad review\n",
       "2019                          6.0                   NaN\n",
       "absolutely                    5.0                   NaN\n",
       "absorbing                     4.0                   NaN\n",
       "absurd                        5.0                   NaN\n",
       "absurdity                     4.0                   NaN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_fresh_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adam</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approach</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awful</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Occurence bad review  Occurence good review\n",
       "actual                     4.0                    NaN\n",
       "adam                       4.0                    NaN\n",
       "approach                   6.0                    NaN\n",
       "attempt                    4.0                    NaN\n",
       "awful                      4.0                    NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rotten_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019',\n",
       " 'absolutely',\n",
       " 'absorbing',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'across',\n",
       " 'acting',\n",
       " 'actor',\n",
       " 'adults',\n",
       " 'adventure',\n",
       " 'affecting',\n",
       " 'age',\n",
       " 'aimee',\n",
       " 'alien',\n",
       " 'allen',\n",
       " 'allows',\n",
       " 'amazing',\n",
       " 'ambitious',\n",
       " 'america',\n",
       " 'among',\n",
       " 'amusing',\n",
       " 'angst',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'anyone',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'art',\n",
       " 'atmospheric',\n",
       " 'audiences',\n",
       " 'awkward',\n",
       " 'baseball',\n",
       " 'battle',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'behind',\n",
       " 'believe',\n",
       " 'bet',\n",
       " 'bigger',\n",
       " 'bill',\n",
       " 'biopic',\n",
       " 'bizarre',\n",
       " 'body',\n",
       " 'bold',\n",
       " 'bond',\n",
       " 'bourne',\n",
       " 'brian',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'brothers',\n",
       " 'brutal',\n",
       " 'build',\n",
       " 'bythenumbers',\n",
       " 'came',\n",
       " 'cannot',\n",
       " 'career',\n",
       " 'central',\n",
       " 'certain',\n",
       " 'change',\n",
       " 'charm',\n",
       " 'chief',\n",
       " 'childhood',\n",
       " 'chilling',\n",
       " 'cinematography',\n",
       " 'city',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'clearly',\n",
       " 'clift',\n",
       " 'close',\n",
       " 'coen',\n",
       " 'combination',\n",
       " 'comedic',\n",
       " 'comingofage',\n",
       " 'commentary',\n",
       " 'committed',\n",
       " 'complex',\n",
       " 'conclusion',\n",
       " 'consistently',\n",
       " 'contemporary',\n",
       " 'conventions',\n",
       " 'cool',\n",
       " 'costume',\n",
       " 'crafted',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creativity',\n",
       " 'crime',\n",
       " 'culture',\n",
       " 'current',\n",
       " 'cut',\n",
       " 'cynical',\n",
       " 'damn',\n",
       " 'dan',\n",
       " 'dance',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'david',\n",
       " 'dazzling',\n",
       " 'debut',\n",
       " 'decades',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'deeply',\n",
       " 'definitely',\n",
       " 'delightfully',\n",
       " 'deliver',\n",
       " 'delivered',\n",
       " 'delivers',\n",
       " 'depth',\n",
       " 'details',\n",
       " 'difficult',\n",
       " 'direction',\n",
       " 'disney',\n",
       " 'display',\n",
       " 'disturbing',\n",
       " 'dog',\n",
       " 'done',\n",
       " 'door',\n",
       " 'doubt',\n",
       " 'early',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'eccentric',\n",
       " 'edge',\n",
       " 'editing',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effects',\n",
       " 'elements',\n",
       " 'elevate',\n",
       " 'emotion',\n",
       " 'emotionally',\n",
       " 'emotions',\n",
       " 'empathy',\n",
       " 'energetic',\n",
       " 'engaging',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'ensemble',\n",
       " 'entertain',\n",
       " 'entire',\n",
       " 'entirely',\n",
       " 'essential',\n",
       " 'example',\n",
       " 'excellent',\n",
       " 'exercise',\n",
       " 'explores',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'fairly',\n",
       " 'families',\n",
       " 'fantastic',\n",
       " 'fascination',\n",
       " 'fast',\n",
       " 'father',\n",
       " 'features',\n",
       " 'female',\n",
       " 'feminist',\n",
       " 'fight',\n",
       " 'filled',\n",
       " 'filmmaker',\n",
       " 'finally',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'finely',\n",
       " 'finest',\n",
       " 'flair',\n",
       " 'focus',\n",
       " 'footage',\n",
       " 'forgotten',\n",
       " 'form',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'frame',\n",
       " 'frequently',\n",
       " 'friendship',\n",
       " 'future',\n",
       " 'generally',\n",
       " 'generation',\n",
       " 'generous',\n",
       " 'genuinely',\n",
       " 'girl',\n",
       " 'gone',\n",
       " 'greatest',\n",
       " 'greatness',\n",
       " 'green',\n",
       " 'grim',\n",
       " 'gripping',\n",
       " 'gritty',\n",
       " 'grotesque',\n",
       " 'happen',\n",
       " 'happy',\n",
       " 'havent',\n",
       " 'heartbreaking',\n",
       " 'heartfelt',\n",
       " 'heavyhanded',\n",
       " 'hell',\n",
       " 'help',\n",
       " 'helps',\n",
       " 'heroes',\n",
       " 'high',\n",
       " 'highly',\n",
       " 'hilarious',\n",
       " 'honest',\n",
       " 'hope',\n",
       " 'house',\n",
       " 'however',\n",
       " 'human',\n",
       " 'humanity',\n",
       " 'humour',\n",
       " 'images',\n",
       " 'imagination',\n",
       " 'impact',\n",
       " 'impossible',\n",
       " 'impressive',\n",
       " 'including',\n",
       " 'increasingly',\n",
       " 'incredibly',\n",
       " 'insightful',\n",
       " 'intellectual',\n",
       " 'intelligent',\n",
       " 'interviews',\n",
       " 'intimate',\n",
       " 'issue',\n",
       " 'issues',\n",
       " 'jacksons',\n",
       " 'job',\n",
       " 'josh',\n",
       " 'journey',\n",
       " 'joy',\n",
       " 'joyful',\n",
       " 'justice',\n",
       " 'keeping',\n",
       " 'keeps',\n",
       " 'key',\n",
       " 'kid',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'land',\n",
       " 'language',\n",
       " 'latest',\n",
       " 'laugh',\n",
       " 'lead',\n",
       " 'leave',\n",
       " 'leaving',\n",
       " 'let',\n",
       " 'lies',\n",
       " 'likely',\n",
       " 'line',\n",
       " 'lives',\n",
       " 'living',\n",
       " 'looking',\n",
       " 'loose',\n",
       " 'lucas',\n",
       " 'magic',\n",
       " 'major',\n",
       " 'manages',\n",
       " 'mars',\n",
       " 'marvel',\n",
       " 'mary',\n",
       " 'masterful',\n",
       " 'masterpiece',\n",
       " 'matter',\n",
       " 'means',\n",
       " 'memory',\n",
       " 'men',\n",
       " 'mental',\n",
       " 'mesmerizing',\n",
       " 'middle',\n",
       " 'mind',\n",
       " 'miss',\n",
       " 'mix',\n",
       " 'modern',\n",
       " 'monster',\n",
       " 'mood',\n",
       " 'moore',\n",
       " 'moral',\n",
       " 'mother',\n",
       " 'move',\n",
       " 'moving',\n",
       " 'murder',\n",
       " 'murray',\n",
       " 'music',\n",
       " 'musical',\n",
       " 'mystery',\n",
       " 'national',\n",
       " 'nature',\n",
       " 'netflix',\n",
       " 'nice',\n",
       " 'noir',\n",
       " 'odd',\n",
       " 'ode',\n",
       " 'offer',\n",
       " 'ok',\n",
       " 'oldfashioned',\n",
       " 'pace',\n",
       " 'palma',\n",
       " 'part',\n",
       " 'particular',\n",
       " 'parts',\n",
       " 'path',\n",
       " 'pathos',\n",
       " 'perfect',\n",
       " 'perfection',\n",
       " 'perfectly',\n",
       " 'perhaps',\n",
       " 'period',\n",
       " 'personal',\n",
       " 'perspective',\n",
       " 'peter',\n",
       " 'places',\n",
       " 'pleasant',\n",
       " 'plenty',\n",
       " 'politics',\n",
       " 'portrait',\n",
       " 'portrayal',\n",
       " 'power',\n",
       " 'powerful',\n",
       " 'primal',\n",
       " 'production',\n",
       " 'profound',\n",
       " 'proves',\n",
       " 'provides',\n",
       " 'provocative',\n",
       " 'psychological',\n",
       " 'pull',\n",
       " 'pulls',\n",
       " 'pure',\n",
       " 'purpose',\n",
       " 'pursuit',\n",
       " 'putting',\n",
       " 'quality',\n",
       " 'quest',\n",
       " 'quiet',\n",
       " 'rare',\n",
       " 'raw',\n",
       " 'reach',\n",
       " 'ready',\n",
       " 'reallife',\n",
       " 'reasons',\n",
       " 'recent',\n",
       " 'refreshing',\n",
       " 'relationship',\n",
       " 'remains',\n",
       " 'remarkable',\n",
       " 'remember',\n",
       " 'represents',\n",
       " 'result',\n",
       " 'results',\n",
       " 'reveals',\n",
       " 'revenge',\n",
       " 'rewarding',\n",
       " 'rhythms',\n",
       " 'rich',\n",
       " 'ride',\n",
       " 'rise',\n",
       " 'romance',\n",
       " 'romp',\n",
       " 'room',\n",
       " 'roots',\n",
       " 'satisfying',\n",
       " 'saw',\n",
       " 'school',\n",
       " 'scifi',\n",
       " 'score',\n",
       " 'season',\n",
       " 'secret',\n",
       " 'seeing',\n",
       " 'sequences',\n",
       " 'serves',\n",
       " 'shes',\n",
       " 'shock',\n",
       " 'shot',\n",
       " 'showcase',\n",
       " 'showing',\n",
       " 'shows',\n",
       " 'significant',\n",
       " 'since',\n",
       " 'sister',\n",
       " 'situation',\n",
       " 'skin',\n",
       " 'slightly',\n",
       " 'smart',\n",
       " 'smarter',\n",
       " 'smith',\n",
       " 'social',\n",
       " 'society',\n",
       " 'solid',\n",
       " 'somewhat',\n",
       " 'son',\n",
       " 'sophisticated',\n",
       " 'soul',\n",
       " 'sound',\n",
       " 'space',\n",
       " 'sparks',\n",
       " 'spirit',\n",
       " 'stage',\n",
       " 'star',\n",
       " 'starring',\n",
       " 'state',\n",
       " 'steve',\n",
       " 'stop',\n",
       " 'strong',\n",
       " 'study',\n",
       " 'stunning',\n",
       " 'subtle',\n",
       " 'succeeds',\n",
       " 'successful',\n",
       " 'summer',\n",
       " 'superhero',\n",
       " 'sure',\n",
       " 'surprise',\n",
       " 'surprisingly',\n",
       " 'surreal',\n",
       " 'survival',\n",
       " 'taking',\n",
       " 'talented',\n",
       " 'talents',\n",
       " 'target',\n",
       " 'telling',\n",
       " 'tells',\n",
       " 'tender',\n",
       " 'terrific',\n",
       " 'thanks',\n",
       " 'themes',\n",
       " 'thinking',\n",
       " 'thoroughly',\n",
       " 'thought',\n",
       " 'thoughtful',\n",
       " 'throughout',\n",
       " 'told',\n",
       " 'top',\n",
       " 'touching',\n",
       " 'tough',\n",
       " 'toy',\n",
       " 'tragedy',\n",
       " 'tricky',\n",
       " 'trip',\n",
       " 'tropes',\n",
       " 'turning',\n",
       " 'twists',\n",
       " 'unexpected',\n",
       " 'unique',\n",
       " 'universe',\n",
       " 'uses',\n",
       " 'usual',\n",
       " 'view',\n",
       " 'viewing',\n",
       " 'violent',\n",
       " 'visuals',\n",
       " 'voice',\n",
       " 'warm',\n",
       " 'watchable',\n",
       " 'ways',\n",
       " 'wellacted',\n",
       " 'whats',\n",
       " 'wit',\n",
       " 'within',\n",
       " 'witty',\n",
       " 'wonder',\n",
       " 'wonderful',\n",
       " 'wonderfully',\n",
       " 'wont',\n",
       " 'working',\n",
       " 'worlds',\n",
       " 'wouldnt',\n",
       " 'writing',\n",
       " 'written',\n",
       " 'yesterday',\n",
       " 'youth',\n",
       " 'youve']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only positive words \n",
    "top_fresh_words_exclusive_list = top_fresh_words_exclusive['Occurence good review'].index.tolist()\n",
    "top_fresh_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolutely',\n",
       " 'addition',\n",
       " 'adventure',\n",
       " 'affectionate',\n",
       " 'amazing',\n",
       " 'ambition',\n",
       " 'art',\n",
       " 'artist',\n",
       " 'arts',\n",
       " 'atmosphere',\n",
       " 'attractive',\n",
       " 'awards',\n",
       " 'balance',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'bond',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'captivating',\n",
       " 'captures',\n",
       " 'celebration',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'christmas',\n",
       " 'classic',\n",
       " 'clever',\n",
       " 'committed',\n",
       " 'consistently',\n",
       " 'contemporary',\n",
       " 'conventional',\n",
       " 'convincingly',\n",
       " 'creates',\n",
       " 'creating',\n",
       " 'crowdpleaser',\n",
       " 'cult',\n",
       " 'decade',\n",
       " 'decades',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'deeply',\n",
       " 'definitely',\n",
       " 'delightful',\n",
       " 'delightfully',\n",
       " 'depth',\n",
       " 'deserves',\n",
       " 'design',\n",
       " 'details',\n",
       " 'different',\n",
       " 'diverse',\n",
       " 'dramatic',\n",
       " 'early',\n",
       " 'elegant',\n",
       " 'emotionally',\n",
       " 'engaging',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'equal',\n",
       " 'especially',\n",
       " 'exploration',\n",
       " 'extraordinary',\n",
       " 'extremely',\n",
       " 'familiar',\n",
       " 'famous',\n",
       " 'fan',\n",
       " 'fantastic',\n",
       " 'fantasy',\n",
       " 'fascinating',\n",
       " 'felt',\n",
       " 'filled',\n",
       " 'finest',\n",
       " 'frank',\n",
       " 'fresh',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'gags',\n",
       " 'gorgeous',\n",
       " 'grand',\n",
       " 'happy',\n",
       " 'heart',\n",
       " 'hilarious',\n",
       " 'honest',\n",
       " 'hope',\n",
       " 'huge',\n",
       " 'impact',\n",
       " 'insightful',\n",
       " 'inspiring',\n",
       " 'intelligent',\n",
       " 'intense',\n",
       " 'intrigue',\n",
       " 'joy',\n",
       " 'laugh',\n",
       " 'loved',\n",
       " 'mature',\n",
       " 'mind',\n",
       " 'mystery',\n",
       " 'nostalgia',\n",
       " 'novel',\n",
       " 'opening',\n",
       " 'passion',\n",
       " 'perfect',\n",
       " 'performers',\n",
       " 'personal',\n",
       " 'pleasure',\n",
       " 'poignant',\n",
       " 'power',\n",
       " 'powerful',\n",
       " 'precisely',\n",
       " 'profound',\n",
       " 'project',\n",
       " 'proves',\n",
       " 'provide',\n",
       " 'provocative',\n",
       " 'psychological',\n",
       " 'quality',\n",
       " 'remarkable',\n",
       " 'reveals',\n",
       " 'rich',\n",
       " 'riveting',\n",
       " 'satisfying',\n",
       " 'sharp',\n",
       " 'simple',\n",
       " 'smart',\n",
       " 'smile',\n",
       " 'stunning',\n",
       " 'succeeds',\n",
       " 'supernatural',\n",
       " 'surprise',\n",
       " 'surprises',\n",
       " 'surprising',\n",
       " 'surprisingly',\n",
       " 'sweet',\n",
       " 'talents',\n",
       " 'thoughtful',\n",
       " 'thrills',\n",
       " 'touch',\n",
       " 'touching',\n",
       " 'tragedy',\n",
       " 'tragic',\n",
       " 'tribute',\n",
       " 'unique',\n",
       " 'universal',\n",
       " 'warm',\n",
       " 'watchable',\n",
       " 'welcome',\n",
       " 'wit',\n",
       " 'witty',\n",
       " 'wonderful',\n",
       " 'worthwhile',\n",
       " 'worthy']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_fresh_words_exclusive = ['absolutely',\n",
    " 'addition',\n",
    " 'adventure',\n",
    " 'affectionate',\n",
    " 'amazing',\n",
    " 'ambition',\n",
    " 'art',\n",
    " 'artist',\n",
    " 'arts',\n",
    " 'atmosphere',\n",
    " 'attractive',\n",
    " 'awards',\n",
    " 'balance',\n",
    " 'beautiful',\n",
    " 'beautifully',\n",
    " 'beauty',\n",
    " 'bond',\n",
    " 'bright',\n",
    " 'brilliant',\n",
    " 'captivating',\n",
    " 'captures',\n",
    " 'celebration',\n",
    " 'charm',\n",
    " 'charming',\n",
    " 'christmas',\n",
    " 'classic',\n",
    " 'clever',\n",
    " 'committed',\n",
    " 'consistently',\n",
    " 'contemporary',\n",
    " 'conventional',\n",
    " 'convincingly',\n",
    " 'creates',\n",
    " 'creating',\n",
    " 'crowdpleaser',\n",
    " 'cult',\n",
    " 'decade',\n",
    " 'decades',\n",
    " 'deep',\n",
    " 'deeper',\n",
    " 'deeply',\n",
    " 'definitely',\n",
    " 'delightful',\n",
    " 'delightfully',\n",
    " 'depth',\n",
    " 'deserves',\n",
    " 'design',\n",
    " 'details',\n",
    " 'different',\n",
    " 'diverse',\n",
    " 'dramatic',\n",
    " 'early',\n",
    " 'elegant',\n",
    " 'emotionally',\n",
    " 'engaging',\n",
    " 'enjoyable',\n",
    " 'enjoyed',\n",
    " 'equal',\n",
    " 'especially',\n",
    " 'exploration',\n",
    " 'extraordinary',\n",
    " 'extremely',\n",
    " 'familiar',\n",
    " 'famous',\n",
    " 'fan',\n",
    " 'fantastic',\n",
    " 'fantasy',\n",
    " 'fascinating',\n",
    " 'felt',\n",
    " 'filled',\n",
    " 'finest',\n",
    " 'frank',\n",
    " 'fresh',\n",
    " 'friends',\n",
    " 'friendship',\n",
    " 'gags',\n",
    " 'gorgeous',\n",
    " 'grand',\n",
    " 'happy',\n",
    " 'heart',\n",
    " 'hilarious',\n",
    " 'honest',\n",
    " 'hope',\n",
    " 'huge',\n",
    " 'impact',\n",
    " 'insightful',\n",
    " 'inspiring',\n",
    " 'intelligent',\n",
    " 'intense',\n",
    " 'intrigue',\n",
    " 'joy',\n",
    " 'laugh',\n",
    " 'loved',\n",
    " 'mature',\n",
    " 'mind',\n",
    " 'mystery',\n",
    " 'nostalgia',\n",
    " 'novel',\n",
    " 'opening',\n",
    " 'passion',\n",
    " 'perfect',\n",
    " 'performers',\n",
    " 'personal',\n",
    " 'pleasure',\n",
    " 'poignant',\n",
    " 'power',\n",
    " 'powerful',\n",
    " 'precisely',\n",
    " 'profound',\n",
    " 'project',\n",
    " 'proves',\n",
    " 'provide',\n",
    " 'provocative',\n",
    " 'psychological',\n",
    " 'quality',\n",
    " 'remarkable',\n",
    " 'reveals',\n",
    " 'rich',\n",
    " 'riveting',\n",
    " 'satisfying',\n",
    " 'sharp',\n",
    " 'simple',\n",
    " 'smart',\n",
    " 'smile',\n",
    " 'stunning',\n",
    " 'succeeds',\n",
    " 'supernatural',\n",
    " 'surprise',\n",
    " 'surprises',\n",
    " 'surprising',\n",
    " 'surprisingly',\n",
    " 'sweet',\n",
    " 'talents',\n",
    " 'thoughtful',\n",
    " 'thrills',\n",
    " 'touch',\n",
    " 'touching',\n",
    " 'tragedy',\n",
    " 'tragic',\n",
    " 'tribute',\n",
    " 'unique',\n",
    " 'universal',\n",
    " 'warm',\n",
    " 'watchable',\n",
    " 'welcome',\n",
    " 'wit',\n",
    " 'witty',\n",
    " 'wonderful',\n",
    " 'worthwhile',\n",
    " 'worthy']\n",
    "\n",
    "top_fresh_words_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actual',\n",
       " 'adam',\n",
       " 'approach',\n",
       " 'attempt',\n",
       " 'awful',\n",
       " 'believable',\n",
       " 'bgrade',\n",
       " 'bland',\n",
       " 'boring',\n",
       " 'building',\n",
       " 'care',\n",
       " 'cash',\n",
       " 'chainsaw',\n",
       " 'christmas',\n",
       " 'clichés',\n",
       " 'climax',\n",
       " 'clumsy',\n",
       " 'comic',\n",
       " 'confusing',\n",
       " 'content',\n",
       " 'contrived',\n",
       " 'critters',\n",
       " 'designed',\n",
       " 'desperate',\n",
       " 'development',\n",
       " 'dull',\n",
       " 'effort',\n",
       " 'else',\n",
       " 'ending',\n",
       " 'energy',\n",
       " 'epic',\n",
       " 'equivalent',\n",
       " 'especially',\n",
       " 'eventually',\n",
       " 'everyone',\n",
       " 'execution',\n",
       " 'fails',\n",
       " 'failure',\n",
       " 'flat',\n",
       " 'flick',\n",
       " 'forgettable',\n",
       " 'frustrating',\n",
       " 'fully',\n",
       " 'gags',\n",
       " 'generic',\n",
       " 'getting',\n",
       " 'giving',\n",
       " 'got',\n",
       " 'guy',\n",
       " 'half',\n",
       " 'hanks',\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'holds',\n",
       " 'hours',\n",
       " 'identity',\n",
       " 'ingredients',\n",
       " 'insight',\n",
       " 'james',\n",
       " 'lacks',\n",
       " 'left',\n",
       " 'length',\n",
       " 'lifetime',\n",
       " 'loud',\n",
       " 'manner',\n",
       " 'mean',\n",
       " 'meaning',\n",
       " 'meaningful',\n",
       " 'melodrama',\n",
       " 'mess',\n",
       " 'minutes',\n",
       " 'misses',\n",
       " 'na',\n",
       " 'name',\n",
       " 'needs',\n",
       " 'night',\n",
       " 'none',\n",
       " 'obsession',\n",
       " 'obvious',\n",
       " 'opportunity',\n",
       " 'overall',\n",
       " 'paper',\n",
       " 'particularly',\n",
       " 'possible',\n",
       " 'premise',\n",
       " 'presence',\n",
       " 'problem',\n",
       " 'promising',\n",
       " 'questions',\n",
       " 'quickly',\n",
       " 'reason',\n",
       " 'relationships',\n",
       " 'release',\n",
       " 'respect',\n",
       " 'romcom',\n",
       " 'running',\n",
       " 'sadly',\n",
       " 'scares',\n",
       " 'second',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seriously',\n",
       " 'setting',\n",
       " 'shouldnt',\n",
       " 'sight',\n",
       " 'simple',\n",
       " 'somehow',\n",
       " 'source',\n",
       " 'spends',\n",
       " 'stale',\n",
       " 'sticks',\n",
       " 'studio',\n",
       " 'stuff',\n",
       " 'substance',\n",
       " 'suffers',\n",
       " 'suggest',\n",
       " 'supporting',\n",
       " 'surface',\n",
       " 'terms',\n",
       " 'theatrical',\n",
       " 'third',\n",
       " 'tries',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'turned',\n",
       " 'tv',\n",
       " 'twist',\n",
       " 'typical',\n",
       " 'unfortunately',\n",
       " 'version',\n",
       " 'video',\n",
       " 'wanted',\n",
       " 'wants',\n",
       " 'watched',\n",
       " 'welcome',\n",
       " 'western',\n",
       " 'worst']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only negative words \n",
    "top_rotten_words_exclusive_list = top_rotten_words_exclusive['Occurence bad review'].index.tolist()\n",
    "top_rotten_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attempt',\n",
       " 'awkward',\n",
       " 'barely',\n",
       " 'basically',\n",
       " 'bizarre',\n",
       " 'bland',\n",
       " 'boring',\n",
       " 'clumsy',\n",
       " 'comedic',\n",
       " 'disappointing',\n",
       " 'disappointingly',\n",
       " 'disappointment',\n",
       " 'disaster',\n",
       " 'dull',\n",
       " 'effort',\n",
       " 'failed',\n",
       " 'fails',\n",
       " 'generic',\n",
       " 'irritating',\n",
       " 'lacking',\n",
       " 'manic',\n",
       " 'missing',\n",
       " 'nobody',\n",
       " 'noir',\n",
       " 'none',\n",
       " 'painfully',\n",
       " 'pointless',\n",
       " 'poorly',\n",
       " 'problem',\n",
       " 'shallow',\n",
       " 'shame',\n",
       " 'sloppy',\n",
       " 'slow',\n",
       " 'suffers',\n",
       " 'superficial',\n",
       " 'try',\n",
       " 'unfortunately',\n",
       " 'unfunny',\n",
       " 'worst']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_rotten_words_exclusive = [\n",
    " 'attempt',\n",
    " 'awkward',\n",
    " 'barely',\n",
    " 'basically',\n",
    " 'bizarre',\n",
    " 'bland',\n",
    " 'boring',\n",
    " 'clumsy',\n",
    " 'comedic',\n",
    " 'disappointing',\n",
    " 'disappointingly',\n",
    " 'disappointment',\n",
    " 'disaster',\n",
    " 'dull',\n",
    " 'effort',\n",
    " 'failed',\n",
    " 'fails',\n",
    " 'generic',\n",
    " 'irritating',\n",
    " 'lacking',\n",
    " 'manic',\n",
    " 'missing',\n",
    " 'nobody',\n",
    " 'noir',\n",
    " 'none',\n",
    " 'painfully',\n",
    " 'pointless',\n",
    " 'poorly',\n",
    " 'problem',\n",
    " 'shallow',\n",
    " 'shame',\n",
    " 'sloppy',\n",
    " 'slow',\n",
    " 'suffers',\n",
    " 'superficial',\n",
    " 'try',\n",
    " 'unfortunately',\n",
    " 'unfunny',\n",
    " 'worst']\n",
    "top_rotten_words_exclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A. Good / bad exclusive words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "NOTFRESH = 0\n",
    "FRESH = 1\n",
    "\n",
    "@labeling_function()\n",
    "def fresh(x):\n",
    "    for word in top_fresh_words_exclusive:\n",
    "        if word in str(x).lower():\n",
    "            return FRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def rotten(x):\n",
    "    for word in top_rotten_words_exclusive:\n",
    "        if word in str(x).lower():\n",
    "            return NOTFRESH\n",
    "    return ABSTAIN\n",
    "#return NOTFRESH if \"best\" in x.str.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:41<00:00, 47.79it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [fresh]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresh coverage:100.0%\n"
     ]
    }
   ],
   "source": [
    "coverage_fresh = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"fresh coverage:{:.1%}\".format(coverage_fresh[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:23<00:00, 84.19it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [rotten]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten coverage:5.0%\n"
     ]
    }
   ],
   "source": [
    "coverage_rotten = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"rotten coverage:{:.1%}\".format(coverage_rotten[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Word 'too' occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "too                     35"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "too                    56"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def keyword_too(x):\n",
    "    return NOTFRESH if 'too' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2915.78it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [keyword_too]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword too coverage:1.8%\n"
     ]
    }
   ],
   "source": [
    "coverage_keyword_too = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword too coverage:{:.1%}\".format(coverage_keyword_too[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Word 'far' occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "far                     15"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "far                    12"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def keyword_far(x):\n",
    "    return FRESH if 'far' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2942.69it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [keyword_far]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword far coverage:1.1%\n"
     ]
    }
   ],
   "source": [
    "coverage_keyword_far = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword far coverage:{:.1%}\".format(coverage_keyword_far[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. \"n't\" words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word occurancy that with punctuation with it\n",
    "\n",
    "# Word occurrences dataframe for fresh reviews\n",
    "development_split_fresh_1 = (development_split_fresh.Review).str.split(expand=True).stack().value_counts()\n",
    "development_split_fresh_df = pd.DataFrame(development_split_fresh_1).reset_index()\n",
    "\n",
    "# Words occurrences dataframe for rotten reviews\n",
    "development_split_rotten_1 = (development_split_rotten.Review).str.split(expand=True).stack().value_counts()\n",
    "development_split_rotten_df = pd.DataFrame(development_split_rotten_1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_not_word = []\n",
    "for word in development_split_fresh_df['index']:\n",
    "    if 'n\\'t' in word:\n",
    "        fresh_not_word.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"doesn't\",\n",
       " \"isn't\",\n",
       " \"don't\",\n",
       " \"can't\",\n",
       " \"won't\",\n",
       " \"aren't\",\n",
       " \"haven't\",\n",
       " \"didn't\",\n",
       " \"wouldn't\",\n",
       " \"Don't\",\n",
       " \"shouldn't\",\n",
       " \"doesn't.\",\n",
       " \"aren't?\",\n",
       " \"hasn't\",\n",
       " \"wasn't\",\n",
       " \"don't.)\",\n",
       " \"doesn't,\",\n",
       " \"hadn't\",\n",
       " \"is-he-or-isn't-he\",\n",
       " \"doesn't?\",\n",
       " \"haven't.\",\n",
       " \"isn't.\"]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_not_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fresh_not_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rotten_not_word = []\n",
    "for word in development_split_rotten_df['index']:\n",
    "    if 'n\\'t' in word:\n",
    "        rotten_not_word.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rotten_not_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"doesn't\",\n",
       " \"isn't\",\n",
       " \"don't\",\n",
       " \"can't\",\n",
       " \"didn't\",\n",
       " \"aren't\",\n",
       " \"shouldn't\",\n",
       " \"won't\",\n",
       " \"wouldn't\",\n",
       " \"Don't\",\n",
       " \"couldn't\",\n",
       " \"wasn't\",\n",
       " \"weren't\",\n",
       " \"hadn't\",\n",
       " \"Doesn't\",\n",
       " \"oh-no-they-didn't\",\n",
       " \"didn't.\",\n",
       " \"story-doesn't\",\n",
       " \"Isn't\",\n",
       " \"can't,\",\n",
       " \"isn't.\",\n",
       " \"ain't.\"]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_not_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Capital words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove punctuation\n",
    "def remove_punctuation_capital_letters(dataframe):\n",
    "    new_words = []\n",
    "    for word in dataframe.Review:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuation in reviews\n",
    "fresh_df = pd.DataFrame(pd.Series(remove_punctuation_capital_letters(development_split_fresh))\\\n",
    "                        .str.split(expand=True).stack().value_counts()) # Split review into words\n",
    "\n",
    "# Capital letters words that are more than 1 character\n",
    "fresh_capital_letters = [word for word in fresh_df.index if word.isupper() and len(word)>1]\n",
    "len(fresh_capital_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OK',\n",
       " 'THE',\n",
       " 'MCU',\n",
       " 'JT',\n",
       " 'WWII',\n",
       " 'DC',\n",
       " 'US',\n",
       " 'TV',\n",
       " 'III',\n",
       " 'WINDTHE',\n",
       " 'BATMAN',\n",
       " 'ESCAPE',\n",
       " 'QC',\n",
       " 'CGI',\n",
       " 'SENTIMENTALITE',\n",
       " 'GBH',\n",
       " 'NOT',\n",
       " 'II',\n",
       " 'AOK',\n",
       " 'MO',\n",
       " 'WWE',\n",
       " '5SF',\n",
       " 'DVD',\n",
       " 'DOOM',\n",
       " 'HUSH',\n",
       " 'PRIMER',\n",
       " 'NO',\n",
       " 'EMPATHY',\n",
       " 'WITCH',\n",
       " 'VFW',\n",
       " 'FROM',\n",
       " 'DIY',\n",
       " 'LOTR',\n",
       " 'BFG3000',\n",
       " 'CIA',\n",
       " 'TOMORROW',\n",
       " 'INC',\n",
       " 'SM',\n",
       " 'T2',\n",
       " '3D',\n",
       " 'ITS',\n",
       " '2U']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_capital_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuation in reviews\n",
    "rotten_df = pd.DataFrame(pd.Series(remove_punctuation_capital_letters(development_split_rotten))\\\n",
    "                        .str.split(expand=True).stack().value_counts()) # Split review into words\n",
    "\n",
    "# Capital letters words that are more than 1 character\n",
    "rotten_capital_letters = [word for word in rotten_df.index if word.isupper() and len(word)>1]\n",
    "len(rotten_capital_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TV',\n",
       " 'II',\n",
       " '3D',\n",
       " 'CGI',\n",
       " 'WWE',\n",
       " 'KILLERMAN',\n",
       " 'VOD',\n",
       " '2U',\n",
       " 'US',\n",
       " 'SHOCKING',\n",
       " 'AARP',\n",
       " 'PSA',\n",
       " 'HBO',\n",
       " 'DMX',\n",
       " 'LA',\n",
       " 'ESPN',\n",
       " 'SHAZAM',\n",
       " 'OK',\n",
       " 'NBC',\n",
       " 'PG13']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_capital_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def capital_letter(x):\n",
    "    if word.isupper() and len(word)>1 in str(x):\n",
    "        return NOTFRESH\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-74-45a272e0647f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-74-45a272e0647f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for word in str()\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for word in str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in development_split.evieRw:\n",
    "        for word in review:\n",
    "            if word.isupper() and len(word)>1:\n",
    "                print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def capital_letter(x):\n",
    "    for review in x.Review:\n",
    "        for word in review.split():\n",
    "            if word.isupper() and len(word) >1:\n",
    "                return NOTFRESH\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def capital_letter(x):\n",
    "    if word.isupper() and len(word) >1 in x.Review.split():\n",
    "        return NOTFRESH\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def capital_letter(x):\n",
    "    if word.isupper() and len(word)>1 in str(x):\n",
    "        return NOTFRESH\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def capital_letter(x):\n",
    "    return NOTFRESH if re.search([A-Z\\s]+, x.text) else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def capital_letter(x):\n",
    "    if re.search(r'[A-Z\\s]+', x.text, flags=re.I):\n",
    "        return NOTFRESH\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def capital_letter(x):\n",
    "    return NOTFRESH if re.search([A-Z\\s]+, x.text) else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in development_split.Review:\n",
    "    for word in review:\n",
    "        if word.isupper() and len(word)>1:\n",
    "            print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for review in development_split.Review:\n",
    "    for word in review.split():\n",
    "        if word.isupper() and len(word) >1:\n",
    "            print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [capital_letter]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_capital_letter = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"capital_letter coverage:{:.1%}\".format(coverage_capital_letter[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_split.Review.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '?' in str(development_split).lower():\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in str(development_split).split():\n",
    "        if word.isupper() and len(word)>1:\n",
    "            print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lfs = [capital_letter]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_capital_letter = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"capital_letter coverage:{:.1%}\".format(coverage_capital_letter[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Punctuation occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn review column into Series\n",
    "development_split_fresh_series = pd.Series(development_split_fresh.Review)\n",
    "development_split_rotten_series = pd.Series(development_split_rotten.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive reviews\n",
    "# Split reviews into word\n",
    "fresh_split = pd.Series(development_split_fresh_series.str.split(expand=True).stack())\n",
    "fresh_words = [i for i in fresh_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in fresh_words]\n",
    "fresh_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative reviews\n",
    "# Split reviews into word\n",
    "rotten_split = pd.Series(development_split_rotten_series.str.split(expand=True).stack())\n",
    "rotten_words = [i for i in rotten_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in rotten_words]\n",
    "rotten_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into a flattened list\n",
    "fresh_flattened_list = [y for x in fresh_split_words for y in x]\n",
    "rotten_flattened_list = [y for x in rotten_split_words for y in x]\n",
    "\n",
    "# Count the occurancy of each character\n",
    "# Positive reviews\n",
    "fresh_split_characters = pd.Series(fresh_flattened_list).value_counts()\n",
    "fresh_split_characters = pd.DataFrame(fresh_split_characters).reset_index()\n",
    "\n",
    "# Negative reviews\n",
    "rotten_split_characters = pd.Series(rotten_flattened_list).value_counts()\n",
    "rotten_split_characters = pd.DataFrame(rotten_split_characters).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Question mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>?</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "57     ?  29"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>?</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "58     ?  14"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" I hate to say this -- partly because I don't want it to be true and partly because it's such a terrible pun -- but could the zombie movie finally be dead?\", 'The title suggests there are no easy answers. So why does everything feel so tidy?', 'Besides being an offensive disservice to the sadly not singular tragedy of Alan Turing, how is The Imitation Game? Well, it has good performances.']\n"
     ]
    }
   ],
   "source": [
    "list_with_question_mark = []\n",
    "for review in development_split_rotten.Review:\n",
    "    if '?' in review:\n",
    "        list_with_question_mark.append(review)\n",
    "        \n",
    "print (list_with_question_mark[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@spark_nlp_labeling_function()\n",
    "def question_mark_nlp(x):\n",
    "    question_mark = [word for word in str(x).lower() if '?' in str(x).lower()]\n",
    "    return 0 if len(person_ents) > 0 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "from snorkel.labeling.lf import labeling_function\n",
    "from snorkel.labeling.lf.nlp_spark import spark_nlp_labeling_function\n",
    "from snorkel.preprocess import preprocessor\n",
    "@spark_nlp_labeling_function(text_field = )\n",
    "def question_mark_nlp(x):\n",
    "    if '?' in str(x).lower():\n",
    "            return NOTFRESH\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "from snorkel.labeling.lf import labeling_function\n",
    "from snorkel.labeling.lf.nlp_spark import spark_nlp_labeling_function\n",
    "from snorkel.preprocess import preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@spark_nlp_labeling_function()\n",
    "def question_mark():\n",
    "    if '?' in str(x).lower():\n",
    "        return NOTFRESH\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def question_mark(x):\n",
    "    return NOTFRESH if '?' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2609.26it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [question_mark]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question mark coverage:0.4%\n"
     ]
    }
   ],
   "source": [
    "coverage_question_mark = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"question mark coverage:{:.1%}\".format(coverage_question_mark[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Exclaimation mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the # of occurance of '!' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the # of occurance of '!' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def exclaimation_mark(x):\n",
    "    return FRESH if '!' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lfs = [exclaimation_mark]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_exclaimation_mark = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"exclaimation mark coverage:{:.1%}\".format(coverage_exclaimation_mark[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(str(x))\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return FRESH if x.polarity > 0.8 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_subjectivity(x):\n",
    "    return FRESH if x.subjectivity >= 0.5 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 19.0 failed 1 times, most recent failure: Lost task 2.0 in stage 19.0 (TID 78, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 379, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/spark.py\", line 36, in map_fn\n    return apply_lfs_to_data_point(*args, lfs=self._lfs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/core.py\", line 83, in apply_lfs_to_data_point\n    y = lf(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 84, in __call__\n    x = self._preprocess_data_point(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 62, in _preprocess_data_point\n    x = preprocessor(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 152, in __call__\n    x_mapped = self._generate_mapped_data_point(x_mapped)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 304, in _generate_mapped_data_point\n    return self._f(x)\n  File \"<ipython-input-61-5106c698ef72>\", line 4, in textblob_sentiment\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1565, in __setattr__\n    raise Exception(\"Row is read-only\")\nException: Row is read-only\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:470)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:453)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:945)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:165)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor67.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 379, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/spark.py\", line 36, in map_fn\n    return apply_lfs_to_data_point(*args, lfs=self._lfs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/core.py\", line 83, in apply_lfs_to_data_point\n    y = lf(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 84, in __call__\n    x = self._preprocess_data_point(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 62, in _preprocess_data_point\n    x = preprocessor(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 152, in __call__\n    x_mapped = self._generate_mapped_data_point(x_mapped)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 304, in _generate_mapped_data_point\n    return self._f(x)\n  File \"<ipython-input-61-5106c698ef72>\", line 4, in textblob_sentiment\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1565, in __setattr__\n    raise Exception(\"Row is read-only\")\nException: Row is read-only\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:470)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:453)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:945)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-1d358b16797c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mapplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkLFApplier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msample_L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevelopment_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/spark.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, data_points)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mapply_lfs_to_data_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzipWithIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_from_row_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 19.0 failed 1 times, most recent failure: Lost task 2.0 in stage 19.0 (TID 78, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 379, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/spark.py\", line 36, in map_fn\n    return apply_lfs_to_data_point(*args, lfs=self._lfs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/core.py\", line 83, in apply_lfs_to_data_point\n    y = lf(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 84, in __call__\n    x = self._preprocess_data_point(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 62, in _preprocess_data_point\n    x = preprocessor(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 152, in __call__\n    x_mapped = self._generate_mapped_data_point(x_mapped)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 304, in _generate_mapped_data_point\n    return self._f(x)\n  File \"<ipython-input-61-5106c698ef72>\", line 4, in textblob_sentiment\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1565, in __setattr__\n    raise Exception(\"Row is read-only\")\nException: Row is read-only\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:470)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:453)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:945)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:165)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor67.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 379, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/spark.py\", line 36, in map_fn\n    return apply_lfs_to_data_point(*args, lfs=self._lfs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/core.py\", line 83, in apply_lfs_to_data_point\n    y = lf(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 84, in __call__\n    x = self._preprocess_data_point(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 62, in _preprocess_data_point\n    x = preprocessor(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 152, in __call__\n    x_mapped = self._generate_mapped_data_point(x_mapped)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 304, in _generate_mapped_data_point\n    return self._f(x)\n  File \"<ipython-input-61-5106c698ef72>\", line 4, in textblob_sentiment\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1565, in __setattr__\n    raise Exception(\"Row is read-only\")\nException: Row is read-only\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:470)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:453)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:945)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "lfs = [textblob_polarity, textblob_subjectivity]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LFAnalysis(L_sample, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
