{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/faculty/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "# Download files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Parental Content Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Director Wayne Wang proves with Maid in Manha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>the lack of dramatic development doesn't leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A riveting documentary that explains educatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The problem with The Informant!, aside from t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Freshness                                             Review\n",
       "0          0                            Parental Content Review\n",
       "1          1   Director Wayne Wang proves with Maid in Manha...\n",
       "2          0   the lack of dramatic development doesn't leav...\n",
       "3          1   A riveting documentary that explains educatio...\n",
       "4          0   The problem with The Informant!, aside from t..."
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data (Pandas)\n",
    "\n",
    "reviews = pd.read_csv('/project/weaklabel_sampledata.csv', header=0, encoding='unicode_escape', nrows=1000)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107726"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Pandas)\n",
    "\n",
    "# Turn 'Review' column into list\n",
    "reviews_list = reviews['Review'].astype(str).tolist()\n",
    "\n",
    "# Clean the data and tokenize it\n",
    "reviews_string = ''\n",
    "reviews_string = reviews_string.join(reviews_list).lower()\n",
    "reviews_string = reviews_string.replace('\"', '').replace(\"'\", '').replace('\\n','').replace(',','').replace('[','').replace(']','')\n",
    "tokens = reviews_string.split()\n",
    "\n",
    "# Check how many words we have\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60915"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Remove punctuation from each token\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "tokens = [w.translate(table) for w in tokens]\n",
    "\n",
    "# Remove remaining tokens that are not alphabetic\n",
    "tokens = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "# Filter out stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [w for w in tokens if not w in stop_words]\n",
    "\n",
    "# Filter out short tokens\n",
    "tokens = [word for word in tokens if len(word) > 1]\n",
    "\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "\n",
    "# Count how many times each word appears\n",
    "count = Counter(tokens).items()\n",
    "sorted_count = sorted(count, key = itemgetter(1))\n",
    "sorted_count.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import LancasterStemmer\n",
    "\n",
    "# initialize Lancaster Stemmer\n",
    "LS = LancasterStemmer()\n",
    "lemmatized = []\n",
    "for l in tokens: lemmatized.append(LS.stem(l))\n",
    "\n",
    "# Count how many times each word appears\n",
    "count = Counter(lemmatized).items()\n",
    "sorted_count = sorted(count, key = itemgetter(1))\n",
    "sorted_count.reverse()\n",
    "\n",
    "# Select 5000 most frequent words\n",
    "top5000 = [i[0] for i in sorted_count[:5000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "review = []\n",
    "\n",
    "for sentence in reviews_list :\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.replace('.', '').replace(\"'\", '').replace('\\n','').replace(',','')\n",
    "    token_sentence = word_tokenize(sentence)\n",
    "    \n",
    "    token_words = []\n",
    "    for token_word in token_sentence:\n",
    "        token_word = LS.stem(token_word)\n",
    "        token_words.append(token_word)\n",
    "    review.append(token_words)\n",
    "len(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>movy</th>\n",
       "      <th>lik</th>\n",
       "      <th>on</th>\n",
       "      <th>mak</th>\n",
       "      <th>act</th>\n",
       "      <th>ev</th>\n",
       "      <th>story</th>\n",
       "      <th>charact</th>\n",
       "      <th>feel</th>\n",
       "      <th>...</th>\n",
       "      <th>showbo</th>\n",
       "      <th>scrappy</th>\n",
       "      <th>withinsweaty</th>\n",
       "      <th>minorkey</th>\n",
       "      <th>glasss</th>\n",
       "      <th>medy</th>\n",
       "      <th>yel</th>\n",
       "      <th>denzel</th>\n",
       "      <th>behemo</th>\n",
       "      <th>freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      film  movy  lik  on  mak  act  ev  story  charact  feel  ...  showbo  \\\n",
       "0        0     0    0   0    0    0   0      0        0     0  ...       0   \n",
       "1        0     1    0   0    0    0   1      0        0     1  ...       0   \n",
       "2        0     0    0   0    0    1   0      0        0     0  ...       0   \n",
       "3        0     0    0   0    0    0   0      0        0     0  ...       0   \n",
       "4        0     0    0   0    0    0   0      0        0     0  ...       0   \n",
       "...    ...   ...  ...  ..  ...  ...  ..    ...      ...   ...  ...     ...   \n",
       "4995     0     1    0   0    0    0   0      0        0     0  ...       0   \n",
       "4996     0     0    0   0    0    0   0      0        0     0  ...       0   \n",
       "4997     1     0    0   0    0    0   0      0        0     0  ...       0   \n",
       "4998     0     0    0   0    0    0   0      0        0     0  ...       0   \n",
       "4999     0     0    0   0    0    0   0      0        0     0  ...       0   \n",
       "\n",
       "      scrappy  withinsweaty  minorkey  glasss  medy  yel  denzel  behemo  \\\n",
       "0           0             0         0       0     0    0       0       0   \n",
       "1           0             0         0       0     0    0       0       0   \n",
       "2           0             0         0       0     0    0       0       0   \n",
       "3           0             0         0       0     0    0       0       0   \n",
       "4           0             0         0       0     0    0       0       0   \n",
       "...       ...           ...       ...     ...   ...  ...     ...     ...   \n",
       "4995        0             0         0       0     0    0       0       0   \n",
       "4996        0             0         0       0     0    0       0       0   \n",
       "4997        0             0         0       0     0    0       0       0   \n",
       "4998        0             0         0       0     0    0       0       0   \n",
       "4999        0             0         0       0     0    0       0       0   \n",
       "\n",
       "      freshness  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "4995          1  \n",
       "4996          0  \n",
       "4997          0  \n",
       "4998          0  \n",
       "4999          0  \n",
       "\n",
       "[5000 rows x 5001 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Pandas)\n",
    "\n",
    "word_matrix = []\n",
    "\n",
    "for i in review: word_matrix.append([1 if j in i else 0 for j in top5000])\n",
    "features = pd.DataFrame(word_matrix, columns = top5000, index = reviews.index)\n",
    "features['freshness']=reviews['Freshness']\n",
    "\n",
    "# Sanity Check\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 500 points : 172, performance 65.60%\n",
      "Number of mislabeled points out of a total 500 points : 156, performance 68.80%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train, test = train_test_split(features, test_size = 0.1)\n",
    "\n",
    "cols = train.columns[:-1]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "gnb = MultinomialNB()\n",
    "\n",
    "models = [lr,gnb]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(train[cols], train['freshness'])\n",
    "    y_pred = model.predict(test[cols])\n",
    "\n",
    "    print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "          .format(test.shape[0], (test[\"freshness\"] != y_pred).sum(),\n",
    "                  100*(1-(test[\"freshness\"] != y_pred).sum()/test.shape[0]))\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 500 points : 153, performance 69.40%\n",
      "Number of mislabeled points out of a total 500 points : 148, performance 70.40%\n"
     ]
    }
   ],
   "source": [
    "# Read the data (Pandas)\n",
    "reviews = pd.read_csv('/project/weaklabel_sampledata.csv', header=0, encoding='unicode_escape', nrows=5000)\n",
    "\n",
    "# Turn 'Review' column into list\n",
    "reviews_list = reviews['Review'].astype(str).tolist()\n",
    "\n",
    "# Clean the data and tokenize it\n",
    "reviews_string = ''\n",
    "reviews_string = reviews_string.join(reviews_list).lower()\n",
    "reviews_string = reviews_string.replace('\"', '').replace(\"'\", '').replace('\\n','').replace(',','').replace('[','').replace(']','')\n",
    "tokens = reviews_string.split()\n",
    "\n",
    "# Remove punctuation from each token\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "tokens = [w.translate(table) for w in tokens]\n",
    "\n",
    "# Remove remaining tokens that are not alphabetic\n",
    "tokens = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "# Filter out stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [w for w in tokens if not w in stop_words]\n",
    "\n",
    "# Filter out short tokens\n",
    "tokens = [word for word in tokens if len(word) > 1]\n",
    "\n",
    "# Count how many times each word appears\n",
    "count = Counter(tokens).items()\n",
    "sorted_count = sorted(count, key = itemgetter(1))\n",
    "sorted_count.reverse()\n",
    "\n",
    "lemmatized = []\n",
    "for l in tokens: lemmatized.append(LS.stem(l))\n",
    "\n",
    "# Count how many times each word appears\n",
    "count = Counter(lemmatized).items()\n",
    "sorted_count = sorted(count, key = itemgetter(1))\n",
    "sorted_count.reverse()\n",
    "\n",
    "# Select 5000 most frequent words\n",
    "top5000 = [i[0] for i in sorted_count[:5000]]\n",
    "\n",
    "review = []\n",
    "\n",
    "for sentence in reviews_list :\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.replace('.', '').replace(\"'\", '').replace('\\n','').replace(',','')\n",
    "    token_sentence = word_tokenize(sentence)\n",
    "    \n",
    "    token_words = []\n",
    "    for token_word in token_sentence:\n",
    "        token_word = LS.stem(token_word)\n",
    "        token_words.append(token_word)\n",
    "    review.append(token_words)\n",
    "\n",
    "word_matrix = []\n",
    "\n",
    "for i in review: word_matrix.append([1 if j in i else 0 for j in top5000])\n",
    "features = pd.DataFrame(word_matrix, columns = top5000, index = reviews.index)\n",
    "features['freshness']=reviews['Freshness']    \n",
    "\n",
    "train, test = train_test_split(features, test_size = 0.1)\n",
    "\n",
    "cols = train.columns[:-1]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "gnb = MultinomialNB()\n",
    "\n",
    "models = [lr,gnb]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(train[cols], train['freshness'])\n",
    "    y_pred = model.predict(test[cols])\n",
    "\n",
    "    print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "          .format(test.shape[0], (test[\"freshness\"] != y_pred).sum(),\n",
    "                  100*(1-(test[\"freshness\"] != y_pred).sum()/test.shape[0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
