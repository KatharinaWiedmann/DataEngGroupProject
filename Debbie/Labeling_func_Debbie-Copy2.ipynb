{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas==0.24.2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-0.24.2              |   py36he6710b0_0         8.5 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.5 MB\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  pandas                               1.0.1-py36h0573a6f_0 --> 0.24.2-py36he6710b0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pandas-0.24.2        | 8.5 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pandas==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    bottleneck-1.3.2           |   py36heb32a55_0         124 KB\n",
      "    dask-2.11.0                |             py_0          13 KB\n",
      "    dask-core-2.11.0           |             py_0         565 KB\n",
      "    distributed-2.11.0         |           py36_0         943 KB\n",
      "    gunicorn-20.0.4            |           py36_0         125 KB\n",
      "    hypothesis-5.5.4           |             py_0         227 KB\n",
      "    nb_conda_kernels-2.2.2     |           py36_0          39 KB\n",
      "    ncurses-6.2                |       he6710b0_0         1.1 MB\n",
      "    plotly-4.5.2               |             py_0         1.6 MB\n",
      "    pytest-astropy-0.8.0       |             py_0           9 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.7 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  bottleneck                           1.3.1-py36hdd07704_0 --> 1.3.2-py36heb32a55_0\n",
      "  dask                                          2.10.1-py_0 --> 2.11.0-py_0\n",
      "  dask-core                                     2.10.1-py_0 --> 2.11.0-py_0\n",
      "  distributed        pkgs/main/noarch::distributed-2.10.0-~ --> pkgs/main/linux-64::distributed-2.11.0-py36_0\n",
      "  gunicorn                                    19.9.0-py36_0 --> 20.0.4-py36_0\n",
      "  hypothesis                                     5.4.1-py_0 --> 5.5.4-py_0\n",
      "  nb_conda_kernels                             2.1.1-py36_1 --> 2.2.2-py36_0\n",
      "  ncurses                                    6.1-he6710b0_1 --> 6.2-he6710b0_0\n",
      "  pandas                              0.24.2-py36he6710b0_0 --> 1.0.1-py36h0573a6f_0\n",
      "  plotly                                         4.4.1-py_0 --> 4.5.2-py_0\n",
      "  pytest-astropy                                 0.7.0-py_0 --> 0.8.0-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "plotly-4.5.2         | 1.6 MB    | ##################################### | 100% \n",
      "ncurses-6.2          | 1.1 MB    | ##################################### | 100% \n",
      "dask-2.11.0          | 13 KB     | ##################################### | 100% \n",
      "pytest-astropy-0.8.0 | 9 KB      | ##################################### | 100% \n",
      "bottleneck-1.3.2     | 124 KB    | ##################################### | 100% \n",
      "gunicorn-20.0.4      | 125 KB    | ##################################### | 100% \n",
      "hypothesis-5.5.4     | 227 KB    | ##################################### | 100% \n",
      "nb_conda_kernels-2.2 | 39 KB     | ##################################### | 100% \n",
      "dask-core-2.11.0     | 565 KB    | ##################################### | 100% \n",
      "distributed-2.11.0   | 943 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: / b'+ /opt/anaconda/envs/Python3/bin/python -m nb_conda_kernels.install --disable --prefix=/opt/anaconda/envs/Python3\\nDisabling nb_conda_kernels...\\nDisabled nb_conda_kernels\\n'\n",
      "/ b'Enabling nb_conda_kernels...\\nStatus: enabled\\n'\n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda upgrade --all -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - snorkel==0.9.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
      "    certifi-2019.11.28         |           py36_0         149 KB  conda-forge\n",
      "    cudatoolkit-10.0.130       |                0       261.2 MB\n",
      "    cudnn-7.6.5                |       cuda10.0_0       165.0 MB\n",
      "    libprotobuf-3.11.3         |       h8b12597_0         4.8 MB  conda-forge\n",
      "    ninja-1.10.0               |       hc9558a2_0         1.9 MB  conda-forge\n",
      "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
      "    pandas-0.24.2              |   py36hb3f55d8_1        11.1 MB  conda-forge\n",
      "    protobuf-3.11.3            |   py36he1b5a44_0         696 KB  conda-forge\n",
      "    pytorch-1.1.0              |cuda100py36he554f03_0       196.2 MB\n",
      "    scikit-learn-0.21.3        |   py36hd81dba3_0         5.0 MB\n",
      "    snorkel-0.9.0              |             py_0          85 KB  conda-forge\n",
      "    tensorboardx-1.9           |             py_0          75 KB  conda-forge\n",
      "    tqdm-4.43.0                |             py_0          47 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       648.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0\n",
      "  cudnn              pkgs/main/linux-64::cudnn-7.6.5-cuda10.0_0\n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.11.3-h8b12597_0\n",
      "  ninja              conda-forge/linux-64::ninja-1.10.0-hc9558a2_0\n",
      "  protobuf           conda-forge/linux-64::protobuf-3.11.3-py36he1b5a44_0\n",
      "  pytorch            pkgs/main/linux-64::pytorch-1.1.0-cuda100py36he554f03_0\n",
      "  snorkel            conda-forge/noarch::snorkel-0.9.0-py_0\n",
      "  tensorboardx       conda-forge/noarch::tensorboardx-1.9-py_0\n",
      "  tqdm               conda-forge/noarch::tqdm-4.43.0-py_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
      "  certifi                                         pkgs/main --> conda-forge\n",
      "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
      "  pandas             pkgs/main::pandas-1.0.1-py36h0573a6f_0 --> conda-forge::pandas-0.24.2-py36hb3f55d8_1\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  scikit-learn                        0.22.1-py36hd81dba3_0 --> 0.21.3-py36hd81dba3_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "tqdm-4.43.0          | 47 KB     | ##################################### | 100% \n",
      "openssl-1.1.1d       | 2.1 MB    | ##################################### | 100% \n",
      "cudatoolkit-10.0.130 | 261.2 MB  | ##################################### | 100% \n",
      "ninja-1.10.0         | 1.9 MB    | ##################################### | 100% \n",
      "scikit-learn-0.21.3  | 5.0 MB    | ##################################### | 100% \n",
      "libprotobuf-3.11.3   | 4.8 MB    | ##################################### | 100% \n",
      "tensorboardx-1.9     | 75 KB     | ##################################### | 100% \n",
      "cudnn-7.6.5          | 165.0 MB  | ##################################### | 100% \n",
      "protobuf-3.11.3      | 696 KB    | ##################################### | 100% \n",
      "pandas-0.24.2        | 11.1 MB   | ##################################### | 100% \n",
      "pytorch-1.1.0        | 196.2 MB  | ##################################### | 100% \n",
      "snorkel-0.9.0        | 85 KB     | ##################################### | 100% \n",
      "ca-certificates-2019 | 145 KB    | ##################################### | 100% \n",
      "certifi-2019.11.28   | 149 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install snorkel==0.9.0 -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - textblob\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    textblob-0.15.3            |             py_0         595 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         595 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  textblob           conda-forge/noarch::textblob-0.15.3-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "textblob-0.15.3      | 595 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier,LabelModel\n",
    "from snorkel.preprocess import preprocessor\n",
    "import nltk\n",
    "from itertools import repeat\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41101</td>\n",
       "      <td>Vibrant, visually exciting and emotionally res...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18134</td>\n",
       "      <td>An enjoyable campy bad film.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3215</td>\n",
       "      <td>This brave little film, a tale of an uncompreh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222</td>\n",
       "      <td>Excellent, accurate, smart analysis of sexual ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181403</td>\n",
       "      <td>a merger of Cold Weather's mumblenoir and LA ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3906</td>\n",
       "      <td>This film is basically a well-meaning fable th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1563</td>\n",
       "      <td>The chemistry between the main trio is very pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>654</td>\n",
       "      <td>An engaging personal essay documentary about n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>428143</td>\n",
       "      <td>If nothing else, The Wolverine proves how cha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20559</td>\n",
       "      <td>A noirish thriller with experimental trimmings...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12812</td>\n",
       "      <td>I think it should be considered child abuse to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1607</td>\n",
       "      <td>Rattlesnake gives you what you expect, but not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15576</td>\n",
       "      <td>Mesmerizing filmmaking.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3950</td>\n",
       "      <td>There is plenty of heat to burn and brand from...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>429447</td>\n",
       "      <td>Divining the bond between mothers and daughte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>445756</td>\n",
       "      <td>The big-screen Scooby makes the silly origina...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3024</td>\n",
       "      <td>Moments of hilarity remain, and the picture is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>183799</td>\n",
       "      <td>[Mitchell's] giddy, knowingly camp direction ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9121</td>\n",
       "      <td>A slight improvement upon its 2010 predecessor.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>265736</td>\n",
       "      <td>Loving is a dogged work, not a great or inspi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>307</td>\n",
       "      <td>Any attempt to explore the impact of the opioi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3722</td>\n",
       "      <td>Noisy and unfunny, still pawing at the same ob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>31256</td>\n",
       "      <td>One of Luis Bunuel's greatest and funniest fil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30934</td>\n",
       "      <td>A romantic comedy that is neither romantic nor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>156665</td>\n",
       "      <td>After 90 years and more than 50 films, Wajda ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>105011</td>\n",
       "      <td>Planted smack-dab in the middle of the Januar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6718</td>\n",
       "      <td>Uneven and slightly muddled futuristic horror ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42756</td>\n",
       "      <td>The teenager's impressionistic headspace is hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>104108</td>\n",
       "      <td>Not a smidgen of originality!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>211268</td>\n",
       "      <td>Shamelessly low-brow, reaching a beer-fueled ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>221256</td>\n",
       "      <td>Inflammatory talk-show host Morton Downey Jr....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>352910</td>\n",
       "      <td>A nicely played family entertainment with per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>2411</td>\n",
       "      <td>Despite the potential double product cross mar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>91877</td>\n",
       "      <td>The plot details are ingeniously handled and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>435</td>\n",
       "      <td>Biopic about artist's relationship with his bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>596</td>\n",
       "      <td>JOKER is a beautiful but simplistically shallo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>21078</td>\n",
       "      <td>Cage acts, at times, as though his head is abo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>3509</td>\n",
       "      <td>Despite its clumsy first-act emphasis on expos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>2809</td>\n",
       "      <td>A wondrous, moodily self-involved piece of wor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>12028</td>\n",
       "      <td>A touching, humorous and enjoyable film.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>108781</td>\n",
       "      <td>The visuals, the structure, the use of sound ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>1458</td>\n",
       "      <td>The tone veers haphazardly from tense, high-st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>471</td>\n",
       "      <td>Even if it is presented with luminous visuals ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>19063</td>\n",
       "      <td>A fervent, sweet-natured tragic romance.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>815</td>\n",
       "      <td>Whilst occasionally letting her film down with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>9730</td>\n",
       "      <td>About as moving as a month-old Kleenex.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>5218</td>\n",
       "      <td>The film comes off like a short story expanded...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2776</td>\n",
       "      <td>It all adds up to an offbeat, unusual horror f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1768</td>\n",
       "      <td>Unfortunately, the filmmakers were overzealous...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>1904</td>\n",
       "      <td>Zombie has gifts; he really does. And I'd rath...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>963</td>\n",
       "      <td>Arriving following the backlash transgender dr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>43820</td>\n",
       "      <td>If you can grin and bear [certain] eye-rolling...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>46516</td>\n",
       "      <td>Fincher, the director of Seven, leads you down...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>4852</td>\n",
       "      <td>Murder Mystery is a lively hodgepodge.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>3678</td>\n",
       "      <td>Thankfully, the voice cast is packed with pops...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>40066</td>\n",
       "      <td>A film that adults can enjoy on their own, wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>276091</td>\n",
       "      <td>It seems Greenberg can write and directly aut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>29835</td>\n",
       "      <td>An excellent top notch gem with beautiful dire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>10645</td>\n",
       "      <td>Fifty years on, we're still living with the af...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>5117</td>\n",
       "      <td>A film like this -- with a large cast and a b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             Review  Freshness\n",
       "0         41101  Vibrant, visually exciting and emotionally res...          1\n",
       "1         18134                       An enjoyable campy bad film.          0\n",
       "2          3215  This brave little film, a tale of an uncompreh...          1\n",
       "3           222  Excellent, accurate, smart analysis of sexual ...          1\n",
       "4        181403   a merger of Cold Weather's mumblenoir and LA ...          1\n",
       "5          3906  This film is basically a well-meaning fable th...          1\n",
       "6          1563  The chemistry between the main trio is very pl...          1\n",
       "7           654  An engaging personal essay documentary about n...          1\n",
       "8        428143   If nothing else, The Wolverine proves how cha...          1\n",
       "9         20559  A noirish thriller with experimental trimmings...          1\n",
       "10        12812  I think it should be considered child abuse to...          0\n",
       "11         1607  Rattlesnake gives you what you expect, but not...          0\n",
       "12        15576                            Mesmerizing filmmaking.          1\n",
       "13         3950  There is plenty of heat to burn and brand from...          0\n",
       "14       429447   Divining the bond between mothers and daughte...          1\n",
       "15       445756   The big-screen Scooby makes the silly origina...          0\n",
       "16         3024  Moments of hilarity remain, and the picture is...          1\n",
       "17       183799   [Mitchell's] giddy, knowingly camp direction ...          1\n",
       "18         9121    A slight improvement upon its 2010 predecessor.          0\n",
       "19       265736   Loving is a dogged work, not a great or inspi...          0\n",
       "20          307  Any attempt to explore the impact of the opioi...          0\n",
       "21         3722  Noisy and unfunny, still pawing at the same ob...          0\n",
       "22        31256  One of Luis Bunuel's greatest and funniest fil...          1\n",
       "23        30934  A romantic comedy that is neither romantic nor...          0\n",
       "24       156665   After 90 years and more than 50 films, Wajda ...          1\n",
       "25       105011   Planted smack-dab in the middle of the Januar...          0\n",
       "26         6718  Uneven and slightly muddled futuristic horror ...          0\n",
       "27        42756  The teenager's impressionistic headspace is hi...          1\n",
       "28       104108                      Not a smidgen of originality!          0\n",
       "29       211268   Shamelessly low-brow, reaching a beer-fueled ...          1\n",
       "..          ...                                                ...        ...\n",
       "970      221256   Inflammatory talk-show host Morton Downey Jr....          0\n",
       "971      352910   A nicely played family entertainment with per...          1\n",
       "972        2411  Despite the potential double product cross mar...          1\n",
       "973       91877   The plot details are ingeniously handled and ...          1\n",
       "974         435  Biopic about artist's relationship with his bu...          0\n",
       "975         596  JOKER is a beautiful but simplistically shallo...          0\n",
       "976       21078  Cage acts, at times, as though his head is abo...          0\n",
       "977        3509  Despite its clumsy first-act emphasis on expos...          1\n",
       "978        2809  A wondrous, moodily self-involved piece of wor...          1\n",
       "979       12028           A touching, humorous and enjoyable film.          1\n",
       "980      108781   The visuals, the structure, the use of sound ...          1\n",
       "981        1458  The tone veers haphazardly from tense, high-st...          0\n",
       "982         471  Even if it is presented with luminous visuals ...          1\n",
       "983       19063           A fervent, sweet-natured tragic romance.          1\n",
       "984         815  Whilst occasionally letting her film down with...          1\n",
       "985        9730            About as moving as a month-old Kleenex.          0\n",
       "986        5218  The film comes off like a short story expanded...          0\n",
       "987        2776  It all adds up to an offbeat, unusual horror f...          1\n",
       "988        1768  Unfortunately, the filmmakers were overzealous...          0\n",
       "989        1904  Zombie has gifts; he really does. And I'd rath...          0\n",
       "990         963  Arriving following the backlash transgender dr...          1\n",
       "991       43820  If you can grin and bear [certain] eye-rolling...          1\n",
       "992       46516  Fincher, the director of Seven, leads you down...          1\n",
       "993        4852             Murder Mystery is a lively hodgepodge.          1\n",
       "994        3678  Thankfully, the voice cast is packed with pops...          0\n",
       "995       40066   A film that adults can enjoy on their own, wi...          1\n",
       "996      276091   It seems Greenberg can write and directly aut...          0\n",
       "997       29835  An excellent top notch gem with beautiful dire...          1\n",
       "998       10645  Fifty years on, we're still living with the af...          0\n",
       "999        5117   A film like this -- with a large cast and a b...          0\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split = pd.read_csv('/project/development_split.csv')\n",
    "development_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid off index column \n",
    "development_split= pd.DataFrame(development_split, columns = ['Review', 'Freshness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vibrant, visually exciting and emotionally res...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An enjoyable campy bad film.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This brave little film, a tale of an uncompreh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent, accurate, smart analysis of sexual ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a merger of Cold Weather's mumblenoir and LA ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Freshness\n",
       "0  Vibrant, visually exciting and emotionally res...          1\n",
       "1                       An enjoyable campy bad film.          0\n",
       "2  This brave little film, a tale of an uncompreh...          1\n",
       "3  Excellent, accurate, smart analysis of sexual ...          1\n",
       "4   a merger of Cold Weather's mumblenoir and LA ...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into positive and negative reviews: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vibrant, visually exciting and emotionally res...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This brave little film, a tale of an uncompreh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent, accurate, smart analysis of sexual ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a merger of Cold Weather's mumblenoir and LA ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This film is basically a well-meaning fable th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Freshness\n",
       "0  Vibrant, visually exciting and emotionally res...          1\n",
       "2  This brave little film, a tale of an uncompreh...          1\n",
       "3  Excellent, accurate, smart analysis of sexual ...          1\n",
       "4   a merger of Cold Weather's mumblenoir and LA ...          1\n",
       "5  This film is basically a well-meaning fable th...          1"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An enjoyable campy bad film.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I think it should be considered child abuse to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rattlesnake gives you what you expect, but not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>There is plenty of heat to burn and brand from...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The big-screen Scooby makes the silly origina...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Review  Freshness\n",
       "1                        An enjoyable campy bad film.          0\n",
       "10  I think it should be considered child abuse to...          0\n",
       "11  Rattlesnake gives you what you expect, but not...          0\n",
       "13  There is plenty of heat to burn and brand from...          0\n",
       "15   The big-screen Scooby makes the silly origina...          0"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split_fresh = development_split[development_split['Freshness'] == 1]\n",
    "development_split_rotten = development_split[development_split['Freshness'] == 0]\n",
    "development_split_fresh.head()\n",
    "development_split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 570 entries, 0 to 997\n",
      "Data columns (total 2 columns):\n",
      "Review       570 non-null object\n",
      "Freshness    570 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 13.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 430 entries, 1 to 999\n",
      "Data columns (total 2 columns):\n",
      "Review       430 non-null object\n",
      "Freshness    430 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 10.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#508 fresh reviews \n",
    "development_split_fresh.info()\n",
    "#492 rotten reviews \n",
    "development_split_rotten.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. Word occurancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation \n",
    "def remove_punctuation(dataframe):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in dataframe.Review.str.lower():\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    vibrant visually exciting and emotionally reso...\n",
       "1    this brave little film a tale of an uncomprehe...\n",
       "2    excellent accurate smart analysis of sexual ha...\n",
       "3     a merger of cold weathers mumblenoir and la n...\n",
       "4    this film is basically a wellmeaning fable tha...\n",
       "dtype: object"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from fresh reviews & turn into Series\n",
    "split_fresh= pd.Series(remove_punctuation(development_split_fresh))\n",
    "split_fresh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordList = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\\\n",
    "                \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\\\n",
    "                \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\",\\\n",
    "                \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\",\\\n",
    "                \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\",\\\n",
    "                \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\",\\\n",
    "                \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\",\\\n",
    "                \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\\\n",
    "                \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords from fresh\n",
    "\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_fresh.replace(replacements, regex=True, inplace=True)\n",
    "split_fresh.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization and Count again\n",
    "def stem_recount(df):\n",
    "    import pandas as pd\n",
    "    # Lemmatization\n",
    "    from nltk import LancasterStemmer\n",
    "    st = LancasterStemmer()\n",
    "    newdf = df.copy()\n",
    "    for i in range(0,len(df)):\n",
    "        newdf.iloc[i,0] = st.stem(str(df.iloc[i,0])) \n",
    "        # Plz make sure the word column is the first column in df when using this function\n",
    "    \n",
    "    # Recount\n",
    "    duplicate = newdf[newdf.duplicated(['index'])]\n",
    "    # Plz make sure the 'index' is the column name consisting of words\n",
    "    for i in range(0,len(newdf)):\n",
    "        if i >= len(duplicate):\n",
    "            break\n",
    "        if newdf.iloc[i,0] == duplicate.iloc[i,0]:\n",
    "            newdf.iloc[i,1] = newdf.iloc[i,1] + duplicate.iloc[i,1]\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new common_words_fresh_df = common_words_fresh_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movy</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lik</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ev</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fun</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ful</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>much</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comedy</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stil</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mak</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ther</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tim</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>way</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dram</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>work</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>span</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>doesnt</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>review</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>direct</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gre</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>also</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>charact</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>world</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>movy</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>enough</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>best</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>entertain</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>francisco</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>jenkin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>expertlyc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>whal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>apolog</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3719</th>\n",
       "      <td>swept</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>dram</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>off</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>backst</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>pred</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>epoch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>cury</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>wellconceiv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>exact</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>laps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>cue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>invict</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>endear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>mock</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>caron</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>compl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>theyd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>bru</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>superbl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>rest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>fletch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>sorry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>coher</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>frank</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  Occurence good review\n",
       "0            film                     89\n",
       "1            movy                     51\n",
       "2              on                     51\n",
       "3           story                     31\n",
       "4             lik                     29\n",
       "5              ev                     28\n",
       "6             fun                     25\n",
       "7             ful                     24\n",
       "8            much                     23\n",
       "9          comedy                     23\n",
       "10           stil                     21\n",
       "11            mak                     20\n",
       "12           ther                     20\n",
       "13            tim                     20\n",
       "14            way                     20\n",
       "15           dram                     17\n",
       "16           work                     17\n",
       "17           span                     17\n",
       "18         doesnt                     17\n",
       "19         review                     17\n",
       "20         direct                     17\n",
       "21            gre                     17\n",
       "22           good                     17\n",
       "23           also                     17\n",
       "24        charact                     17\n",
       "25          world                     17\n",
       "26           movy                     17\n",
       "27         enough                     17\n",
       "28           best                     16\n",
       "29      entertain                     16\n",
       "...           ...                    ...\n",
       "3714    francisco                      1\n",
       "3715       jenkin                      1\n",
       "3716    expertlyc                      1\n",
       "3717         whal                      1\n",
       "3718       apolog                      1\n",
       "3719        swept                      1\n",
       "3720         dram                      1\n",
       "3721          off                      1\n",
       "3722       backst                      1\n",
       "3723         pred                      1\n",
       "3724        epoch                      1\n",
       "3725         cury                      1\n",
       "3726  wellconceiv                      1\n",
       "3727        exact                      1\n",
       "3728         laps                      1\n",
       "3729          cue                      1\n",
       "3730       invict                      1\n",
       "3731       endear                      1\n",
       "3732         mock                      1\n",
       "3733        caron                      1\n",
       "3734        compl                      1\n",
       "3735        theyd                      1\n",
       "3736            9                      1\n",
       "3737          bru                      1\n",
       "3738      superbl                      1\n",
       "3739         rest                      1\n",
       "3740       fletch                      1\n",
       "3741        sorry                      1\n",
       "3742        coher                      1\n",
       "3743        frank                      1\n",
       "\n",
       "[3744 rows x 2 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_recount(common_words_fresh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get most common words in positive reviews \n",
    "\n",
    "common_words_fresh = split_fresh.str.split(expand=True).stack().value_counts()\n",
    "common_words_fresh_df = pd.DataFrame(common_words_fresh)\n",
    "common_words_fresh_df = common_words_fresh_df.rename({0:'Occurence good review'}, axis='columns')\n",
    "top_common_words_fresh = common_words_fresh_df[common_words_fresh_df['Occurence good review'] >=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theres</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drama</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doesnt</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characters</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enough</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertaining</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turned</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creepy</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offerings</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>role</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>since</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cool</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creates</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scares</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uncomfortable</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humour</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depicts</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>light</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moved</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tell</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friendship</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demands</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delight</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upon</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impressively</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genres</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blanchett</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provides</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remarkably</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youve</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>553 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Occurence good review\n",
       "film                              89\n",
       "movie                             51\n",
       "one                               51\n",
       "story                             31\n",
       "like                              29\n",
       "even                              28\n",
       "fun                               25\n",
       "full                              24\n",
       "much                              23\n",
       "comedy                            23\n",
       "still                             21\n",
       "make                              20\n",
       "theres                            20\n",
       "time                              20\n",
       "way                               20\n",
       "drama                             17\n",
       "work                              17\n",
       "spanish                           17\n",
       "doesnt                            17\n",
       "review                            17\n",
       "director                          17\n",
       "great                             17\n",
       "good                              17\n",
       "also                              17\n",
       "characters                        17\n",
       "world                             17\n",
       "movies                            17\n",
       "enough                            17\n",
       "best                              16\n",
       "entertaining                      16\n",
       "...                              ...\n",
       "turned                             3\n",
       "creepy                             3\n",
       "offerings                          3\n",
       "part                               3\n",
       "role                               3\n",
       "since                              3\n",
       "cool                               3\n",
       "creates                            3\n",
       "scares                             3\n",
       "uncomfortable                      3\n",
       "humour                             3\n",
       "depicts                            3\n",
       "light                              3\n",
       "moved                              3\n",
       "tell                               3\n",
       "friendship                         3\n",
       "wont                               3\n",
       "water                              3\n",
       "demands                            3\n",
       "delight                            3\n",
       "upon                               3\n",
       "impressively                       3\n",
       "genres                             3\n",
       "blanchett                          3\n",
       "green                              3\n",
       "provides                           3\n",
       "remarkably                         3\n",
       "youve                              3\n",
       "special                            3\n",
       "actor                              3\n",
       "\n",
       "[553 rows x 1 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_common_words_fresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          an enjoyable campy bad film\n",
       "1    i think it should be considered child abuse to...\n",
       "2    rattlesnake gives you what you expect but not ...\n",
       "3    there is plenty of heat to burn and brand from...\n",
       "4     the bigscreen scooby makes the silly original...\n",
       "dtype: object"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from rotten & turn into Series\n",
    "split_rotten= pd.Series(remove_punctuation(development_split_rotten))\n",
    "split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords from negative reviews\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_rotten.replace(replacements, regex=True, inplace=True)\n",
    "split_rotten.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization to compare word occurances differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization and Count again\n",
    "def stem_recount(df):\n",
    "    import pandas as pd\n",
    "    # Lemmatization\n",
    "    from nltk import LancasterStemmer\n",
    "    st = LancasterStemmer()\n",
    "    newdf = df.copy()\n",
    "    for i in range(0,len(df)):\n",
    "        newdf.iloc[i,0] = st.stem(str(df.iloc[i,0])) \n",
    "        # Plz make sure the word column is the first column in df when using this function\n",
    "    \n",
    "    # Recount\n",
    "    duplicate = newdf[newdf.duplicated(['index'])]\n",
    "    # Plz make sure the 'index' is the column name consisting of words\n",
    "    for i in range(0,len(newdf)):\n",
    "        if i >= len(duplicate):\n",
    "            break\n",
    "        if newdf.iloc[i,0] == duplicate.iloc[i,0]:\n",
    "            newdf.iloc[i,1] = newdf.iloc[i,1] + duplicate.iloc[i,1]\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_common_words_rotten = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "new_common_words_rotten_df = pd.DataFrame(new_common_words_rotten).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movy</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lik</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>too</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>much</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ev</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>on</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nev</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>charact</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>story</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tim</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>good</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feel</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bad</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feel</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>littl</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>enough</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>doesnt</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mak</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hor</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bet</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>noth</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ful</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>new</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>seem</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ther</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>real</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>film</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>perform</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>stil</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>12andunder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>evint</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>releas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>undercard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>dos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>sitcomlik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>wellworn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>provoc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>hors</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>see</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>build</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>bril</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>spectr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>top</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>tol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>clunky</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>stark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>fourlevel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>season</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>lin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>lit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>everlik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>fac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>sacr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>dissect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>card</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>cov</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>catandm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>lov</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2931 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index   0\n",
       "0           film  62\n",
       "1           movy  50\n",
       "2            lik  33\n",
       "3            too  30\n",
       "4           much  27\n",
       "5             ev  25\n",
       "6             on  25\n",
       "7            nev  23\n",
       "8        charact  23\n",
       "9          story  23\n",
       "10           tim  18\n",
       "11          good  18\n",
       "12          feel  17\n",
       "13           bad  17\n",
       "14          feel  17\n",
       "15         littl  17\n",
       "16        enough  16\n",
       "17        doesnt  16\n",
       "18           mak  16\n",
       "19           hor  14\n",
       "20           bet  13\n",
       "21          noth  13\n",
       "22           ful  13\n",
       "23           new  13\n",
       "24          seem  13\n",
       "25          ther  13\n",
       "26          real  12\n",
       "27          film  12\n",
       "28       perform  12\n",
       "29          stil  12\n",
       "...          ...  ..\n",
       "2901  12andunder   1\n",
       "2902       evint   1\n",
       "2903      releas   1\n",
       "2904   undercard   1\n",
       "2905         dos   1\n",
       "2906   sitcomlik   1\n",
       "2907    wellworn   1\n",
       "2908      provoc   1\n",
       "2909        hors   1\n",
       "2910         see   1\n",
       "2911       build   1\n",
       "2912        bril   1\n",
       "2913      spectr   1\n",
       "2914         top   1\n",
       "2915         tol   1\n",
       "2916      clunky   1\n",
       "2917       stark   1\n",
       "2918   fourlevel   1\n",
       "2919      season   1\n",
       "2920         lin   1\n",
       "2921         lit   1\n",
       "2922     everlik   1\n",
       "2923     correct   1\n",
       "2924         fac   1\n",
       "2925        sacr   1\n",
       "2926     dissect   1\n",
       "2927        card   1\n",
       "2928         cov   1\n",
       "2929     catandm   1\n",
       "2930         lov   1\n",
       "\n",
       "[2931 rows x 2 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_recount(new_common_words_rotten_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get most common words in positive reviews \n",
    "\n",
    "common_words_rotten = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "common_words_rotten_df = pd.DataFrame(common_words_rotten)\n",
    "common_words_rotten_df = common_words_rotten_df.rename({0:'Occurence bad review'}, axis='columns')\n",
    "top_common_words_rotten = common_words_rotten_df[common_words_rotten_df['Occurence bad review'] >=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characters</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feels</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enough</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doesnt</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horror</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nothing</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seems</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theres</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>films</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performances</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thrilling</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solid</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lake</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tone</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nature</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewer</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personality</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carry</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poorly</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stupidity</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lacks</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>involved</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forgettable</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resolution</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>making</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wild</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predecessor</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acting</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suspense</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expect</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>however</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>won</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Occurence bad review\n",
       "film                             62\n",
       "movie                            50\n",
       "like                             33\n",
       "too                              30\n",
       "much                             27\n",
       "even                             25\n",
       "one                              25\n",
       "never                            23\n",
       "characters                       23\n",
       "story                            23\n",
       "time                             18\n",
       "good                             18\n",
       "feel                             17\n",
       "bad                              17\n",
       "feels                            17\n",
       "little                           17\n",
       "enough                           16\n",
       "doesnt                           16\n",
       "make                             16\n",
       "horror                           14\n",
       "better                           13\n",
       "nothing                          13\n",
       "full                             13\n",
       "new                              13\n",
       "seems                            13\n",
       "theres                           13\n",
       "really                           12\n",
       "films                            12\n",
       "performances                     12\n",
       "still                            12\n",
       "...                             ...\n",
       "thrilling                         3\n",
       "complex                           3\n",
       "solid                             3\n",
       "old                               3\n",
       "lake                              3\n",
       "tone                              3\n",
       "nature                            3\n",
       "half                              3\n",
       "viewer                            3\n",
       "personality                       3\n",
       "carry                             3\n",
       "poorly                            3\n",
       "stupidity                         3\n",
       "lacks                             3\n",
       "title                             3\n",
       "involved                          3\n",
       "forgettable                       3\n",
       "resolution                        3\n",
       "making                            3\n",
       "large                             3\n",
       "wild                              3\n",
       "predecessor                       3\n",
       "acting                            3\n",
       "sex                               3\n",
       "wait                              3\n",
       "suspense                          3\n",
       "expect                            3\n",
       "however                           3\n",
       "won                               3\n",
       "entertainment                     3\n",
       "\n",
       "[401 rows x 1 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_common_words_rotten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** EXPLAIN WHY LEMMATIZATION DOES NOT WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison good and bad movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the two lists \n",
    "#--> find out which of the words in the good list only appear in the good movies (and not in the bad movies )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempts before \n",
    "#outer join --> displays words that are only in good reviews and only in bad reviews\n",
    "# top_common_words = pd.concat([top_common_words_fresh, top_common_words_rotten], axis=1)\n",
    "# top_common_words\n",
    "\n",
    "#inner join \n",
    "# top_common_words = pd.merge(top_common_words_fresh, top_common_words_rotten, left_index=True, right_index=True)\n",
    "# top_common_words\n",
    "\n",
    "top_fresh_words_exclusive = top_common_words_fresh.merge(top_common_words_rotten, indicator='i', how='outer', left_index=True,\\\n",
    "                                                         right_index=True).query('i == \"left_only\"').drop('i', 1)\n",
    "\n",
    "top_rotten_words_exclusive = top_common_words_rotten.merge(top_common_words_fresh, indicator='i', how='outer', left_index=True,\\\n",
    "                                                           right_index=True).query('i == \"left_only\"').drop('i', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolutely</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absorbing</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>across</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Occurence good review  Occurence bad review\n",
       "2                             3.0                   NaN\n",
       "absolutely                    4.0                   NaN\n",
       "absorbing                     4.0                   NaN\n",
       "across                        6.0                   NaN\n",
       "actor                         3.0                   NaN"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_fresh_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>achievement</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actually</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adventure</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aimed</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Occurence bad review  Occurence good review\n",
       "achievement                   3.0                    NaN\n",
       "act                           5.0                    NaN\n",
       "actually                      4.0                    NaN\n",
       "adventure                     4.0                    NaN\n",
       "aimed                         3.0                    NaN"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rotten_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " 'absolutely',\n",
       " 'absorbing',\n",
       " 'across',\n",
       " 'actor',\n",
       " 'adam',\n",
       " 'adds',\n",
       " 'air',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'along',\n",
       " 'already',\n",
       " 'always',\n",
       " 'america',\n",
       " 'american',\n",
       " 'among',\n",
       " 'amp',\n",
       " 'amusing',\n",
       " 'anger',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'appeal',\n",
       " 'attention',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'behind',\n",
       " 'believe',\n",
       " 'beyond',\n",
       " 'big',\n",
       " 'blanchett',\n",
       " 'bleak',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'body',\n",
       " 'bond',\n",
       " 'boys',\n",
       " 'breathtaking',\n",
       " 'breathtakingly',\n",
       " 'brilliant',\n",
       " 'burn',\n",
       " 'camera',\n",
       " 'certainly',\n",
       " 'charismatic',\n",
       " 'charm',\n",
       " 'chemistry',\n",
       " 'children',\n",
       " 'classic',\n",
       " 'clearly',\n",
       " 'clever',\n",
       " 'coen',\n",
       " 'color',\n",
       " 'combination',\n",
       " 'comingofage',\n",
       " 'compelling',\n",
       " 'complete',\n",
       " 'confusion',\n",
       " 'cool',\n",
       " 'course',\n",
       " 'creates',\n",
       " 'creating',\n",
       " 'creative',\n",
       " 'creepy',\n",
       " 'dark',\n",
       " 'darkness',\n",
       " 'dead',\n",
       " 'debut',\n",
       " 'deeply',\n",
       " 'delight',\n",
       " 'delightfully',\n",
       " 'deliver',\n",
       " 'delivers',\n",
       " 'demands',\n",
       " 'depicts',\n",
       " 'devil',\n",
       " 'dialogue',\n",
       " 'direction',\n",
       " 'directors',\n",
       " 'disturbing',\n",
       " 'easy',\n",
       " 'effective',\n",
       " 'el',\n",
       " 'elements',\n",
       " 'emotion',\n",
       " 'emotionally',\n",
       " 'emotions',\n",
       " 'engaging',\n",
       " 'enjoyed',\n",
       " 'entertaining',\n",
       " 'entirely',\n",
       " 'epic',\n",
       " 'evil',\n",
       " 'exactly',\n",
       " 'excellent',\n",
       " 'exciting',\n",
       " 'executed',\n",
       " 'extraordinarily',\n",
       " 'extremely',\n",
       " 'fails',\n",
       " 'fan',\n",
       " 'fans',\n",
       " 'fascinating',\n",
       " 'fast',\n",
       " 'features',\n",
       " 'feeling',\n",
       " 'female',\n",
       " 'fiction',\n",
       " 'finds',\n",
       " 'fine',\n",
       " 'flat',\n",
       " 'frame',\n",
       " 'fresh',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'future',\n",
       " 'genres',\n",
       " 'genuine',\n",
       " 'genuinely',\n",
       " 'girls',\n",
       " 'gold',\n",
       " 'greatest',\n",
       " 'green',\n",
       " 'grown',\n",
       " 'guilt',\n",
       " 'happy',\n",
       " 'hasnt',\n",
       " 'heart',\n",
       " 'heartfelt',\n",
       " 'hero',\n",
       " 'highly',\n",
       " 'hilarious',\n",
       " 'historical',\n",
       " 'hits',\n",
       " 'hodgepodge',\n",
       " 'hold',\n",
       " 'hope',\n",
       " 'hours',\n",
       " 'human',\n",
       " 'humanity',\n",
       " 'humour',\n",
       " 'ignore',\n",
       " 'imaginative',\n",
       " 'important',\n",
       " 'impressively',\n",
       " 'inspired',\n",
       " 'inventive',\n",
       " 'investment',\n",
       " 'issues',\n",
       " 'james',\n",
       " 'job',\n",
       " 'journey',\n",
       " 'joy',\n",
       " 'keeps',\n",
       " 'kubricks',\n",
       " 'la',\n",
       " 'lady',\n",
       " 'language',\n",
       " 'leaves',\n",
       " 'left',\n",
       " 'light',\n",
       " 'likable',\n",
       " 'likely',\n",
       " 'logic',\n",
       " 'long',\n",
       " 'looks',\n",
       " 'lovely',\n",
       " 'mad',\n",
       " 'main',\n",
       " 'male',\n",
       " 'manages',\n",
       " 'masterpiece',\n",
       " 'mean',\n",
       " 'meaning',\n",
       " 'means',\n",
       " 'men',\n",
       " 'michael',\n",
       " 'mind',\n",
       " 'minute',\n",
       " 'modern',\n",
       " 'monster',\n",
       " 'monsters',\n",
       " 'morgan',\n",
       " 'motion',\n",
       " 'moved',\n",
       " 'moving',\n",
       " 'mr',\n",
       " 'mystery',\n",
       " 'netflixs',\n",
       " 'novel',\n",
       " 'obsession',\n",
       " 'occasionally',\n",
       " 'ode',\n",
       " 'offerings',\n",
       " 'offers',\n",
       " 'oldfashioned',\n",
       " 'park',\n",
       " 'part',\n",
       " 'parts',\n",
       " 'perfect',\n",
       " 'perfectly',\n",
       " 'performers',\n",
       " 'period',\n",
       " 'piece',\n",
       " 'pieces',\n",
       " 'played',\n",
       " 'pleasant',\n",
       " 'please',\n",
       " 'plenty',\n",
       " 'poignant',\n",
       " 'portrait',\n",
       " 'portrayal',\n",
       " 'positive',\n",
       " 'potent',\n",
       " 'power',\n",
       " 'powerful',\n",
       " 'promise',\n",
       " 'proves',\n",
       " 'provides',\n",
       " 'pure',\n",
       " 'questions',\n",
       " 'quiet',\n",
       " 'reach',\n",
       " 'ready',\n",
       " 'reason',\n",
       " 'relationships',\n",
       " 'remarkably',\n",
       " 'reminder',\n",
       " 'resonant',\n",
       " 'rewarding',\n",
       " 'right',\n",
       " 'rings',\n",
       " 'road',\n",
       " 'rock',\n",
       " 'role',\n",
       " 'romp',\n",
       " 'room',\n",
       " 'said',\n",
       " 'satisfying',\n",
       " 'saved',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'school',\n",
       " 'science',\n",
       " 'screen',\n",
       " 'secret',\n",
       " 'sequences',\n",
       " 'shadow',\n",
       " 'shame',\n",
       " 'shows',\n",
       " 'simple',\n",
       " 'simply',\n",
       " 'since',\n",
       " 'sit',\n",
       " 'size',\n",
       " 'slight',\n",
       " 'slow',\n",
       " 'slowly',\n",
       " 'small',\n",
       " 'somewhat',\n",
       " 'sort',\n",
       " 'sorts',\n",
       " 'sound',\n",
       " 'spite',\n",
       " 'stars',\n",
       " 'starts',\n",
       " 'straightforward',\n",
       " 'strange',\n",
       " 'street',\n",
       " 'structure',\n",
       " 'success',\n",
       " 'superb',\n",
       " 'sure',\n",
       " 'surprising',\n",
       " 'sweet',\n",
       " 'taking',\n",
       " 'target',\n",
       " 'tastes',\n",
       " 'teenage',\n",
       " 'tell',\n",
       " 'tension',\n",
       " 'terrific',\n",
       " 'thanks',\n",
       " 'thoughtful',\n",
       " 'thoughtprovoking',\n",
       " 'throughout',\n",
       " 'together',\n",
       " 'told',\n",
       " 'top',\n",
       " 'touching',\n",
       " 'toward',\n",
       " 'trilogy',\n",
       " 'turn',\n",
       " 'turned',\n",
       " 'turns',\n",
       " 'twilight',\n",
       " 'uncomfortable',\n",
       " 'unexpected',\n",
       " 'unlike',\n",
       " 'unusual',\n",
       " 'uses',\n",
       " 'version',\n",
       " 'viewing',\n",
       " 'violence',\n",
       " 'visual',\n",
       " 'visually',\n",
       " 'voice',\n",
       " 'warm',\n",
       " 'water',\n",
       " 'whole',\n",
       " 'winning',\n",
       " 'wit',\n",
       " 'woman',\n",
       " 'women',\n",
       " 'wonderful',\n",
       " 'wont',\n",
       " 'working',\n",
       " 'writer',\n",
       " 'y',\n",
       " 'year',\n",
       " 'young',\n",
       " 'youve']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only positive words \n",
    "top_fresh_words_exclusive_list = top_fresh_words_exclusive['Occurence good review'].index.tolist()\n",
    "top_fresh_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beautiful',\n",
       " 'best',\n",
       " 'comic',\n",
       " 'compelling',\n",
       " 'emotional',\n",
       " 'entertaining',\n",
       " 'family',\n",
       " 'fans',\n",
       " 'fun',\n",
       " 'game',\n",
       " 'high',\n",
       " 'humor',\n",
       " 'kind',\n",
       " 'new',\n",
       " 'powerful',\n",
       " 'satisfying',\n",
       " 'script',\n",
       " 'simple',\n",
       " 'true']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_fresh_words_exclusive = ['beautiful',\n",
    " 'best',\n",
    " 'comic',\n",
    " 'compelling',\n",
    " 'emotional',\n",
    " 'entertaining',\n",
    " 'family',\n",
    " 'fans',\n",
    " 'fun',\n",
    " 'game',\n",
    " 'high',\n",
    " 'humor',\n",
    " 'kind',\n",
    " 'new',\n",
    " 'powerful',\n",
    " 'satisfying',\n",
    " 'script',\n",
    " 'simple',\n",
    " 'true']\n",
    "\n",
    "top_fresh_words_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['achievement',\n",
       " 'act',\n",
       " 'actually',\n",
       " 'adventure',\n",
       " 'aimed',\n",
       " 'anyone',\n",
       " 'around',\n",
       " 'badly',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'belief',\n",
       " 'blow',\n",
       " 'boring',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'care',\n",
       " 'carry',\n",
       " 'case',\n",
       " 'central',\n",
       " 'check',\n",
       " 'child',\n",
       " 'choices',\n",
       " 'clear',\n",
       " 'clichés',\n",
       " 'coming',\n",
       " 'competent',\n",
       " 'complex',\n",
       " 'concept',\n",
       " 'consider',\n",
       " 'core',\n",
       " 'corporate',\n",
       " 'credit',\n",
       " 'day',\n",
       " 'deadly',\n",
       " 'deserve',\n",
       " 'didnt',\n",
       " 'different',\n",
       " 'disappointing',\n",
       " 'dog',\n",
       " 'done',\n",
       " 'dull',\n",
       " 'earnest',\n",
       " 'efforts',\n",
       " 'empty',\n",
       " 'end',\n",
       " 'eventually',\n",
       " 'everything',\n",
       " 'execution',\n",
       " 'expect',\n",
       " 'fail',\n",
       " 'falls',\n",
       " 'fantastic',\n",
       " 'filmmaking',\n",
       " 'finish',\n",
       " 'five',\n",
       " 'forgettable',\n",
       " 'four',\n",
       " 'franchise',\n",
       " 'games',\n",
       " 'generic',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'given',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'groundbreaking',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'half',\n",
       " 'head',\n",
       " 'hes',\n",
       " 'hollow',\n",
       " 'house',\n",
       " 'however',\n",
       " 'idea',\n",
       " 'ideas',\n",
       " 'im',\n",
       " 'involved',\n",
       " 'jokes',\n",
       " 'jones',\n",
       " 'jump',\n",
       " 'justice',\n",
       " 'kids',\n",
       " 'knows',\n",
       " 'lack',\n",
       " 'lacks',\n",
       " 'lake',\n",
       " 'land',\n",
       " 'large',\n",
       " 'lead',\n",
       " 'least',\n",
       " 'level',\n",
       " 'lifeless',\n",
       " 'ludicrous',\n",
       " 'mark',\n",
       " 'maybe',\n",
       " 'melodrama',\n",
       " 'merely',\n",
       " 'mess',\n",
       " 'momentum',\n",
       " 'mostly',\n",
       " 'must',\n",
       " 'nasty',\n",
       " 'near',\n",
       " 'neither',\n",
       " 'offensive',\n",
       " 'oh',\n",
       " 'opportunity',\n",
       " 'oscar',\n",
       " 'overcome',\n",
       " 'overly',\n",
       " 'particular',\n",
       " 'personality',\n",
       " 'points',\n",
       " 'poorly',\n",
       " 'potential',\n",
       " 'predecessor',\n",
       " 'predictable',\n",
       " 'premise',\n",
       " 'problem',\n",
       " 'promising',\n",
       " 'put',\n",
       " 'quality',\n",
       " 'quickly',\n",
       " 'resolution',\n",
       " 'ridiculous',\n",
       " 'romance',\n",
       " 'sad',\n",
       " 'save',\n",
       " 'saving',\n",
       " 'scifi',\n",
       " 'score',\n",
       " 'seeing',\n",
       " 'seemed',\n",
       " 'sell',\n",
       " 'series',\n",
       " 'serious',\n",
       " 'sex',\n",
       " 'shallow',\n",
       " 'shock',\n",
       " 'short',\n",
       " 'someone',\n",
       " 'sounds',\n",
       " 'standards',\n",
       " 'studio',\n",
       " 'stupidity',\n",
       " 'style',\n",
       " 'subject',\n",
       " 'teen',\n",
       " 'terrible',\n",
       " 'thrilling',\n",
       " 'times',\n",
       " 'tired',\n",
       " 'tone',\n",
       " 'tries',\n",
       " 'truth',\n",
       " 'uneven',\n",
       " 'unfortunately',\n",
       " 'violent',\n",
       " 'vision',\n",
       " 'wait',\n",
       " 'whos',\n",
       " 'win',\n",
       " 'won',\n",
       " 'worst',\n",
       " 'written',\n",
       " 'youd',\n",
       " 'youll',\n",
       " 'zero']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only negative words \n",
    "top_rotten_words_exclusive_list = top_rotten_words_exclusive['Occurence bad review'].index.tolist()\n",
    "top_rotten_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_rotten_words_exclusive = [\n",
    " 'bad',\n",
    " 'big',\n",
    " 'dead',\n",
    " 'hard',\n",
    " 'interesting',\n",
    " 'jokes',\n",
    " 'latest',\n",
    " 'less',\n",
    " 'lot',\n",
    " 'part',\n",
    " 'plot',\n",
    " 'probably',\n",
    " 'seem',\n",
    " 'seems',\n",
    " 'simply',\n",
    " 'think',\n",
    " 'tries',\n",
    " 'ultimately',\n",
    " 'violence',\n",
    " 'want',\n",
    " 'would',\n",
    " 'yet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad',\n",
       " 'big',\n",
       " 'dead',\n",
       " 'hard',\n",
       " 'interesting',\n",
       " 'jokes',\n",
       " 'latest',\n",
       " 'less',\n",
       " 'lot',\n",
       " 'part',\n",
       " 'plot',\n",
       " 'probably',\n",
       " 'seem',\n",
       " 'seems',\n",
       " 'simply',\n",
       " 'think',\n",
       " 'tries',\n",
       " 'ultimately',\n",
       " 'violence',\n",
       " 'want',\n",
       " 'would',\n",
       " 'yet']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rotten_words_exclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Good / bad exclusive words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "NOTFRESH = 0\n",
    "FRESH = 1\n",
    "\n",
    "@labeling_function()\n",
    "\n",
    "def fresh(x):\n",
    "    for word in top_fresh_words_exclusive:\n",
    "        if word in str(x).lower():\n",
    "            return FRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 188.67it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [fresh]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good coverage:12.5%\n"
     ]
    }
   ],
   "source": [
    "coverage_fresh = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"good coverage:{:.1%}\".format(coverage_fresh[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       j Polarity  Coverage  Overlaps  Conflicts\n",
       "fresh  0      [1]     0.125       0.0        0.0"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=sample_L, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same for rotten: \n",
    "\n",
    "ABSTAIN = -1\n",
    "NOTFRESH = 0\n",
    "FRESH = 1\n",
    "\n",
    "@labeling_function()\n",
    "def rotten(x):\n",
    "    for word in top_rotten_words_exclusive:\n",
    "        if word in str(x).lower():\n",
    "            return NOTFRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 166.71it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [rotten]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten coverage:13.9%\n"
     ]
    }
   ],
   "source": [
    "coverage_rotten = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"rotten coverage:{:.1%}\".format(coverage_rotten[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Word 'too' occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "too                     14"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "too                    30"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'too']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Word 'far' occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "far                      6"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "far                    10"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'far']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. \"n't\" words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word occurancy that with punctuation with it\n",
    "\n",
    "# Word occurrences dataframe for fresh reviews\n",
    "development_split_fresh_1 = development_split_fresh_series.str.split(expand=True).stack().value_counts()\n",
    "development_split_fresh_df = pd.DataFrame(development_split_fresh_1).reset_index()\n",
    "\n",
    "# Words occurrences dataframe for rotten reviews\n",
    "development_split_rotten_1 = development_split_rotten_series.str.split(expand=True).stack().value_counts()\n",
    "development_split_rotten_df = pd.DataFrame(development_split_rotten_1).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Capital words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_capital_letters = [word for word in development_split_fresh_df['index'] if word.isupper()]\n",
    "len(fresh_capital_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'I',\n",
       " 'F.',\n",
       " 'L.',\n",
       " 'MO,',\n",
       " 'TIFF',\n",
       " 'HOBBS',\n",
       " '\"A',\n",
       " 'TV',\n",
       " 'DIY',\n",
       " 'T.',\n",
       " 'STORY',\n",
       " 'ANYA',\n",
       " 'WAITING',\n",
       " '[A]',\n",
       " 'SHAW',\n",
       " '(I',\n",
       " 'LA',\n",
       " 'A.',\n",
       " 'WAY',\n",
       " 'B',\n",
       " 'C+',\n",
       " 'E.',\n",
       " 'II',\n",
       " 'FOR',\n",
       " '2U\"',\n",
       " 'VHS',\n",
       " 'MARRIAGE',\n",
       " 'CGI']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_capital_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_capital_letters = [word for word in development_split_rotten_df['index'] if word.isupper()]\n",
    "len(rotten_capital_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'I',\n",
       " 'PSA',\n",
       " 'IP\"',\n",
       " 'OK,',\n",
       " 'WAY!',\n",
       " 'WILD',\n",
       " 'J.',\n",
       " 'SNL',\n",
       " 'O',\n",
       " 'TV',\n",
       " 'II?',\n",
       " 'ROSE',\n",
       " 'TWO',\n",
       " 'HA!',\n",
       " 'NPR',\n",
       " 'NO',\n",
       " 'CGI',\n",
       " '\"A',\n",
       " 'P.S.',\n",
       " 'DVD',\n",
       " 'FDR',\n",
       " 'JOKER']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_capital_letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Punctuation occurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn review column into Series\n",
    "development_split_fresh_series = pd.Series(development_split_fresh.Review)\n",
    "development_split_rotten_series = pd.Series(development_split_rotten.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive reviews\n",
    "# Split reviews into word\n",
    "fresh_split = pd.Series(development_split_fresh_series.str.split(expand=True).stack())\n",
    "fresh_words = [i for i in fresh_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in fresh_words]\n",
    "fresh_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative reviews\n",
    "# Split reviews into word\n",
    "rotten_split = pd.Series(development_split_rotten_series.str.split(expand=True).stack())\n",
    "rotten_words = [i for i in rotten_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in rotten_words]\n",
    "rotten_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into a flattened list\n",
    "fresh_flattened_list = [y for x in fresh_split_words for y in x]\n",
    "rotten_flattened_list = [y for x in rotten_split_words for y in x]\n",
    "\n",
    "# Count the occurancy of each character\n",
    "# Positive reviews\n",
    "fresh_split_characters = pd.Series(fresh_flattened_list).value_counts()\n",
    "fresh_split_characters = pd.DataFrame(fresh_split_characters).reset_index()\n",
    "\n",
    "# Negative reviews\n",
    "rotten_split_characters = pd.Series(rotten_flattened_list).value_counts()\n",
    "rotten_split_characters = pd.DataFrame(rotten_split_characters).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Question mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>?</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "59     ?  13"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>?</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "47     ?  31"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" Is I Am Number Four going to revolutionize Young Adult fantasy filmmaking? Let's not FOURce the issue.\", \"What is the real crime? Why, beating the audience about the ears, eyes and brain with essentially the same sequence of events from eight characters' points of view, none of which adds much more than deafening hysteria and identically dreadful music.\", 'Reducing the iconic brute to a victim of childhood neglect and abuse? That\\'s not, as The Beginning\\'s tagline boasts, \"The Birth of Fear.\" It\\'s the death of it.']\n"
     ]
    }
   ],
   "source": [
    "list_with_question_mark = []\n",
    "for review in development_split_rotten.Review:\n",
    "    if '?' in review:\n",
    "        list_with_question_mark.append(review)\n",
    "        \n",
    "print (list_with_question_mark[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Exclaimation mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  0\n",
       "77     !  2"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>!</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "57     !  10"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in fresh reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
