{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas==0.24.2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-0.24.2              |   py36he6710b0_0         8.5 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.5 MB\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  pandas                               1.0.1-py36h0573a6f_0 --> 0.24.2-py36he6710b0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pandas-0.24.2        | 8.5 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pandas==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    bottleneck-1.3.2           |   py36heb32a55_0         124 KB\n",
      "    dask-2.11.0                |             py_0          13 KB\n",
      "    dask-core-2.11.0           |             py_0         565 KB\n",
      "    distributed-2.11.0         |           py36_0         943 KB\n",
      "    gunicorn-20.0.4            |           py36_0         125 KB\n",
      "    hypothesis-5.5.4           |             py_0         227 KB\n",
      "    nb_conda_kernels-2.2.2     |           py36_0          39 KB\n",
      "    ncurses-6.2                |       he6710b0_0         1.1 MB\n",
      "    plotly-4.5.2               |             py_0         1.6 MB\n",
      "    pytest-astropy-0.8.0       |             py_0           9 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.7 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  bottleneck                           1.3.1-py36hdd07704_0 --> 1.3.2-py36heb32a55_0\n",
      "  dask                                          2.10.1-py_0 --> 2.11.0-py_0\n",
      "  dask-core                                     2.10.1-py_0 --> 2.11.0-py_0\n",
      "  distributed        pkgs/main/noarch::distributed-2.10.0-~ --> pkgs/main/linux-64::distributed-2.11.0-py36_0\n",
      "  gunicorn                                    19.9.0-py36_0 --> 20.0.4-py36_0\n",
      "  hypothesis                                     5.4.1-py_0 --> 5.5.4-py_0\n",
      "  nb_conda_kernels                             2.1.1-py36_1 --> 2.2.2-py36_0\n",
      "  ncurses                                    6.1-he6710b0_1 --> 6.2-he6710b0_0\n",
      "  pandas                              0.24.2-py36he6710b0_0 --> 1.0.1-py36h0573a6f_0\n",
      "  plotly                                         4.4.1-py_0 --> 4.5.2-py_0\n",
      "  pytest-astropy                                 0.7.0-py_0 --> 0.8.0-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "plotly-4.5.2         | 1.6 MB    | ##################################### | 100% \n",
      "ncurses-6.2          | 1.1 MB    | ##################################### | 100% \n",
      "dask-2.11.0          | 13 KB     | ##################################### | 100% \n",
      "pytest-astropy-0.8.0 | 9 KB      | ##################################### | 100% \n",
      "bottleneck-1.3.2     | 124 KB    | ##################################### | 100% \n",
      "gunicorn-20.0.4      | 125 KB    | ##################################### | 100% \n",
      "hypothesis-5.5.4     | 227 KB    | ##################################### | 100% \n",
      "nb_conda_kernels-2.2 | 39 KB     | ##################################### | 100% \n",
      "dask-core-2.11.0     | 565 KB    | ##################################### | 100% \n",
      "distributed-2.11.0   | 943 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: / b'+ /opt/anaconda/envs/Python3/bin/python -m nb_conda_kernels.install --disable --prefix=/opt/anaconda/envs/Python3\\nDisabling nb_conda_kernels...\\nDisabled nb_conda_kernels\\n'\n",
      "/ b'Enabling nb_conda_kernels...\\nStatus: enabled\\n'\n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda upgrade --all -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - snorkel==0.9.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
      "    certifi-2019.11.28         |           py36_0         149 KB  conda-forge\n",
      "    cudatoolkit-10.0.130       |                0       261.2 MB\n",
      "    cudnn-7.6.5                |       cuda10.0_0       165.0 MB\n",
      "    libprotobuf-3.11.3         |       h8b12597_0         4.8 MB  conda-forge\n",
      "    ninja-1.10.0               |       hc9558a2_0         1.9 MB  conda-forge\n",
      "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
      "    pandas-0.24.2              |   py36hb3f55d8_1        11.1 MB  conda-forge\n",
      "    protobuf-3.11.3            |   py36he1b5a44_0         696 KB  conda-forge\n",
      "    pytorch-1.1.0              |cuda100py36he554f03_0       196.2 MB\n",
      "    scikit-learn-0.21.3        |   py36hd81dba3_0         5.0 MB\n",
      "    snorkel-0.9.0              |             py_0          85 KB  conda-forge\n",
      "    tensorboardx-1.9           |             py_0          75 KB  conda-forge\n",
      "    tqdm-4.43.0                |             py_0          47 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       648.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0\n",
      "  cudnn              pkgs/main/linux-64::cudnn-7.6.5-cuda10.0_0\n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.11.3-h8b12597_0\n",
      "  ninja              conda-forge/linux-64::ninja-1.10.0-hc9558a2_0\n",
      "  protobuf           conda-forge/linux-64::protobuf-3.11.3-py36he1b5a44_0\n",
      "  pytorch            pkgs/main/linux-64::pytorch-1.1.0-cuda100py36he554f03_0\n",
      "  snorkel            conda-forge/noarch::snorkel-0.9.0-py_0\n",
      "  tensorboardx       conda-forge/noarch::tensorboardx-1.9-py_0\n",
      "  tqdm               conda-forge/noarch::tqdm-4.43.0-py_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
      "  certifi                                         pkgs/main --> conda-forge\n",
      "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
      "  pandas             pkgs/main::pandas-1.0.1-py36h0573a6f_0 --> conda-forge::pandas-0.24.2-py36hb3f55d8_1\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  scikit-learn                        0.22.1-py36hd81dba3_0 --> 0.21.3-py36hd81dba3_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "tqdm-4.43.0          | 47 KB     | ##################################### | 100% \n",
      "openssl-1.1.1d       | 2.1 MB    | ##################################### | 100% \n",
      "cudatoolkit-10.0.130 | 261.2 MB  | ##################################### | 100% \n",
      "ninja-1.10.0         | 1.9 MB    | ##################################### | 100% \n",
      "scikit-learn-0.21.3  | 5.0 MB    | ##################################### | 100% \n",
      "libprotobuf-3.11.3   | 4.8 MB    | ##################################### | 100% \n",
      "tensorboardx-1.9     | 75 KB     | ##################################### | 100% \n",
      "cudnn-7.6.5          | 165.0 MB  | ##################################### | 100% \n",
      "protobuf-3.11.3      | 696 KB    | ##################################### | 100% \n",
      "pandas-0.24.2        | 11.1 MB   | ##################################### | 100% \n",
      "pytorch-1.1.0        | 196.2 MB  | ##################################### | 100% \n",
      "snorkel-0.9.0        | 85 KB     | ##################################### | 100% \n",
      "ca-certificates-2019 | 145 KB    | ##################################### | 100% \n",
      "certifi-2019.11.28   | 149 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install snorkel==0.9.0 -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - textblob\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    textblob-0.15.3            |             py_0         595 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         595 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  textblob           conda-forge/noarch::textblob-0.15.3-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "textblob-0.15.3      | 595 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier,LabelModel\n",
    "from snorkel.preprocess import preprocessor\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41101</td>\n",
       "      <td>Vibrant, visually exciting and emotionally res...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18134</td>\n",
       "      <td>An enjoyable campy bad film.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3215</td>\n",
       "      <td>This brave little film, a tale of an uncompreh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222</td>\n",
       "      <td>Excellent, accurate, smart analysis of sexual ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181403</td>\n",
       "      <td>a merger of Cold Weather's mumblenoir and LA ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3906</td>\n",
       "      <td>This film is basically a well-meaning fable th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1563</td>\n",
       "      <td>The chemistry between the main trio is very pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>654</td>\n",
       "      <td>An engaging personal essay documentary about n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>428143</td>\n",
       "      <td>If nothing else, The Wolverine proves how cha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20559</td>\n",
       "      <td>A noirish thriller with experimental trimmings...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12812</td>\n",
       "      <td>I think it should be considered child abuse to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1607</td>\n",
       "      <td>Rattlesnake gives you what you expect, but not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15576</td>\n",
       "      <td>Mesmerizing filmmaking.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3950</td>\n",
       "      <td>There is plenty of heat to burn and brand from...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>429447</td>\n",
       "      <td>Divining the bond between mothers and daughte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>445756</td>\n",
       "      <td>The big-screen Scooby makes the silly origina...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3024</td>\n",
       "      <td>Moments of hilarity remain, and the picture is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>183799</td>\n",
       "      <td>[Mitchell's] giddy, knowingly camp direction ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9121</td>\n",
       "      <td>A slight improvement upon its 2010 predecessor.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>265736</td>\n",
       "      <td>Loving is a dogged work, not a great or inspi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>307</td>\n",
       "      <td>Any attempt to explore the impact of the opioi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3722</td>\n",
       "      <td>Noisy and unfunny, still pawing at the same ob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>31256</td>\n",
       "      <td>One of Luis Bunuel's greatest and funniest fil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30934</td>\n",
       "      <td>A romantic comedy that is neither romantic nor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>156665</td>\n",
       "      <td>After 90 years and more than 50 films, Wajda ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>105011</td>\n",
       "      <td>Planted smack-dab in the middle of the Januar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6718</td>\n",
       "      <td>Uneven and slightly muddled futuristic horror ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42756</td>\n",
       "      <td>The teenager's impressionistic headspace is hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>104108</td>\n",
       "      <td>Not a smidgen of originality!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>211268</td>\n",
       "      <td>Shamelessly low-brow, reaching a beer-fueled ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>221256</td>\n",
       "      <td>Inflammatory talk-show host Morton Downey Jr....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>352910</td>\n",
       "      <td>A nicely played family entertainment with per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>2411</td>\n",
       "      <td>Despite the potential double product cross mar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>91877</td>\n",
       "      <td>The plot details are ingeniously handled and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>435</td>\n",
       "      <td>Biopic about artist's relationship with his bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>596</td>\n",
       "      <td>JOKER is a beautiful but simplistically shallo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>21078</td>\n",
       "      <td>Cage acts, at times, as though his head is abo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>3509</td>\n",
       "      <td>Despite its clumsy first-act emphasis on expos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>2809</td>\n",
       "      <td>A wondrous, moodily self-involved piece of wor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>12028</td>\n",
       "      <td>A touching, humorous and enjoyable film.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>108781</td>\n",
       "      <td>The visuals, the structure, the use of sound ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>1458</td>\n",
       "      <td>The tone veers haphazardly from tense, high-st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>471</td>\n",
       "      <td>Even if it is presented with luminous visuals ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>19063</td>\n",
       "      <td>A fervent, sweet-natured tragic romance.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>815</td>\n",
       "      <td>Whilst occasionally letting her film down with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>9730</td>\n",
       "      <td>About as moving as a month-old Kleenex.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>5218</td>\n",
       "      <td>The film comes off like a short story expanded...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2776</td>\n",
       "      <td>It all adds up to an offbeat, unusual horror f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1768</td>\n",
       "      <td>Unfortunately, the filmmakers were overzealous...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>1904</td>\n",
       "      <td>Zombie has gifts; he really does. And I'd rath...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>963</td>\n",
       "      <td>Arriving following the backlash transgender dr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>43820</td>\n",
       "      <td>If you can grin and bear [certain] eye-rolling...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>46516</td>\n",
       "      <td>Fincher, the director of Seven, leads you down...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>4852</td>\n",
       "      <td>Murder Mystery is a lively hodgepodge.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>3678</td>\n",
       "      <td>Thankfully, the voice cast is packed with pops...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>40066</td>\n",
       "      <td>A film that adults can enjoy on their own, wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>276091</td>\n",
       "      <td>It seems Greenberg can write and directly aut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>29835</td>\n",
       "      <td>An excellent top notch gem with beautiful dire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>10645</td>\n",
       "      <td>Fifty years on, we're still living with the af...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>5117</td>\n",
       "      <td>A film like this -- with a large cast and a b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             Review  Freshness\n",
       "0         41101  Vibrant, visually exciting and emotionally res...          1\n",
       "1         18134                       An enjoyable campy bad film.          0\n",
       "2          3215  This brave little film, a tale of an uncompreh...          1\n",
       "3           222  Excellent, accurate, smart analysis of sexual ...          1\n",
       "4        181403   a merger of Cold Weather's mumblenoir and LA ...          1\n",
       "5          3906  This film is basically a well-meaning fable th...          1\n",
       "6          1563  The chemistry between the main trio is very pl...          1\n",
       "7           654  An engaging personal essay documentary about n...          1\n",
       "8        428143   If nothing else, The Wolverine proves how cha...          1\n",
       "9         20559  A noirish thriller with experimental trimmings...          1\n",
       "10        12812  I think it should be considered child abuse to...          0\n",
       "11         1607  Rattlesnake gives you what you expect, but not...          0\n",
       "12        15576                            Mesmerizing filmmaking.          1\n",
       "13         3950  There is plenty of heat to burn and brand from...          0\n",
       "14       429447   Divining the bond between mothers and daughte...          1\n",
       "15       445756   The big-screen Scooby makes the silly origina...          0\n",
       "16         3024  Moments of hilarity remain, and the picture is...          1\n",
       "17       183799   [Mitchell's] giddy, knowingly camp direction ...          1\n",
       "18         9121    A slight improvement upon its 2010 predecessor.          0\n",
       "19       265736   Loving is a dogged work, not a great or inspi...          0\n",
       "20          307  Any attempt to explore the impact of the opioi...          0\n",
       "21         3722  Noisy and unfunny, still pawing at the same ob...          0\n",
       "22        31256  One of Luis Bunuel's greatest and funniest fil...          1\n",
       "23        30934  A romantic comedy that is neither romantic nor...          0\n",
       "24       156665   After 90 years and more than 50 films, Wajda ...          1\n",
       "25       105011   Planted smack-dab in the middle of the Januar...          0\n",
       "26         6718  Uneven and slightly muddled futuristic horror ...          0\n",
       "27        42756  The teenager's impressionistic headspace is hi...          1\n",
       "28       104108                      Not a smidgen of originality!          0\n",
       "29       211268   Shamelessly low-brow, reaching a beer-fueled ...          1\n",
       "..          ...                                                ...        ...\n",
       "970      221256   Inflammatory talk-show host Morton Downey Jr....          0\n",
       "971      352910   A nicely played family entertainment with per...          1\n",
       "972        2411  Despite the potential double product cross mar...          1\n",
       "973       91877   The plot details are ingeniously handled and ...          1\n",
       "974         435  Biopic about artist's relationship with his bu...          0\n",
       "975         596  JOKER is a beautiful but simplistically shallo...          0\n",
       "976       21078  Cage acts, at times, as though his head is abo...          0\n",
       "977        3509  Despite its clumsy first-act emphasis on expos...          1\n",
       "978        2809  A wondrous, moodily self-involved piece of wor...          1\n",
       "979       12028           A touching, humorous and enjoyable film.          1\n",
       "980      108781   The visuals, the structure, the use of sound ...          1\n",
       "981        1458  The tone veers haphazardly from tense, high-st...          0\n",
       "982         471  Even if it is presented with luminous visuals ...          1\n",
       "983       19063           A fervent, sweet-natured tragic romance.          1\n",
       "984         815  Whilst occasionally letting her film down with...          1\n",
       "985        9730            About as moving as a month-old Kleenex.          0\n",
       "986        5218  The film comes off like a short story expanded...          0\n",
       "987        2776  It all adds up to an offbeat, unusual horror f...          1\n",
       "988        1768  Unfortunately, the filmmakers were overzealous...          0\n",
       "989        1904  Zombie has gifts; he really does. And I'd rath...          0\n",
       "990         963  Arriving following the backlash transgender dr...          1\n",
       "991       43820  If you can grin and bear [certain] eye-rolling...          1\n",
       "992       46516  Fincher, the director of Seven, leads you down...          1\n",
       "993        4852             Murder Mystery is a lively hodgepodge.          1\n",
       "994        3678  Thankfully, the voice cast is packed with pops...          0\n",
       "995       40066   A film that adults can enjoy on their own, wi...          1\n",
       "996      276091   It seems Greenberg can write and directly aut...          0\n",
       "997       29835  An excellent top notch gem with beautiful dire...          1\n",
       "998       10645  Fifty years on, we're still living with the af...          0\n",
       "999        5117   A film like this -- with a large cast and a b...          0\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split = pd.read_csv('/project/development_split.csv')\n",
    "development_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid off index column \n",
    "development_split= pd.DataFrame(development_split, columns = ['Review', 'Freshness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vibrant, visually exciting and emotionally res...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An enjoyable campy bad film.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This brave little film, a tale of an uncompreh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent, accurate, smart analysis of sexual ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a merger of Cold Weather's mumblenoir and LA ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Freshness\n",
       "0  Vibrant, visually exciting and emotionally res...          1\n",
       "1                       An enjoyable campy bad film.          0\n",
       "2  This brave little film, a tale of an uncompreh...          1\n",
       "3  Excellent, accurate, smart analysis of sexual ...          1\n",
       "4   a merger of Cold Weather's mumblenoir and LA ...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into positive and negative reviews: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vibrant, visually exciting and emotionally res...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This brave little film, a tale of an uncompreh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent, accurate, smart analysis of sexual ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a merger of Cold Weather's mumblenoir and LA ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This film is basically a well-meaning fable th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The chemistry between the main trio is very pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>An engaging personal essay documentary about n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If nothing else, The Wolverine proves how cha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A noirish thriller with experimental trimmings...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mesmerizing filmmaking.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Divining the bond between mothers and daughte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Moments of hilarity remain, and the picture is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[Mitchell's] giddy, knowingly camp direction ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>One of Luis Bunuel's greatest and funniest fil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>After 90 years and more than 50 films, Wajda ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The teenager's impressionistic headspace is hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Shamelessly low-brow, reaching a beer-fueled ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\"One\" isn't out for blood, electing to care fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\"Inherit the Viper\" isn't surprising, but it's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Mr. Irving remains a disturbingly facile spin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>If the historical context for black anger is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>It's very interesting, amusing, with a few hic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Isn't It Romantic is a fun and enjoyable roman...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>If Matchstick Men isn't the classic con The St...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Martel creates a cinema of dialectical tensio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A movie about teenage taggers in the Bronx sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Still one of the creepiest, scariest, most sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Jamie Bell gives a pulsating performance in Sk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>What could have been a feeble attempt to ride ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Despite its drawbacks, Ladies in Black is a fu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Superman II is a marvelous toy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>So well-cast, well-acted and tactful it become...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>You've seen haunted houses and medical horror ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>\"Katie Says Goodbye\" is nearly 90 minutes of t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>a delightfully warm-hearted look at the joys a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Its racial aspects make for uncomfortable view...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>The stylized acting requires Min-hee Kim as L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>Tune out the dreck and there are enough laughs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>It is quiet, restrained, unfussy, and has, at ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>'Saint Laurent' imagines the life of the influ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>With disorienting camerawork set to synth and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>MARRIAGE STORY breathes life into the hardship...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>The Unauthorized Bash Brothers Experience genu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>A nicely played family entertainment with per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Despite the potential double product cross mar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>The plot details are ingeniously handled and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>Despite its clumsy first-act emphasis on expos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>A wondrous, moodily self-involved piece of wor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>A touching, humorous and enjoyable film.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>The visuals, the structure, the use of sound ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Even if it is presented with luminous visuals ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>A fervent, sweet-natured tragic romance.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Whilst occasionally letting her film down with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>It all adds up to an offbeat, unusual horror f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Arriving following the backlash transgender dr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>If you can grin and bear [certain] eye-rolling...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Fincher, the director of Seven, leads you down...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Murder Mystery is a lively hodgepodge.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>A film that adults can enjoy on their own, wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>An excellent top notch gem with beautiful dire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Freshness\n",
       "0    Vibrant, visually exciting and emotionally res...          1\n",
       "2    This brave little film, a tale of an uncompreh...          1\n",
       "3    Excellent, accurate, smart analysis of sexual ...          1\n",
       "4     a merger of Cold Weather's mumblenoir and LA ...          1\n",
       "5    This film is basically a well-meaning fable th...          1\n",
       "6    The chemistry between the main trio is very pl...          1\n",
       "7    An engaging personal essay documentary about n...          1\n",
       "8     If nothing else, The Wolverine proves how cha...          1\n",
       "9    A noirish thriller with experimental trimmings...          1\n",
       "12                             Mesmerizing filmmaking.          1\n",
       "14    Divining the bond between mothers and daughte...          1\n",
       "16   Moments of hilarity remain, and the picture is...          1\n",
       "17    [Mitchell's] giddy, knowingly camp direction ...          1\n",
       "22   One of Luis Bunuel's greatest and funniest fil...          1\n",
       "24    After 90 years and more than 50 films, Wajda ...          1\n",
       "27   The teenager's impressionistic headspace is hi...          1\n",
       "29    Shamelessly low-brow, reaching a beer-fueled ...          1\n",
       "32   \"One\" isn't out for blood, electing to care fo...          1\n",
       "33   \"Inherit the Viper\" isn't surprising, but it's...          1\n",
       "34    Mr. Irving remains a disturbingly facile spin...          1\n",
       "36    If the historical context for black anger is ...          1\n",
       "37   It's very interesting, amusing, with a few hic...          1\n",
       "40   Isn't It Romantic is a fun and enjoyable roman...          1\n",
       "42   If Matchstick Men isn't the classic con The St...          1\n",
       "43    Martel creates a cinema of dialectical tensio...          1\n",
       "46    A movie about teenage taggers in the Bronx sh...          1\n",
       "47    Still one of the creepiest, scariest, most sh...          1\n",
       "48   Jamie Bell gives a pulsating performance in Sk...          1\n",
       "50   What could have been a feeble attempt to ride ...          1\n",
       "51   Despite its drawbacks, Ladies in Black is a fu...          1\n",
       "..                                                 ...        ...\n",
       "944                    Superman II is a marvelous toy.          1\n",
       "947  So well-cast, well-acted and tactful it become...          1\n",
       "949  You've seen haunted houses and medical horror ...          1\n",
       "951  \"Katie Says Goodbye\" is nearly 90 minutes of t...          1\n",
       "953  a delightfully warm-hearted look at the joys a...          1\n",
       "959  Its racial aspects make for uncomfortable view...          1\n",
       "962   The stylized acting requires Min-hee Kim as L...          1\n",
       "963  Tune out the dreck and there are enough laughs...          1\n",
       "964  It is quiet, restrained, unfussy, and has, at ...          1\n",
       "965  'Saint Laurent' imagines the life of the influ...          1\n",
       "966  With disorienting camerawork set to synth and ...          1\n",
       "967  MARRIAGE STORY breathes life into the hardship...          1\n",
       "969  The Unauthorized Bash Brothers Experience genu...          1\n",
       "971   A nicely played family entertainment with per...          1\n",
       "972  Despite the potential double product cross mar...          1\n",
       "973   The plot details are ingeniously handled and ...          1\n",
       "977  Despite its clumsy first-act emphasis on expos...          1\n",
       "978  A wondrous, moodily self-involved piece of wor...          1\n",
       "979           A touching, humorous and enjoyable film.          1\n",
       "980   The visuals, the structure, the use of sound ...          1\n",
       "982  Even if it is presented with luminous visuals ...          1\n",
       "983           A fervent, sweet-natured tragic romance.          1\n",
       "984  Whilst occasionally letting her film down with...          1\n",
       "987  It all adds up to an offbeat, unusual horror f...          1\n",
       "990  Arriving following the backlash transgender dr...          1\n",
       "991  If you can grin and bear [certain] eye-rolling...          1\n",
       "992  Fincher, the director of Seven, leads you down...          1\n",
       "993             Murder Mystery is a lively hodgepodge.          1\n",
       "995   A film that adults can enjoy on their own, wi...          1\n",
       "997  An excellent top notch gem with beautiful dire...          1\n",
       "\n",
       "[570 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split_fresh = development_split[development_split['Freshness'] == 1]\n",
    "development_split_rotten = development_split[development_split['Freshness'] == 0]\n",
    "\n",
    "development_split_fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 570 entries, 0 to 997\n",
      "Data columns (total 2 columns):\n",
      "Review       570 non-null object\n",
      "Freshness    570 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 13.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 430 entries, 1 to 999\n",
      "Data columns (total 2 columns):\n",
      "Review       430 non-null object\n",
      "Freshness    430 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 10.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#508 fresh reviews \n",
    "development_split_fresh.info()\n",
    "#492 rotten reviews \n",
    "development_split_rotten.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Punctuation occurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn review column into Series\n",
    "development_split_fresh = pd.Series(development_split_fresh.Review)\n",
    "development_split_rotten = pd.Series(development_split_rotten.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive reviews\n",
    "# Split reviews into word\n",
    "fresh_split = pd.Series(development_split_fresh.str.split(expand=True).stack())\n",
    "fresh_words = [i for i in fresh_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in fresh_words]\n",
    "fresh_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative reviews\n",
    "# Split reviews into word\n",
    "rotten_split = pd.Series(development_split_rotten.str.split(expand=True).stack())\n",
    "rotten_words = [i for i in rotten_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in rotten_words]\n",
    "rotten_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Turn into a flattened list\n",
    "fresh_flattened_list = [y for x in fresh_split_words for y in x]\n",
    "rotten_flattened_list = [y for x in rotten_split_words for y in x]\n",
    "\n",
    "# Count the occurancy of each character\n",
    "# Positive reviews\n",
    "fresh_split_characters = pd.Series(fresh_flattened_list).value_counts()\n",
    "fresh_split_characters = pd.DataFrame(fresh_split_characters).reset_index()\n",
    "\n",
    "# Negative reviews\n",
    "rotten_split_characters = pd.Series(rotten_flattened_list).value_counts()\n",
    "rotten_split_characters = pd.DataFrame(rotten_split_characters).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 Question Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>?</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "59     ?  13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>?</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "47     ?  31"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***WRITEUP FOR REASONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***LABELING FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 Exclaimation mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  0\n",
       "77     !  2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>!</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "57     !  10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***WRITEUP FOR REASONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***LABELING FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Word occurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word occurancy that with punctuation with it\n",
    "\n",
    "# Word occurancies dataframe for fresh reviews\n",
    "development_split_fresh_1 = development_split_fresh.str.split(expand=True).stack().value_counts()\n",
    "development_split_fresh_df = pd.DataFrame(development_split_fresh_1).reset_index()\n",
    "\n",
    "# Words occurancies dataframe for rotten reviews\n",
    "development_split_rotten_1 = development_split_rotten.str.split(expand=True).stack().value_counts()\n",
    "development_split_rotten_df = pd.DataFrame(development_split_rotten_1).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1 word \"too\" occurancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word occuracn\n",
    "development_split_fresh_df[development_split_fresh_df['index'] == '...'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "84   ...  12"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split_fresh_df[development_split_fresh_df['index'] == '...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation \n",
    "def remove_punctuation(dataframe):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in dataframe.Review.str.lower():\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       hall is most impressive here she truly spread...\n",
       "1      the true shock of rolling thunder revue is in ...\n",
       "2       surprisingly this insightful tearjerker is pa...\n",
       "3       the film that made consummate french actor je...\n",
       "4       it is a very compelling movie despite the fac...\n",
       "5       the human centipede by skillful dutch directo...\n",
       "6       dreamworks first animated film to blow disney...\n",
       "7       dark river is a gripping tale of two siblings...\n",
       "8       a perfect example of what is perceived as esc...\n",
       "9       like knightleys performance its not entirely ...\n",
       "10      olnek has crafted a lovely heartwarming piece...\n",
       "11      its not often one can recapture the hope of t...\n",
       "12                             giddy goofy and heartfelt\n",
       "13      comic book films cannot survive on action or ...\n",
       "14      a big broiling stew of complex thought austra...\n",
       "15     a funny believable film about the ability of e...\n",
       "16      queen of katwes a film thats thoughtful charm...\n",
       "17      oddly a sports movie about baseball for egghe...\n",
       "18      in that ambivalence lies the films greatest c...\n",
       "19       you can feel the panic rage and fear of the ...\n",
       "20      no matter what you think about tobacco climat...\n",
       "21      a fitting end to the trilogy and a very good ...\n",
       "22      alice doesnt live here anymore is an american...\n",
       "23     a terrific cast a gloomy tone and a few wellpl...\n",
       "24      this extravagantly foul outlandishly profane ...\n",
       "25      school of rock is the best kind of crowdpleas...\n",
       "26      faults relies on awkward uncertainty to tell ...\n",
       "27      its a witty appealing romantic comedy with a ...\n",
       "28     to call the end result an absolute triumph wou...\n",
       "29     this is a film that gives off a rich aroma of ...\n",
       "                             ...                        \n",
       "478    a hodgepodge of tired jokes that is occasional...\n",
       "479     its a familiar tale but one which feels fresh...\n",
       "480     its a reminder that even for worldfamous icon...\n",
       "481     less a rumination on free will than a potboil...\n",
       "482     a poignant drama about a pianist stricken wit...\n",
       "483     this is a film that is as unexpected as it is...\n",
       "484     the screenplay  which was written by delpy la...\n",
       "485     a movie star who can slip easily into highbea...\n",
       "486     director ognjen glavonics film manages to tra...\n",
       "487     refreshingly unpredictable imaginative funny ...\n",
       "488     casting isaac is chandors masterstroke this i...\n",
       "489     a oneofakind gangster drama with an impeccabl...\n",
       "490     its almost too good to be true that the coen ...\n",
       "491     elvis is clearly used as a metaphor by jareck...\n",
       "492     money for nothing lacks the rush of rush but ...\n",
       "493     i had a lot of fun watching barbra streisand ...\n",
       "494     the result is stunning  both as a narrative f...\n",
       "495     if the two halves dont quite balance nonethel...\n",
       "496     nicely shot by mike gioulakis split keeps us ...\n",
       "497     even at its slowest the insinuating wish you ...\n",
       "498     a messy but affecting parable about fate gend...\n",
       "499     the brilliance of eisenbergs performance is t...\n",
       "500     distraught father avenges his dead son sparki...\n",
       "501     indiana jones and the kingdom of the crystal ...\n",
       "502     in our time the sinister turn of events at th...\n",
       "503     its a pitiless primitive primal world millers...\n",
       "504      despite more catholic imagery than a midperi...\n",
       "505     i dont know if its the best movie of the year...\n",
       "506     less verifiable than implied september dawn n...\n",
       "507     an engaging super hero flick that is both rea...\n",
       "Length: 508, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from fresh & turn into Series\n",
    "split_fresh= pd.Series(remove_punctuation(development_split_fresh))\n",
    "split_fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       hall impressive truly spreads wings gives ful...\n",
       "1       true shock rolling thunder revue good alive d...\n",
       "2       surprisingly insightful tearjerker padded exp...\n",
       "3       film made consummate french actor jean gabin ...\n",
       "4       compelling movie despite fact story hops arou...\n",
       "5       human centipede skillful dutch director tom s...\n",
       "6       dreamworks first animated film blow disney water\n",
       "7       dark river gripping tale two siblings trying ...\n",
       "8                     perfect example perceived escapism\n",
       "9       like knightleys performance entirely successf...\n",
       "10      olnek crafted lovely heartwarming piece remin...\n",
       "11      often one recapture hope youth via charming f...\n",
       "12                                 giddy goofy heartfelt\n",
       "13      comic book films cannot survive action specta...\n",
       "14      big broiling stew complex thought australia d...\n",
       "15      funny believable film ability even damaged im...\n",
       "16      queen katwes film thats thoughtful charming h...\n",
       "17      oddly sports movie baseball eggheads equally ...\n",
       "18      ambivalence lies films greatest conquest mana...\n",
       "19      feel panic rage fear participants theres rare...\n",
       "20      matter think tobacco climate change fire reta...\n",
       "21                         fitting end trilogy good film\n",
       "22      alice doesnt live anymore american comedy sor...\n",
       "23      terrific cast gloomy tone wellplaced little b...\n",
       "24      extravagantly foul outlandishly profane howli...\n",
       "25      school rock best kind crowdpleaser highconcep...\n",
       "26      faults relies awkward uncertainty tell tale i...\n",
       "27      witty appealing romantic comedy surprising ed...\n",
       "28      call end result absolute triumph would underc...\n",
       "29      film gives rich aroma intellectual pursuit ca...\n",
       "                             ...                        \n",
       "478     hodgepodge tired jokes occasionally goosed go...\n",
       "479           familiar tale one feels fresh fascinating \n",
       "480     reminder even worldfamous icons pointless red...\n",
       "481     less rumination free potboiler intellectual p...\n",
       "482     poignant drama pianist stricken als caregiver...\n",
       "483                        film unexpected unforgettable\n",
       "484     screenplay written delpy landeau nahon jitter...\n",
       "485     movie star slip easily highbeam mode smith gi...\n",
       "486     director ognjen glavonics film manages transm...\n",
       "487     refreshingly unpredictable imaginative funny ...\n",
       "488     casting isaac chandors masterstroke starmakin...\n",
       "489     oneofakind gangster drama impeccable performa...\n",
       "490     almost good true coen brothers adapted mccart...\n",
       "491     elvis clearly used metaphor jarecki undeniabl...\n",
       "492     money nothing lacks rush rush still might fin...\n",
       "493     lot fun watching barbra streisand effortlessl...\n",
       "494     result stunning narrative film document place...\n",
       "495     two halves dont quite balance nonetheless loo...\n",
       "496     nicely shot mike gioulakis split keeps us riv...\n",
       "497     even slowest insinuating wish keeps grip like...\n",
       "498     messy affecting parable fate gender identity ...\n",
       "499     brilliance eisenbergs performance even want s...\n",
       "500     distraught father avenges dead son sparking d...\n",
       "501     indiana jones kingdom crystal skull quite bit...\n",
       "502     time sinister turn events denmark corporation...\n",
       "503     pitiless primitive primal world millers built...\n",
       "504     despite catholic imagery midperiod madonna vi...\n",
       "505          dont know best movie year utterly enjoyable\n",
       "506     less verifiable implied september dawn nevert...\n",
       "507        engaging super hero flick realistic fantastic\n",
       "Length: 508, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing stopwords from fresh\n",
    "stopWordList = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\\\n",
    "                \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\\\n",
    "                \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\",\\\n",
    "                \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\",\\\n",
    "                \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\",\\\n",
    "                \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\",\\\n",
    "                \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\",\\\n",
    "                \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\\\n",
    "                \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "\n",
    "from itertools import repeat\n",
    "\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_fresh.replace(replacements, regex=True, inplace=True)\n",
    "split_fresh.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)\n",
    "\n",
    "split_fresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "film           80\n",
       "movie          56\n",
       "one            43\n",
       "like           35\n",
       "story          32\n",
       "good           24\n",
       "even           24\n",
       "full           24\n",
       "us             23\n",
       "performance    22\n",
       "comedy         20\n",
       "little         20\n",
       "time           20\n",
       "best           19\n",
       "review         19\n",
       "love           18\n",
       "great          17\n",
       "fun            17\n",
       "isnt           17\n",
       "doesnt         17\n",
       "much           17\n",
       "spanish        16\n",
       "life           16\n",
       "makes          15\n",
       "well           15\n",
       "films          15\n",
       "bit            15\n",
       "first          14\n",
       "get            14\n",
       "drama          14\n",
       "               ..\n",
       "end             9\n",
       "might           9\n",
       "mind            9\n",
       "script          9\n",
       "powerful        9\n",
       "made            9\n",
       "piece           9\n",
       "feel            9\n",
       "quite           9\n",
       "satisfying      8\n",
       "thriller        8\n",
       "fans            8\n",
       "keeps           8\n",
       "really          8\n",
       "something       8\n",
       "kind            8\n",
       "rather          8\n",
       "world           8\n",
       "new             7\n",
       "experience      7\n",
       "thats           7\n",
       "also            7\n",
       "years           7\n",
       "lives           7\n",
       "go              7\n",
       "home            7\n",
       "dark            7\n",
       "american        7\n",
       "comic           7\n",
       "better          7\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get most common words in positive reviews \n",
    "\n",
    "common_words_fresh = split_fresh.str.split(expand=True).stack().value_counts()\n",
    "top_common_words_fresh = common_words_fresh[0:100]\n",
    "top_common_words_fresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       an extraordinarily silly flamboyantly empty h...\n",
       "1       the ride in due date is not only the usual ra...\n",
       "2        there is a beentheredonethat feeling permeat...\n",
       "3                   vile humorless distasteful sickening\n",
       "4       talberts directing is on par with a prescript...\n",
       "5       after all this we cant help but ask why cheri...\n",
       "6       friday stars several actors who cant act it a...\n",
       "7       a fitfully engrossing and overreaching film t...\n",
       "8       if only we were given a plausible reason for ...\n",
       "9      any film that makes rose byrne unappealing has...\n",
       "10      the first question youll ask yourself while w...\n",
       "11                              so bad on so many levels\n",
       "12      90 minutes of emptyheaded family entertainmen...\n",
       "13      its elements are actually quite typical of a ...\n",
       "14      fizzling at the first and limping to the last...\n",
       "15      mildly amusing but compared to pixars splashy...\n",
       "16      the strangest thing about marvels latest feat...\n",
       "17      a succession of tepid gags tethered by a flim...\n",
       "18      only kristin scott thomas channeling in the l...\n",
       "19                 if only it wasnt such bloody nonsense\n",
       "20      at once a brash strutting pop culture pastich...\n",
       "21      absolutely nothing but a history lesson prese...\n",
       "22      director decubellis is frightfully beholden t...\n",
       "23      this pricey juiceless pulp could never have b...\n",
       "24      great junk like resident evil and passable sc...\n",
       "25      it has cred to spare see producer peter jacks...\n",
       "26      an awkward screenplay by andrew matthews offe...\n",
       "27      the films commanding achievement is probably ...\n",
       "28                                even the title is lazy\n",
       "29      like hepatitis b this is one of those movies ...\n",
       "                             ...                        \n",
       "462     its applauseworthy work and a killer climax b...\n",
       "463     never delivers the big laughs this star in th...\n",
       "464     the films biggest failure isnt accios constan...\n",
       "465     you know there is something wrong with a movi...\n",
       "466     a solidly cast interesting budget concept is ...\n",
       "467     on paper the elements for suspense  sharks ra...\n",
       "468     its not that hell fest is bad its just that i...\n",
       "469     like the directors other film this has no str...\n",
       "470    its not exactly stupid cynical might be a bett...\n",
       "471     peter boyle as the salesman and james caan as...\n",
       "472     every tale in the ballad of buster scruggs ru...\n",
       "473     bitty and frustrating its bigger laughs are s...\n",
       "474     a failed attempt to probe dramatically the in...\n",
       "475                         pretty and pretty heartless \n",
       "476     sure hemsworth looks great and the whales att...\n",
       "477     fie on the diabolical mind that cooked up thi...\n",
       "478     its too bad the actress spends more time jump...\n",
       "479     sgt stubby is an odd lesson in how some stori...\n",
       "480     a great grinding garbage disposal of a movie ...\n",
       "481     the dead tell a tale in the latest pirates of...\n",
       "482     somewhere vin diesel is laughing all the way ...\n",
       "483     the present edition in spite of an impressive...\n",
       "484     we  get zombie diarrhea jokes zombie fat joke...\n",
       "485     i accept that she was popular and am even wil...\n",
       "486           should be avoided like a hound with rabies\n",
       "487     in the battle of the ugly syrup creatures wit...\n",
       "488     though screenwriter jeffrey hatcher has stuff...\n",
       "489     the clichés weigh things down as it becomes a...\n",
       "490     the good heart isnt a good movie but it does ...\n",
       "491     your enjoyment of all this will probably depe...\n",
       "Length: 492, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuation \n",
    "def remove_punctuation(dataframe):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in dataframe.Review.str.lower():\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "#Remove punctuation from rotten & turn into Series\n",
    "split_rotten= pd.Series(remove_punctuation(development_split_rotten))\n",
    "split_rotten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       extraordinarily silly flamboyantly empty hodg...\n",
       "1       ride due date usual raucous escapade car cras...\n",
       "2       beentheredonethat feeling permeating dark sha...\n",
       "3                   vile humorless distasteful sickening\n",
       "4       talberts directing par prescriptiondrug comme...\n",
       "5                 cant help ask cherie anyway shine joan\n",
       "6       friday stars several actors cant act also sta...\n",
       "7       fitfully engrossing overreaching film somehow...\n",
       "8       given plausible reason joseph battling bloodb...\n",
       "9       film makes rose byrne unappealing head well t...\n",
       "10      first question youll ask walking canyons thin...\n",
       "11                                       bad many levels\n",
       "12      90 minutes emptyheaded family entertainment t...\n",
       "13      elements actually quite typical syndicated ca...\n",
       "14      fizzling first limping last misfire obsessed ...\n",
       "15      mildly amusing compared pixars splashy fish s...\n",
       "16      strangest thing marvels latest feature charac...\n",
       "17       succession tepid gags tethered flimsy narrative\n",
       "18      kristin scott thomas channeling loops malcolm...\n",
       "19                                 wasnt bloody nonsense\n",
       "20      brash strutting pop culture pastiche gloomy e...\n",
       "21      absolutely nothing history lesson presented f...\n",
       "22      director decubellis frightfully beholden trop...\n",
       "23      pricey juiceless pulp could never killed crit...\n",
       "24      great junk like resident evil passable schloc...\n",
       "25      cred spare see producer peter jackson writing...\n",
       "26      awkward screenplay andrew matthews offers lit...\n",
       "27      films commanding achievement probably tonal w...\n",
       "28                                       even title lazy\n",
       "29              like hepatitis b one movies hope go away\n",
       "                             ...                        \n",
       "462     applauseworthy work killer climax killer clim...\n",
       "463     never delivers big laughs star promising prem...\n",
       "464     films biggest failure isnt accios constant co...\n",
       "465     know something wrong movie even david cross g...\n",
       "466     solidly cast interesting budget concept absol...\n",
       "467     paper elements suspense sharks rapidly deplet...\n",
       "468     hell fest bad makes feel like could done much...\n",
       "469                like directors film strong role woman\n",
       "470             exactly stupid cynical might better word\n",
       "471     peter boyle salesman james caan swine best ex...\n",
       "472     every tale ballad buster scruggs runs steam r...\n",
       "473     bitty frustrating bigger laughs set offbalanc...\n",
       "474     failed attempt probe dramatically inner worki...\n",
       "475                             pretty pretty heartless \n",
       "476     sure hemsworth looks great whales attacks gen...\n",
       "477           fie diabolical mind cooked plot really fie\n",
       "478     bad actress spends time jumping pose pose ins...\n",
       "479     sgt stubby odd lesson stories even stories wo...\n",
       "480     great grinding garbage disposal movie transfo...\n",
       "481     dead tell tale latest pirates caribbean movie...\n",
       "482               somewhere vin diesel laughing way bank\n",
       "483     present edition spite impressive cast blood b...\n",
       "484     get zombie diarrhea jokes zombie fat jokes zo...\n",
       "485     accept popular even willing take faith work b...\n",
       "486                            avoided like hound rabies\n",
       "487     battle ugly syrup creatures teeth anyone real...\n",
       "488     though screenwriter jeffrey hatcher stuffed p...\n",
       "489     clichés weigh things becomes rescue mission m...\n",
       "490     good heart isnt good movie two good performances\n",
       "491     enjoyment probably depend heavily willingness...\n",
       "Length: 492, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWordList = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "\n",
    "from itertools import repeat\n",
    "\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_rotten.replace(replacements, regex=True, inplace=True)\n",
    "split_rotten.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)\n",
    "\n",
    "split_rotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "film             64\n",
       "movie            62\n",
       "like             46\n",
       "make             29\n",
       "much             27\n",
       "one              26\n",
       "even             24\n",
       "story            20\n",
       "little           19\n",
       "would            19\n",
       "doesnt           18\n",
       "characters       18\n",
       "comedy           18\n",
       "time             18\n",
       "funny            18\n",
       "bad              17\n",
       "first            16\n",
       "cant             15\n",
       "movies           15\n",
       "might            15\n",
       "way              15\n",
       "isnt             14\n",
       "enough           14\n",
       "plot             14\n",
       "never            14\n",
       "feel             13\n",
       "good             13\n",
       "many             12\n",
       "get              12\n",
       "films            12\n",
       "                 ..\n",
       "director          8\n",
       "seems             8\n",
       "probably          8\n",
       "quite             8\n",
       "review            8\n",
       "less              8\n",
       "picture           8\n",
       "pretty            8\n",
       "jokes             8\n",
       "big               8\n",
       "great             8\n",
       "character         8\n",
       "falls             7\n",
       "narrative         7\n",
       "may               7\n",
       "actors            7\n",
       "whole             7\n",
       "tries             7\n",
       "certainly         7\n",
       "hollywood         7\n",
       "entertainment     7\n",
       "violence          7\n",
       "left              7\n",
       "world             7\n",
       "think             7\n",
       "ultimately        7\n",
       "part              7\n",
       "emotional         7\n",
       "dead              7\n",
       "script            7\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get most common words in negative reviews \n",
    "\n",
    "common_words_rotten = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "top_common_words_rotten = common_words_rotten[0:100]\n",
    "top_common_words_rotten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison good and bad movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the two lists \n",
    "#--> find out which of the words in the good list only appear in the good movies (and not in the bad movies )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actors</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anyone</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>certainly</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dead</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>despite</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>falls</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feels</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hollywood</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interesting</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokes</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latest</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>less</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lot</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutes</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narrative</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>picture</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plot</th>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probably</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seem</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seems</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simply</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tries</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ultimately</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violence</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yet</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youre</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Occurence bad review  Occurence good review\n",
       "actors                          7.0                    NaN\n",
       "also                           10.0                    NaN\n",
       "anyone                          9.0                    NaN\n",
       "bad                            17.0                    NaN\n",
       "big                             8.0                    NaN\n",
       "certainly                       7.0                    NaN\n",
       "come                            7.0                    NaN\n",
       "dead                            7.0                    NaN\n",
       "despite                        10.0                    NaN\n",
       "entertainment                   7.0                    NaN\n",
       "falls                           7.0                    NaN\n",
       "feels                           9.0                    NaN\n",
       "hard                            8.0                    NaN\n",
       "hollywood                       7.0                    NaN\n",
       "interesting                     9.0                    NaN\n",
       "jokes                           8.0                    NaN\n",
       "know                           11.0                    NaN\n",
       "latest                          8.0                    NaN\n",
       "left                            7.0                    NaN\n",
       "less                            8.0                    NaN\n",
       "lot                             8.0                    NaN\n",
       "minutes                         9.0                    NaN\n",
       "narrative                       7.0                    NaN\n",
       "part                            7.0                    NaN\n",
       "picture                         8.0                    NaN\n",
       "plot                           14.0                    NaN\n",
       "point                           8.0                    NaN\n",
       "probably                        8.0                    NaN\n",
       "right                           9.0                    NaN\n",
       "seem                            8.0                    NaN\n",
       "seems                           8.0                    NaN\n",
       "simply                          7.0                    NaN\n",
       "thing                           7.0                    NaN\n",
       "think                           7.0                    NaN\n",
       "tries                           7.0                    NaN\n",
       "ultimately                      7.0                    NaN\n",
       "violence                        7.0                    NaN\n",
       "want                            9.0                    NaN\n",
       "would                          19.0                    NaN\n",
       "yet                             9.0                    NaN\n",
       "youre                           9.0                    NaN"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert series back into DF \n",
    "top_common_words_fresh = pd.DataFrame(top_common_words_fresh) \n",
    "top_common_words_fresh = top_common_words_fresh.rename({0:'Occurence good review'}, axis='columns')\n",
    "top_common_words_fresh\n",
    "\n",
    "top_common_words_rotten = pd.DataFrame(top_common_words_rotten) \n",
    "top_common_words_rotten = top_common_words_rotten.rename({0:'Occurence bad review'}, axis='columns')\n",
    "top_common_words_rotten\n",
    "\n",
    "\n",
    "#Attempts before \n",
    "#outer join --> displays words that are only in good reviews and only in bad reviews\n",
    "# top_common_words = pd.concat([top_common_words_fresh, top_common_words_rotten], axis=1)\n",
    "# top_common_words\n",
    "\n",
    "#inner join \n",
    "# top_common_words = pd.merge(top_common_words_fresh, top_common_words_rotten, left_index=True, right_index=True)\n",
    "# top_common_words\n",
    "\n",
    "\n",
    "\n",
    "top_fresh_words_exclusive = top_common_words_fresh.merge(top_common_words_rotten, indicator='i', how='outer', left_index=True, right_index=True).query('i == \"left_only\"').drop('i', 1)\n",
    "top_fresh_words_exclusive\n",
    "\n",
    "top_rotten_words_exclusive = top_common_words_rotten.merge(top_common_words_fresh, indicator='i', how='outer', left_index=True, right_index=True).query('i == \"left_only\"').drop('i', 1)\n",
    "top_rotten_words_exclusive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['almost',\n",
       " 'beautiful',\n",
       " 'best',\n",
       " 'bit',\n",
       " 'comic',\n",
       " 'compelling',\n",
       " 'emotional',\n",
       " 'end',\n",
       " 'entertaining',\n",
       " 'ever',\n",
       " 'everything',\n",
       " 'family',\n",
       " 'fans',\n",
       " 'fun',\n",
       " 'game',\n",
       " 'genre',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'high',\n",
       " 'home',\n",
       " 'humor',\n",
       " 'keeps',\n",
       " 'kind',\n",
       " 'lives',\n",
       " 'love',\n",
       " 'man',\n",
       " 'may',\n",
       " 'mind',\n",
       " 'moments',\n",
       " 'new',\n",
       " 'performance',\n",
       " 'piece',\n",
       " 'powerful',\n",
       " 'satisfying',\n",
       " 'script',\n",
       " 'simple',\n",
       " 'spanish',\n",
       " 'still',\n",
       " 'though',\n",
       " 'true',\n",
       " 'us']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only positive words \n",
    "top_fresh_words_exclusive = top_fresh_words_exclusive['Occurence good review'].index.tolist()\n",
    "top_fresh_words_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beautiful',\n",
       " 'best',\n",
       " 'comic',\n",
       " 'compelling',\n",
       " 'emotional',\n",
       " 'entertaining',\n",
       " 'family',\n",
       " 'fans',\n",
       " 'fun',\n",
       " 'game',\n",
       " 'high',\n",
       " 'humor',\n",
       " 'kind',\n",
       " 'new',\n",
       " 'powerful',\n",
       " 'satisfying',\n",
       " 'script',\n",
       " 'simple',\n",
       " 'true']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_fresh_words_exclusive = ['beautiful',\n",
    " 'best',\n",
    " 'comic',\n",
    " 'compelling',\n",
    " 'emotional',\n",
    " 'entertaining',\n",
    " 'family',\n",
    " 'fans',\n",
    " 'fun',\n",
    " 'game',\n",
    " 'high',\n",
    " 'humor',\n",
    " 'kind',\n",
    " 'new',\n",
    " 'powerful',\n",
    " 'satisfying',\n",
    " 'script',\n",
    " 'simple',\n",
    " 'true']\n",
    "\n",
    "top_fresh_words_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actors',\n",
       " 'also',\n",
       " 'anyone',\n",
       " 'bad',\n",
       " 'big',\n",
       " 'certainly',\n",
       " 'come',\n",
       " 'dead',\n",
       " 'despite',\n",
       " 'entertainment',\n",
       " 'falls',\n",
       " 'feels',\n",
       " 'hard',\n",
       " 'hollywood',\n",
       " 'interesting',\n",
       " 'jokes',\n",
       " 'know',\n",
       " 'latest',\n",
       " 'left',\n",
       " 'less',\n",
       " 'lot',\n",
       " 'minutes',\n",
       " 'narrative',\n",
       " 'part',\n",
       " 'picture',\n",
       " 'plot',\n",
       " 'point',\n",
       " 'probably',\n",
       " 'right',\n",
       " 'seem',\n",
       " 'seems',\n",
       " 'simply',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'tries',\n",
       " 'ultimately',\n",
       " 'violence',\n",
       " 'want',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'youre']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only negative words \n",
    "top_rotten_words_exclusive = top_rotten_words_exclusive['Occurence bad review'].index.tolist()\n",
    "top_rotten_words_exclusive\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_rotten_words_exclusive = [\n",
    " 'bad',\n",
    " 'big',\n",
    " 'dead',\n",
    " 'hard',\n",
    " 'interesting',\n",
    " 'jokes',\n",
    " 'latest',\n",
    " 'less',\n",
    " 'lot',\n",
    " 'part',\n",
    " 'plot',\n",
    " 'probably',\n",
    " 'seem',\n",
    " 'seems',\n",
    " 'simply',\n",
    " 'think',\n",
    " 'tries',\n",
    " 'ultimately',\n",
    " 'violence',\n",
    " 'want',\n",
    " 'would',\n",
    " 'yet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad',\n",
       " 'big',\n",
       " 'dead',\n",
       " 'hard',\n",
       " 'interesting',\n",
       " 'jokes',\n",
       " 'latest',\n",
       " 'less',\n",
       " 'lot',\n",
       " 'part',\n",
       " 'plot',\n",
       " 'probably',\n",
       " 'seem',\n",
       " 'seems',\n",
       " 'simply',\n",
       " 'think',\n",
       " 'tries',\n",
       " 'ultimately',\n",
       " 'violence',\n",
       " 'want',\n",
       " 'would',\n",
       " 'yet']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rotten_words_exclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling functions based on good / bad words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "NOTFRESH = 0\n",
    "FRESH = 1\n",
    "\n",
    "@labeling_function()\n",
    "\n",
    "def fresh(x):\n",
    "    for word in top_fresh_words_exclusive:\n",
    "        if word in str(x).lower():\n",
    "            return FRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 188.67it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [fresh]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good coverage:12.5%\n"
     ]
    }
   ],
   "source": [
    "coverage_fresh = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"good coverage:{:.1%}\".format(coverage_fresh[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       j Polarity  Coverage  Overlaps  Conflicts\n",
       "fresh  0      [1]     0.125       0.0        0.0"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=sample_L, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same for rotten: \n",
    "\n",
    "ABSTAIN = -1\n",
    "NOTFRESH = 0\n",
    "FRESH = 1\n",
    "\n",
    "@labeling_function()\n",
    "def rotten(x):\n",
    "    for word in top_rotten_words_exclusive:\n",
    "        if word in str(x).lower():\n",
    "            return NOTFRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 166.71it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [rotten]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "sample_L = applier.apply(development_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten coverage:13.9%\n"
     ]
    }
   ],
   "source": [
    "coverage_rotten = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"rotten coverage:{:.1%}\".format(coverage_rotten[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
