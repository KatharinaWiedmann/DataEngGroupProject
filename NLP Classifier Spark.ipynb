{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "# Spark Environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import pyspark\n",
    "\n",
    "number_cores = 4\n",
    "memory_gb = 16\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f7cb4357b70>\n"
     ]
    }
   ],
   "source": [
    "# get the context\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "print(spark) \n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/faculty/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/faculty/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langid in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (1.1.6)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from langid) (1.18.1)\r\n"
     ]
    }
   ],
   "source": [
    "# Download files\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "!pip install langid\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import preproc as pp\n",
    "\n",
    "# Register all the functions in Preproc with Spark Context\n",
    "check_lang_udf = udf(pp.check_lang, StringType())\n",
    "remove_stops_udf = udf(pp.remove_stops, StringType())\n",
    "remove_features_udf = udf(pp.remove_features, StringType())\n",
    "tag_and_remove_udf = udf(pp.tag_and_remove, StringType())\n",
    "lemmatize_udf = udf(pp.lemmatize, StringType())\n",
    "check_blanks_udf = udf(pp.check_blanks, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----+\n",
      "|   _c0|                text|label|\n",
      "+------+--------------------+-----+\n",
      "| 10797|Vantage Point is ...|    0|\n",
      "|  1774|The movie makes i...|    0|\n",
      "|  4134|Claire Denis show...|    0|\n",
      "|198598| The plotting is ...|    1|\n",
      "| 52380|The [movie's] two...|    0|\n",
      "| 36362|The first feature...|    1|\n",
      "|  7981|Misses the sense ...|    0|\n",
      "|  6049|The movie is a fa...|    1|\n",
      "| 16033|\"... in the end \"...|    0|\n",
      "| 18483|Follows some of t...|    1|\n",
      "|  4003|\"Even in its most...|    1|\n",
      "|  2486|When the story sh...|    1|\n",
      "| 20840|A thrilling but f...|    1|\n",
      "|  9037|It remains watcha...|    1|\n",
      "|296687| Cusack, who self...|    1|\n",
      "|176770| Knightley's Suga...|    0|\n",
      "|  2104| Best of all is P...|    1|\n",
      "|  2736|None of the filmm...|    0|\n",
      "| 31659|Filled with clich...|    0|\n",
      "| 52054|a cloying mess cr...|    0|\n",
      "+------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1942"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Read the data (Spark)\n",
    "#review_df = sqlContext.read.csv('/project/weaklabel_sampledata.csv', header=True).limit(5000)\n",
    "# TEST\n",
    "review_df = sqlContext.read.csv('/project/development_split.csv', header=True)\n",
    "\n",
    "review_df = review_df.withColumnRenamed('Review','text')\n",
    "review_df = review_df.withColumnRenamed('Freshness','label')\n",
    "review_df = review_df.withColumn(\"label\", review_df[\"label\"].cast(IntegerType()))\n",
    "review_df = review_df.filter(review_df.label. isNotNull())\n",
    "review_df.show()\n",
    "\n",
    "review_df.printSchema()\n",
    "review_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----+\n",
      "|   _c0|                text|label|\n",
      "+------+--------------------+-----+\n",
      "| 10797|vantage point thr...|    0|\n",
      "|  1774|movie make point ...|    0|\n",
      "|  4134|claire denis show...|    0|\n",
      "|198598|plot predictable ...|    1|\n",
      "| 52380|movie half lard e...|    0|\n",
      "| 36362|first feature cre...|    1|\n",
      "|  7981|miss sense menace...|    0|\n",
      "|  6049|movie convince fa...|    1|\n",
      "| 16033|end pink fraudule...|    0|\n",
      "| 18483|follow play drug ...|    1|\n",
      "|  4003|inspired moment s...|    1|\n",
      "|  2486|story shift nashv...|    1|\n",
      "| 20840|thrill frivolous ...|    1|\n",
      "|  9037|remains watchable...|    1|\n",
      "|296687|cusack mock iconi...|    1|\n",
      "|176770|knightley sugar p...|    0|\n",
      "|  2104|best parker perfe...|    1|\n",
      "|  2736|none filmmaking a...|    0|\n",
      "| 31659|fill cliche run m...|    0|\n",
      "| 52054|cloy mess cry rew...|    0|\n",
      "+------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove stop words to reduce dimensionality\n",
    "review_df = review_df.withColumn(\"text\", remove_stops_udf(review_df[\"text\"]))\n",
    "\n",
    "# remove other non essential words\n",
    "review_df = review_df.withColumn(\"text\", remove_features_udf(review_df[\"text\"]))\n",
    "\n",
    "# tag the words remaining and keep only Nouns, Verbs and Adjectives\n",
    "review_df = review_df.withColumn(\"text\", tag_and_remove_udf(review_df[\"text\"]))\n",
    "\n",
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "review_df = review_df.withColumn(\"text\", lemmatize_udf(review_df[\"text\"]))\n",
    "\n",
    "review_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1575"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split training and test data\n",
    "splits = review_df.randomSplit([0.8, 0.2])\n",
    "training_df = splits[0]\n",
    "test_df = splits[1]\n",
    "\n",
    "training_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|                text|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|tough decent bit ...|    0|       1.0|\n",
      "|love simon sad mo...|    1|       1.0|\n",
      "|best representati...|    1|       1.0|\n",
      "|blend social real...|    1|       1.0|\n",
      "|glass castle slap...|    0|       1.0|\n",
      "|better worse movi...|    0|       1.0|\n",
      "|start try replica...|    0|       1.0|\n",
      "|godard set intere...|    0|       1.0|\n",
      "|abundance informa...|    1|       1.0|\n",
      "|sexy thriller sex...|    0|       1.0|\n",
      "|fun watch superhe...|    0|       1.0|\n",
      "|incoherent mishma...|    0|       0.0|\n",
      "|mija journey comp...|    1|       1.0|\n",
      "|bernadette linkla...|    0|       1.0|\n",
      "|fantastic manipul...|    1|       1.0|\n",
      "|sweet natured fla...|    1|       1.0|\n",
      "|video don afraid ...|    1|       1.0|\n",
      "|oooh certain sais...|    1|       1.0|\n",
      "|fable film remind...|    1|       1.0|\n",
      "|tale existential ...|    1|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol='words', outputCol=\"features\")\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")\n",
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nb])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)\n",
    "\n",
    "cvModel = cv.fit(training_df)\n",
    "\n",
    "result = cvModel.transform(test_df)\n",
    "prediction_df = result.select(\"text\", \"label\", \"prediction\")\n",
    "prediction_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6388140161725068"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Evaluate the Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(result, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b25c00c6d882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mhashingTF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHashingTF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0midf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminDocFreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"idf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Read the data (Spark)\n",
    "review_df = sqlContext.read.csv('/project/weaklabel_sampledata.csv', header=True).limit(3000)\n",
    "\n",
    "review_df = review_df.withColumnRenamed('Review','text')\n",
    "review_df = review_df.withColumnRenamed('Freshness','label')\n",
    "review_df = review_df.withColumn(\"label\", review_df[\"label\"].cast(IntegerType()))\n",
    "\n",
    "# remove stop words to reduce dimensionality\n",
    "review_df = review_df.withColumn(\"text\", remove_stops_udf(review_df[\"text\"]))\n",
    "\n",
    "# remove other non essential words\n",
    "review_df = review_df.withColumn(\"text\", remove_features_udf(review_df[\"text\"]))\n",
    "\n",
    "# tag the words remaining and keep only Nouns, Verbs and Adjectives\n",
    "review_df = review_df.withColumn(\"text\", tag_and_remove_udf(review_df[\"text\"]))\n",
    "\n",
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "review_df = review_df.withColumn(\"text\", lemmatize_udf(review_df[\"text\"]))\n",
    "\n",
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol='words', outputCol=\"features\")\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")\n",
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nb])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)\n",
    "\n",
    "cvModel = cv.fit(training_df)\n",
    "\n",
    "result = cvModel.transform(test_df)\n",
    "prediction_df = result.select(\"text\", \"label\", \"prediction\")\n",
    "\n",
    "#Evaluate the accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(result, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    0| Parental Content...|\n",
      "|    1| Director Wayne W...|\n",
      "|    0| the lack of dram...|\n",
      "|    1| A riveting docum...|\n",
      "|    0| The problem with...|\n",
      "|    0| Too tepid and to...|\n",
      "|    0| Bernie lacks the...|\n",
      "|    0| Simply one of th...|\n",
      "|    0|\" More drab \"\"fi\"...|\n",
      "|    1| With its emphasi...|\n",
      "|    1| It's not like ha...|\n",
      "|    1|The intelligently...|\n",
      "|    0| Yields at least ...|\n",
      "|    0| The 'Mr. Holland...|\n",
      "|    0| The Lawnmower Ma...|\n",
      "|    1| The Cell's strik...|\n",
      "|    0| Director Takashi...|\n",
      "|    1| [House of Wax] g...|\n",
      "|    1| treats the audie...|\n",
      "|    1|This movie's calm...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the data (Spark)\n",
    "review_df = sqlContext.read.csv('/project/weaklabel_sampledata.csv', header=True).limit(3000)\n",
    "\n",
    "review_df = review_df.withColumnRenamed('Review','text')\n",
    "review_df = review_df.withColumnRenamed('Freshness','label')\n",
    "review_df = review_df.withColumn(\"label\", review_df[\"label\"].cast(IntegerType()))\n",
    "\n",
    "review_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_csv('/project/12000_predicted_labels.csv')\n",
    "check.to_csv('12000_predicted_labels_v2.csv', sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+---------------+\n",
      "|_c0|Unnamed: 0|              Review|predicted_train|\n",
      "+---+----------+--------------------+---------------+\n",
      "|  0|     25985|The film reveals ...|              1|\n",
      "|  1|    117079| There simply has...|              1|\n",
      "|  2|     85518| There's not much...|              0|\n",
      "|  3|      8395|This ugly and rat...|              0|\n",
      "|  4|      5162|The film's indefi...|              0|\n",
      "|  5|       287|My Dog Skip probe...|              1|\n",
      "|  6|      2263|It makes for good...|              0|\n",
      "|  7|     39415| You may find you...|              0|\n",
      "|  8|     49991|After his first t...|              0|\n",
      "|  9|     39451| This is a compel...|              1|\n",
      "| 10|     41232|\"The World's End ...|              0|\n",
      "| 11|     40089|Old and new, Skyf...|              1|\n",
      "| 12|        75|37 Seconds is ove...|              0|\n",
      "| 13|      5676|Here's something ...|              0|\n",
      "| 14|    365234| The Shack does a...|              1|\n",
      "| 15|     28804|I know, I know, I...|              0|\n",
      "| 16|      4409|a love letter to ...|              1|\n",
      "| 17|      1915|Emanuel is a test...|              0|\n",
      "| 18|     27531|An outstanding mo...|              1|\n",
      "| 19|    391407| On the basketbal...|              0|\n",
      "+---+----------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_df_2 = sqlContext.read.csv('/project/12000_predicted_labels_v2.csv', header=True,sep='~')\n",
    "\n",
    "review_df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    0| Parental Content...|\n",
      "|    1| Director Wayne W...|\n",
      "|    0| the lack of dram...|\n",
      "|    1| A riveting docum...|\n",
      "|    0| The problem with...|\n",
      "|    0| Too tepid and to...|\n",
      "|    0| Bernie lacks the...|\n",
      "|    0| Simply one of th...|\n",
      "|    0|\" More drab \"\"fi\"...|\n",
      "|    1| With its emphasi...|\n",
      "|    1| It's not like ha...|\n",
      "|    1|The intelligently...|\n",
      "|    0| Yields at least ...|\n",
      "|    0| The 'Mr. Holland...|\n",
      "|    0| The Lawnmower Ma...|\n",
      "|    1| The Cell's strik...|\n",
      "|    0| Director Takashi...|\n",
      "|    1| [House of Wax] g...|\n",
      "|    1| treats the audie...|\n",
      "|    1|This movie's calm...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38994"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.show()\n",
    "review_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    0| Parental Content...|\n",
      "|    1| Director Wayne W...|\n",
      "|    0| the lack of dram...|\n",
      "|    1| A riveting docum...|\n",
      "|    0| The problem with...|\n",
      "|    0| Too tepid and to...|\n",
      "|    0| Bernie lacks the...|\n",
      "|    0| Simply one of th...|\n",
      "|    0|\" More drab \"\"fi\"...|\n",
      "|    1| With its emphasi...|\n",
      "|    1| It's not like ha...|\n",
      "|    1|The intelligently...|\n",
      "|    0| Yields at least ...|\n",
      "|    0| The 'Mr. Holland...|\n",
      "|    0| The Lawnmower Ma...|\n",
      "|    1| The Cell's strik...|\n",
      "|    0| Director Takashi...|\n",
      "|    1| [House of Wax] g...|\n",
      "|    1| treats the audie...|\n",
      "|    1|This movie's calm...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50992"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data (Spark)\n",
    "review_df_2000 = review_df\n",
    "review_df_12000 = sqlContext.read.csv('/project/12000_predicted_labels_v2.csv', header=True,sep='~')\n",
    "\n",
    "# Remove Null\n",
    "review_df_12000 = review_df_12000.filter(review_df_12000.predicted_train.isNotNull())\n",
    "\n",
    "review_df_12000 = review_df_12000.withColumnRenamed('Review','text')\n",
    "review_df_12000 = review_df_12000.withColumnRenamed('predicted_train','label')\n",
    "review_df_12000 = review_df_12000.withColumn(\"label\", review_df_12000[\"label\"].cast(IntegerType()))\n",
    "\n",
    "# Combine with review_df with 2000 labels\n",
    "review_df_combined = review_df.union(review_df_12000.select(['label','text']))\n",
    "\n",
    "review_df_combined.show()\n",
    "review_df_combined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words to reduce dimensionality\n",
    "review_df = review_df.withColumn(\"text\", remove_stops_udf(review_df[\"text\"]))\n",
    "\n",
    "# remove other non essential words\n",
    "review_df = review_df.withColumn(\"text\", remove_features_udf(review_df[\"text\"]))\n",
    "\n",
    "# tag the words remaining and keep only Nouns, Verbs and Adjectives\n",
    "review_df = review_df.withColumn(\"text\", tag_and_remove_udf(review_df[\"text\"]))\n",
    "\n",
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "review_df = review_df.withColumn(\"text\", lemmatize_udf(review_df[\"text\"]))\n",
    "\n",
    "training_df = review_df\n",
    "\n",
    "training_df.show()\n",
    "training_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
