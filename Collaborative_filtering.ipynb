{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Collaborative_filtering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KatharinaWiedmann/DataEngGroupProject/blob/master/Collaborative_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7wUqfSl2VmcX"
      },
      "source": [
        "# Using ALS with Spark \n",
        "\n",
        "This basic Recommender System will use the Spark ALS and explore the effects of outcome of a cross-validation on the dataset. \n",
        "This Notebook requires the Movielens dataset to be present in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NvDz4AgvNm9",
        "colab_type": "code",
        "outputId": "e666faec-7336-437f-b6c7-8a74a5fe50ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "#from other notebook \n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "\n",
        "!pip install pyspark\n",
        "!pip install altair"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (2.4.5)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.7)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair) (0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from altair) (0.25.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from altair) (1.18.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair) (0.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair) (2.11.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair) (2.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->altair) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEIHscAnvkBh",
        "colab_type": "code",
        "outputId": "88266730-138d-4653-b05e-8c2e4952114d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#from other notebook \n",
        "import pyspark\n",
        "# get a spark context\n",
        "sc = pyspark.SparkContext.getOrCreate()\n",
        "print(sc)\n",
        "# get the context\n",
        "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
        "print(spark)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SparkContext master=local[*] appName=pyspark-shell>\n",
            "<pyspark.sql.session.SparkSession object at 0x7fca8c97dc18>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN1h8_rvCg_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhbRbBLCWD1h",
        "colab_type": "code",
        "outputId": "20485a6a-a72e-47b8-fffc-34a35c3b6344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "from google.colab import files\n",
        "!ls -l\n",
        "#!rm spark-2.4.4-bin-hadoop2.7.tgz.1\n",
        "\n",
        "!echo $JAVA_HOME/bin\n",
        "!export PATH=$PATH:$JAVA_HOME/bin\n",
        "!echo $PATH"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 681276\n",
            "drwx------  4 root root      4096 Mar 19 12:45 drive\n",
            "drwxr-xr-x  1 root root      4096 Mar  3 18:11 sample_data\n",
            "drwxr-xr-x 13 1000 1000      4096 Feb  2 19:47 spark-2.4.5-bin-hadoop2.7\n",
            "-rw-r--r--  1 root root 232530699 Feb  2 20:27 spark-2.4.5-bin-hadoop2.7.tgz\n",
            "-rw-r--r--  1 root root 232530699 Feb  2 20:27 spark-2.4.5-bin-hadoop2.7.tgz.1\n",
            "-rw-r--r--  1 root root 232530699 Feb  2 20:27 spark-2.4.5-bin-hadoop2.7.tgz.2\n",
            "drwxr-xr-x  2 root root      4096 Mar 19 13:11 spark-warehouse\n",
            "/usr/lib/jvm/java-8-openjdk-amd64/bin\n",
            "/tensorflow-1.15.0/python3.6/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xaKVofYd95G",
        "colab_type": "text"
      },
      "source": [
        "check versions and dependencies, this may change with changes to Colab and Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocjx7B2EXPL3",
        "colab_type": "code",
        "outputId": "7437234f-96d6-4032-e535-5fcc9ccd9af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!java -version\n",
        "!python --version\n",
        "!ls /usr/lib/jvm/\n",
        "!echo $JAVA_HOME\n",
        "spark.version\n",
        "!ls /content\n",
        "!echo $PATH"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.6\" 2020-01-14\n",
            "OpenJDK Runtime Environment (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1, mixed mode, sharing)\n",
            "Python 3.6.9\n",
            "default-java\t\t   java-11-openjdk-amd64     java-8-openjdk-amd64\n",
            "java-1.11.0-openjdk-amd64  java-1.8.0-openjdk-amd64\n",
            "/usr/lib/jvm/java-8-openjdk-amd64\n",
            "drive\t\t\t   spark-2.4.5-bin-hadoop2.7.tgz    spark-warehouse\n",
            "sample_data\t\t   spark-2.4.5-bin-hadoop2.7.tgz.1\n",
            "spark-2.4.5-bin-hadoop2.7  spark-2.4.5-bin-hadoop2.7.tgz.2\n",
            "/tensorflow-1.15.0/python3.6/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Da0U58DFVmcb"
      },
      "source": [
        "## Step 1 - Load the Data\n",
        "Read the data, split into tokens and create a structured DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zE39AsRoVmcf",
        "outputId": "47a52f70-d6c6-4e2b-c995-4d17b99cd696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType\n",
        "# the imports are used creating the data frame\n",
        "\n",
        "#for ratings \n",
        "\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate() # create a SparkSession \n",
        "# this gets us an RDD. (could also be done with RDD.textFile in this case)\n",
        "lines = spark.read.text(\"/content/drive/My Drive/Colab Notebooks/data/movielens/u.data\").rdd\n",
        "# now split the lines at the '\\t'\n",
        "parts = lines.map(lambda row: row.value.split(\"\\t\"))\n",
        "\n",
        "parts.collect()\n",
        "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
        "                                     rating=float(p[2]), timestamp=int(p[3])))\n",
        "ratings = spark.createDataFrame(ratingsRDD)\n",
        "ratings.createOrReplaceTempView('ratings') # register the DataFrame so that we can use it with Spark SQL.\n",
        "\n",
        "#this is the whole data frame \n",
        "ratings.show(20)\n",
        "\n",
        "(training, test) = ratings.randomSplit([0.8, 0.2]) # split into test and training set\n",
        "training.printSchema() # just for testing, should show the four columns\n",
        "print(training.count()) # just for testing, should be around 1200\n",
        "\n",
        "\n",
        "# #This is the training data \n",
        "# training.show()\n",
        "\n",
        "\n",
        "# #This is the test data \n",
        "# test.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+---------+------+\n",
            "|movieId|rating|timestamp|userId|\n",
            "+-------+------+---------+------+\n",
            "|    242|   3.0|881250949|   196|\n",
            "|    302|   3.0|891717742|   186|\n",
            "|    377|   1.0|878887116|    22|\n",
            "|     51|   2.0|880606923|   244|\n",
            "|    346|   1.0|886397596|   166|\n",
            "|    474|   4.0|884182806|   298|\n",
            "|    265|   2.0|881171488|   115|\n",
            "|    465|   5.0|891628467|   253|\n",
            "|    451|   3.0|886324817|   305|\n",
            "|     86|   3.0|883603013|     6|\n",
            "|    257|   2.0|879372434|    62|\n",
            "|   1014|   5.0|879781125|   286|\n",
            "|    222|   5.0|876042340|   200|\n",
            "|     40|   3.0|891035994|   210|\n",
            "|     29|   3.0|888104457|   224|\n",
            "|    785|   3.0|879485318|   303|\n",
            "|    387|   5.0|879270459|   122|\n",
            "|    274|   2.0|879539794|   194|\n",
            "|   1042|   4.0|874834944|   291|\n",
            "|   1184|   2.0|892079237|   234|\n",
            "+-------+------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- movieId: long (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: long (nullable = true)\n",
            " |-- userId: long (nullable = true)\n",
            "\n",
            "79853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5UqLQASdnjC",
        "colab_type": "code",
        "outputId": "70dfab8e-5eb5-42bc-ed49-ec2658912a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#checking min and max rating \n",
        "max_rating = spark.sql(\"SELECT max(rating) FROM ratings\")\n",
        "max_rating.show()\n",
        "\n",
        "\n",
        "min_rating = spark.sql(\"SELECT min(rating) FROM ratings\")\n",
        "min_rating.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|max(rating)|\n",
            "+-----------+\n",
            "|        5.0|\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|min(rating)|\n",
            "+-----------+\n",
            "|        1.0|\n",
            "+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7gxrful1ibb",
        "colab_type": "code",
        "outputId": "c7c0a2fe-679d-4616-deff-ab4579ef8221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "#for movie titles\n",
        "m_cols = ['movie_id', 'title', 'release_date']\n",
        "movies = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/movielens/u.item\", sep=\"|\", names=m_cols, usecols=range(2), encoding=\"iso-8859-1\")\n",
        "\n",
        "\n",
        "movies\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6529502a1c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'movie_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'release_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/data/movielens/u.item\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/content/drive/My Drive/Colab Notebooks/data/movielens/u.item' does not exist: b'/content/drive/My Drive/Colab Notebooks/data/movielens/u.item'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uGJDZMctVmcv"
      },
      "source": [
        "# Step 2 - Create a baseline\n",
        "\n",
        "Now take a very simple estimate as the baseline: calculate the mean of all ratings.    \n",
        "\n",
        "The average can be calculated with the SQL `AVG` command, within an SQL `SELECT` statement. \n",
        "\n",
        "Then calculate the MSE with respect to the average (as predictor)\n",
        "\n",
        "Calculate the RMSE as a naive baseline to compare the trained model against\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k9FB2exsVmcx",
        "outputId": "76e4f962-33c4-4946-a025-52992f9820a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Average rating in total \n",
        "SQL1 = 'SELECT AVG(rating) FROM ratings'\n",
        "row = spark.sql(SQL1).collect()[0] # get the single row with the result\n",
        "#row #average rating = 3.529\n",
        "\n",
        "meanRating = row['avg(rating)'] # access Row as a map \n",
        "print('meanRating',meanRating)\n",
        "\n",
        "#Average rating per movie ???\n",
        "se_rdd = test.rdd.map(lambda row: Row(se = pow(row['rating']-meanRating,2)) ) \n",
        "se_df = spark.createDataFrame(se_rdd) \n",
        "# #se_df.show()\n",
        "se_df.createOrReplaceTempView('se')\n",
        "print('se_df',se_df)\n",
        "\n",
        "#Would select average rating for each movie, but not what we need \n",
        "# SQL2 = 'SELECT * FROM se'\n",
        "# row = spark.sql(SQL2).collect()\n",
        "# row\n",
        "\n",
        "#Get average rating for all movies altogether \n",
        "SQL2 = 'SELECT AVG(se) FROM se'\n",
        "row = spark.sql(SQL2).collect()[0]\n",
        "row\n",
        "\n",
        "meanSE = row['avg(se)'] # access Row as a map \n",
        "print('RMSE',pow(meanSE,0.5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "meanRating 3.52986\n",
            "se_df DataFrame[se: double]\n",
            "RMSE 1.1295544091605558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BcvJZND5Vmc4"
      },
      "source": [
        "## Step 3 - Train an ALS Estimator and perform CV \n",
        "\n",
        "Now create an ALS estimator and a parameter grid to explore different values for the `rank` and `regParam` parameter of the ALS. Then build a cross-validator to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zpPgO80HVmc6",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit #to cross validate & fine tune hyperparameters of our model \n",
        "from pyspark.ml.evaluation import RegressionEvaluator # to measure performance of ALS model \n",
        "from pyspark.ml.recommendation import ALS #import ALS algorithm \n",
        "\n",
        "#alternative 1: \n",
        "# # Build the recommendation model using ALS on the training data\n",
        "# als = ALS(maxIter=3, \n",
        "#           rank=10, \n",
        "#           regParam=0.1, \n",
        "#           userCol=\"userId\", \n",
        "#           itemCol=\"movieId\", \n",
        "#           ratingCol=\"rating\")\n",
        "\n",
        "\n",
        "#Own alternative: \n",
        "als = ALS(userCol=\"userId\",\n",
        "          itemCol=\"movieId\", \n",
        "          ratingCol=\"rating\",\n",
        "          coldStartStrategy=\"drop\",\n",
        "          nonnegative = True) #don't want negative predictions\n",
        "\n",
        "#Fine tune hyperparameters: rank, maxIter (here not given, would be max iterations between X, Y to minimize the error)\n",
        "# Regularization Parameter to prevent ALS from overfitting to the data \n",
        "# rank of X, Y matrices\n",
        "paramGrid = ParamGridBuilder().addGrid(als.regParam, [0.03,0.1,0.3]).addGrid(als.rank, [3,10,30]).build()\n",
        "\n",
        "#Define evaluator as RMSE\n",
        "#tell ALS which is the label column and what we want to call the prediction column\n",
        "regEval = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "\n",
        "\n",
        "#Build cross validation using CrossValidator  \n",
        "crossVal = CrossValidator(\n",
        "          estimator=als,\n",
        "          estimatorParamMaps=paramGrid, \n",
        "          evaluator=regEval)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JTvVhTN3Vmc_"
      },
      "source": [
        "## Step 4 - Evaluate The Model\n",
        "\n",
        "Take the trained cvModel and extract the best parameter values by inspecting the estimatorParameterMaps. \n",
        "Compare the RMSE value to that of the mean for different parameter settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXkEsPvq8CCr",
        "colab_type": "code",
        "outputId": "8a283f5f-174c-4c9c-9b68-b8b8d792d0cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#alternative 2: \n",
        "\n",
        "#fit ALS model to training data\n",
        "model = crossVal.fit(training)\n",
        "\n",
        "#Extract best model from tuning exercise using ParamGridBuilder \n",
        "best_model = model.bestModel \n",
        "\n",
        "#fitting the best model (from above) to the test data  --> generates predictions\n",
        "predictions = best_model.transform(test)\n",
        "#get RMSE \n",
        "rmse = regEval.evaluate(predictions)\n",
        "\n",
        "\n",
        "#Print evaluation metrics and model parameters\n",
        "print(\"RMSE= \" + str(rmse))\n",
        "print(\"***Best model***\")\n",
        "print(\"Rank: \" + str(best_model.rank))\n",
        "print(\"MaxIter: \" + str(best_model._java_obj.parent().getMaxIter()))\n",
        "print(\"RegParam: \" + str(best_model._java_obj.parent().getRegParam())) \n",
        "\n",
        "\n",
        "#RMSE = 0.9366 --> reasonably reliable "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE= 0.9278876830744898\n",
            "***Best model***\n",
            "Rank: 3\n",
            "MaxIter: 10\n",
            "RegParam: 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MBpK-8FAaNA",
        "colab_type": "code",
        "outputId": "77a4b87a-3d27-4c17-831c-b9e29b6bf37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#To see how far off our predictions are \n",
        "predictions.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+---------+------+----------+\n",
            "|movieId|rating|timestamp|userId|prediction|\n",
            "+-------+------+---------+------+----------+\n",
            "|    148|   3.0|879540276|   406| 2.6706975|\n",
            "|    148|   3.0|891543129|    27| 2.8232176|\n",
            "|    148|   2.0|880843892|   916| 2.4764628|\n",
            "|    148|   4.0|889492989|   663| 3.1737113|\n",
            "|    148|   4.0|876544781|   330| 4.0028377|\n",
            "|    148|   5.0|893212730|   416| 3.6113138|\n",
            "|    148|   3.0|884133284|   435|  2.875884|\n",
            "|    148|   4.0|880387474|   923| 3.6291358|\n",
            "|    148|   3.0|879110346|   455| 2.9570184|\n",
            "|    148|   2.0|880167030|   880| 3.1370335|\n",
            "|    148|   4.0|890862563|   834| 3.4727056|\n",
            "|    148|   5.0|888817717|   532| 3.9184709|\n",
            "|    148|   3.0|891228196|   234| 2.2788446|\n",
            "|    148|   5.0|879563367|   459| 3.3802338|\n",
            "|    148|   1.0|888907015|   293| 2.1969743|\n",
            "|    148|   4.0|884646436|   396| 3.5099092|\n",
            "|    148|   1.0|874951482|    21|  2.294134|\n",
            "|    148|   3.0|880434755|   203|  3.164443|\n",
            "|    148|   2.0|882608961|   592| 2.6451952|\n",
            "|    148|   4.0|880044944|   378| 2.9454608|\n",
            "+-------+------+---------+------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8jGB7ldBERQ",
        "colab_type": "code",
        "outputId": "13839a93-19a4-47a6-90df-e5a9dff05bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#Now want to make actual recommendations: \n",
        "#Get top 5 recommendations for all users \n",
        "#predictions can be larger than 5, as they are simply predictions \n",
        "\n",
        "user_recs = best_model.recommendForAllUsers(5)\n",
        "user_recs.show()\n",
        "\n",
        "#Register as temporary view\n",
        "user_recs.createOrReplaceTempView('user_recs') \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+\n",
            "|userId|     recommendations|\n",
            "+------+--------------------+\n",
            "|   471|[[1155, 6.445314]...|\n",
            "|   463|[[814, 4.503483],...|\n",
            "|   833|[[1491, 5.538618]...|\n",
            "|   496|[[1491, 4.4210076...|\n",
            "|   148|[[1589, 5.4492717...|\n",
            "|   540|[[1467, 5.0062723...|\n",
            "|   392|[[814, 5.312068],...|\n",
            "|   243|[[814, 4.9330974]...|\n",
            "|   623|[[814, 4.871832],...|\n",
            "|   737|[[1491, 6.254104]...|\n",
            "|   897|[[1589, 5.479496]...|\n",
            "|   858|[[1449, 4.8004155...|\n",
            "|    31|[[1491, 6.3782377...|\n",
            "|   516|[[814, 5.2516212]...|\n",
            "|   580|[[1589, 5.566204]...|\n",
            "|   251|[[814, 4.9980354]...|\n",
            "|   451|[[1589, 6.1134114...|\n",
            "|    85|[[814, 4.6332707]...|\n",
            "|   137|[[1589, 6.3322535...|\n",
            "|   808|[[814, 5.700057],...|\n",
            "+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZcWIxU_QkIq",
        "colab_type": "code",
        "outputId": "e7418c76-e78d-42f3-f868-235e9fe4d17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#read in UserIds for recommendations\n",
        "selected_user_ids = spark.read.text('/content/drive/My Drive/Colab Notebooks/data/movielens/user_predictions.csv').rdd\n",
        "\n",
        "selected_user_ids = spark.createDataFrame(selected_user_ids)\n",
        "\n",
        "# register the DataFrame so that we can use it with Spark SQL\n",
        "selected_user_ids.createOrReplaceTempView('selected_user_ids')\n",
        "\n",
        "\n",
        "selected_user_ids = spark.sql(\"SELECT value from selected_user_ids\")\n",
        "\n",
        "#rename column \n",
        "selected_user_ids = selected_user_ids.withColumnRenamed(\"value\", \"userId\")\n",
        "\n",
        "# Check that it is a PySpark DataFrame \n",
        "type(selected_user_ids)\n",
        "\n",
        "selected_user_ids.show()\n",
        "\n",
        "\n",
        "selected_user_ids.columns\n",
        "\n",
        "# register the DataFrame so that we can use it with Spark SQL\n",
        "selected_user_ids.createOrReplaceTempView('selected_user_ids')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|userId|\n",
            "+------+\n",
            "|   198|\n",
            "|    11|\n",
            "|   314|\n",
            "|   184|\n",
            "|   163|\n",
            "|   710|\n",
            "|   881|\n",
            "|   504|\n",
            "|   267|\n",
            "|   653|\n",
            "+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHN6aQusSDwU",
        "colab_type": "code",
        "outputId": "7c19cd05-c0fa-482a-af20-ca4101cce7f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#Combine the two frames \n",
        "combined_frame = spark.sql(\"SELECT s.userId, u.recommendations FROM selected_user_ids as s LEFT JOIN user_recs AS u ON s.userId = u.userId\")\n",
        "combined_frame.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+\n",
            "|userId|     recommendations|\n",
            "+------+--------------------+\n",
            "|   881|[[1467, 4.5301466...|\n",
            "|   163|[[814, 4.0768776]...|\n",
            "|   504|[[814, 5.122557],...|\n",
            "|   314|[[113, 5.4674745]...|\n",
            "|   267|[[1467, 5.4449453...|\n",
            "|   653|[[1467, 3.8005152...|\n",
            "|   710|[[1491, 4.895296]...|\n",
            "|    11|[[814, 4.9344387]...|\n",
            "|   198|[[1449, 4.3232374...|\n",
            "|   184|[[814, 4.9805717]...|\n",
            "+------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaX9p1M8uo84",
        "colab_type": "code",
        "outputId": "5faf8126-0e68-4f60-853b-355d5ff39b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "#Convert into a Pandas DF for easy usability\n",
        "user_recs_pandas = combined_frame.toPandas()\n",
        "\n",
        "user_recs_pandas['userId']\n",
        "\n",
        "user_recs_pandas['recommendations']\n",
        "\n",
        "\n",
        "movie_rec_for_each_customer = []\n",
        "\n",
        "\n",
        "for i in user_recs_pandas['recommendations']: \n",
        "    first_movie = (i[0][0])\n",
        "    second_movie = (i[1][0])\n",
        "    third_movie = (i[2][0])\n",
        "    fourth_movie = (i[3][0])\n",
        "    fifth_movie = (i[4][0])\n",
        "    combined_movie_recs = [first_movie, second_movie, third_movie, fourth_movie, fifth_movie]\n",
        "    movie_rec_for_each_customer.append(combined_movie_recs)\n",
        "\n",
        "movie_rec_for_each_customer\n",
        "\n",
        "recommended_movies = pd.DataFrame(movie_rec_for_each_customer, index=user_recs_pandas['userId'])\n",
        "\n",
        "recommended_movies.columns = ['movie_1', 'movie_2', 'movie_3', 'movie_4', 'movie_5']\n",
        "\n",
        "recommended_movies\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_1</th>\n",
              "      <th>movie_2</th>\n",
              "      <th>movie_3</th>\n",
              "      <th>movie_4</th>\n",
              "      <th>movie_5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>1467</td>\n",
              "      <td>113</td>\n",
              "      <td>814</td>\n",
              "      <td>1589</td>\n",
              "      <td>1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>814</td>\n",
              "      <td>113</td>\n",
              "      <td>1662</td>\n",
              "      <td>867</td>\n",
              "      <td>1599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>814</td>\n",
              "      <td>113</td>\n",
              "      <td>1662</td>\n",
              "      <td>1467</td>\n",
              "      <td>1599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>113</td>\n",
              "      <td>1269</td>\n",
              "      <td>1589</td>\n",
              "      <td>1662</td>\n",
              "      <td>1192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>1467</td>\n",
              "      <td>1500</td>\n",
              "      <td>1491</td>\n",
              "      <td>1367</td>\n",
              "      <td>1449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>653</th>\n",
              "      <td>1467</td>\n",
              "      <td>1589</td>\n",
              "      <td>1500</td>\n",
              "      <td>1607</td>\n",
              "      <td>1397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>1491</td>\n",
              "      <td>1449</td>\n",
              "      <td>1512</td>\n",
              "      <td>1367</td>\n",
              "      <td>814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>814</td>\n",
              "      <td>1599</td>\n",
              "      <td>1449</td>\n",
              "      <td>1651</td>\n",
              "      <td>1650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>1449</td>\n",
              "      <td>814</td>\n",
              "      <td>1491</td>\n",
              "      <td>1367</td>\n",
              "      <td>1512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>814</td>\n",
              "      <td>1449</td>\n",
              "      <td>1512</td>\n",
              "      <td>1358</td>\n",
              "      <td>1599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        movie_1  movie_2  movie_3  movie_4  movie_5\n",
              "userId                                             \n",
              "881        1467      113      814     1589     1500\n",
              "163         814      113     1662      867     1599\n",
              "504         814      113     1662     1467     1599\n",
              "314         113     1269     1589     1662     1192\n",
              "267        1467     1500     1491     1367     1449\n",
              "653        1467     1589     1500     1607     1397\n",
              "710        1491     1449     1512     1367      814\n",
              "11          814     1599     1449     1651     1650\n",
              "198        1449      814     1491     1367     1512\n",
              "184         814     1449     1512     1358     1599"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDSIRZBvpnii",
        "colab_type": "code",
        "outputId": "a0e2cbef-f075-482c-9a1c-3b5ed60af72f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "movies\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>title</th>\n",
              "      <th>release_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1677</th>\n",
              "      <td>1678</td>\n",
              "      <td>Mat' i syn (1997)</td>\n",
              "      <td>06-Feb-1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1678</th>\n",
              "      <td>1679</td>\n",
              "      <td>B. Monkey (1998)</td>\n",
              "      <td>06-Feb-1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1679</th>\n",
              "      <td>1680</td>\n",
              "      <td>Sliding Doors (1998)</td>\n",
              "      <td>01-Jan-1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1680</th>\n",
              "      <td>1681</td>\n",
              "      <td>You So Crazy (1994)</td>\n",
              "      <td>01-Jan-1994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>1682</td>\n",
              "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
              "      <td>08-Mar-1996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1682 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      movie_id                                      title release_date\n",
              "0            1                           Toy Story (1995)  01-Jan-1995\n",
              "1            2                           GoldenEye (1995)  01-Jan-1995\n",
              "2            3                          Four Rooms (1995)  01-Jan-1995\n",
              "3            4                          Get Shorty (1995)  01-Jan-1995\n",
              "4            5                             Copycat (1995)  01-Jan-1995\n",
              "...        ...                                        ...          ...\n",
              "1677      1678                          Mat' i syn (1997)  06-Feb-1998\n",
              "1678      1679                           B. Monkey (1998)  06-Feb-1998\n",
              "1679      1680                       Sliding Doors (1998)  01-Jan-1998\n",
              "1680      1681                        You So Crazy (1994)  01-Jan-1994\n",
              "1681      1682  Scream of Stone (Schrei aus Stein) (1991)  08-Mar-1996\n",
              "\n",
              "[1682 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLRzgBNjj1Ne",
        "colab_type": "code",
        "outputId": "0f090857-c8d9-4bf3-ab6e-27c99a94ffcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        }
      },
      "source": [
        "#get dictionary of ids & movies\n",
        "rename_dict = movies.set_index('movie_id').to_dict()['title']\n",
        "rename_dict\n",
        "\n",
        "#replace values with titles \n",
        "recommended_movies = recommended_movies.replace(rename_dict)\n",
        "\n",
        "recommended_movies"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_1</th>\n",
              "      <th>movie_2</th>\n",
              "      <th>movie_3</th>\n",
              "      <th>movie_4</th>\n",
              "      <th>movie_5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>Saint of Fort Washington, The (1993)</td>\n",
              "      <td>Horseman on the Roof, The (Hussard sur le toit...</td>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Schizopolis (1996)</td>\n",
              "      <td>Santa with Muscles (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Horseman on the Roof, The (Hussard sur le toit...</td>\n",
              "      <td>Rough Magic (1995)</td>\n",
              "      <td>Whole Wide World, The (1996)</td>\n",
              "      <td>Someone Else's America (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Horseman on the Roof, The (Hussard sur le toit...</td>\n",
              "      <td>Rough Magic (1995)</td>\n",
              "      <td>Saint of Fort Washington, The (1993)</td>\n",
              "      <td>Someone Else's America (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>Horseman on the Roof, The (Hussard sur le toit...</td>\n",
              "      <td>Love in the Afternoon (1957)</td>\n",
              "      <td>Schizopolis (1996)</td>\n",
              "      <td>Rough Magic (1995)</td>\n",
              "      <td>Boys of St. Vincent, The (1993)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>Saint of Fort Washington, The (1993)</td>\n",
              "      <td>Santa with Muscles (1996)</td>\n",
              "      <td>Tough and Deadly (1995)</td>\n",
              "      <td>Faust (1994)</td>\n",
              "      <td>Pather Panchali (1955)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>653</th>\n",
              "      <td>Saint of Fort Washington, The (1993)</td>\n",
              "      <td>Schizopolis (1996)</td>\n",
              "      <td>Santa with Muscles (1996)</td>\n",
              "      <td>Hurricane Streets (1998)</td>\n",
              "      <td>Of Human Bondage (1934)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>Tough and Deadly (1995)</td>\n",
              "      <td>Pather Panchali (1955)</td>\n",
              "      <td>World of Apu, The (Apur Sansar) (1959)</td>\n",
              "      <td>Faust (1994)</td>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Someone Else's America (1995)</td>\n",
              "      <td>Pather Panchali (1955)</td>\n",
              "      <td>Spanish Prisoner, The (1997)</td>\n",
              "      <td>Butcher Boy, The (1998)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>Pather Panchali (1955)</td>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Tough and Deadly (1995)</td>\n",
              "      <td>Faust (1994)</td>\n",
              "      <td>World of Apu, The (Apur Sansar) (1959)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Pather Panchali (1955)</td>\n",
              "      <td>World of Apu, The (Apur Sansar) (1959)</td>\n",
              "      <td>The Deadly Cure (1996)</td>\n",
              "      <td>Someone Else's America (1995)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  movie_1  ...                                 movie_5\n",
              "userId                                                     ...                                        \n",
              "881                  Saint of Fort Washington, The (1993)  ...               Santa with Muscles (1996)\n",
              "163                         Great Day in Harlem, A (1994)  ...           Someone Else's America (1995)\n",
              "504                         Great Day in Harlem, A (1994)  ...           Someone Else's America (1995)\n",
              "314     Horseman on the Roof, The (Hussard sur le toit...  ...         Boys of St. Vincent, The (1993)\n",
              "267                  Saint of Fort Washington, The (1993)  ...                  Pather Panchali (1955)\n",
              "653                  Saint of Fort Washington, The (1993)  ...                 Of Human Bondage (1934)\n",
              "710                               Tough and Deadly (1995)  ...           Great Day in Harlem, A (1994)\n",
              "11                          Great Day in Harlem, A (1994)  ...                 Butcher Boy, The (1998)\n",
              "198                                Pather Panchali (1955)  ...  World of Apu, The (Apur Sansar) (1959)\n",
              "184                         Great Day in Harlem, A (1994)  ...           Someone Else's America (1995)\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D0ygAMOEVmdA",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rays69WC6JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}