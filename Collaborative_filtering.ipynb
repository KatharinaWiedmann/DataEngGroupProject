{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Collaborative_filtering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KatharinaWiedmann/DataEngGroupProject/blob/master/Collaborative_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7wUqfSl2VmcX"
      },
      "source": [
        "# Collaborative Filtering  \n",
        "\n",
        "This basic Recommender System will use the Collaborative filtering method to determine the recommended movies for 10 users. It requires us to have: \n",
        "- u.data file: contains the movie ratings \n",
        "- u.item file: contains the movie titles \n",
        "- user_predictions.csv: contains the user ids for the specific users who we want to predict the movies for\n",
        "\n",
        "I used the tutorial on youtube for [Recommendation Engines Using ALS in PySpark (MovieLens Dataset)](https://www.youtube.com/watch?v=FgGjc5oabrA) as well as the provided notebook (and adjusted it) as a baseline for this project. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qc3anmYsqxp",
        "colab_type": "text"
      },
      "source": [
        "###Preparation\n",
        "\n",
        "First, I need to prepare the Notebook, i.e. install libraries, create a Spark Context, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NvDz4AgvNm9",
        "colab_type": "code",
        "outputId": "40c1c321-005e-4367-db60-c0f7ab4daff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        " !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "\n",
        "!pip install pyspark\n",
        "!pip install altair"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 54kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 49.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=9249f84a8a66c46f4cd9dd0adc5120df19f3580bd9e0a4d58aba39893be32231\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair) (2.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair) (2.11.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair) (0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from altair) (0.25.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from altair) (1.18.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair) (0.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->altair) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEIHscAnvkBh",
        "colab_type": "code",
        "outputId": "fc7aea0f-a31e-407a-fadd-5875743165a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pyspark\n",
        "# get a spark context\n",
        "sc = pyspark.SparkContext.getOrCreate()\n",
        "print(sc)\n",
        "# get the context\n",
        "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
        "print(spark)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SparkContext master=local[*] appName=pyspark-shell>\n",
            "<pyspark.sql.session.SparkSession object at 0x7f5537829c50>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN1h8_rvCg_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhbRbBLCWD1h",
        "colab_type": "code",
        "outputId": "11240fc8-3856-4124-82db-bb56c411f4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from google.colab import files\n",
        "!ls -l\n",
        "#!rm spark-2.4.4-bin-hadoop2.7.tgz.1\n",
        "\n",
        "!echo $JAVA_HOME/bin\n",
        "!export PATH=$PATH:$JAVA_HOME/bin\n",
        "!echo $PATH"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 227100\n",
            "drwx------  4 root root      4096 Mar 31 08:29 drive\n",
            "drwxr-xr-x  1 root root      4096 Mar 18 16:23 sample_data\n",
            "drwxr-xr-x 13 1000 1000      4096 Feb  2 19:47 spark-2.4.5-bin-hadoop2.7\n",
            "-rw-r--r--  1 root root 232530699 Feb  2 20:27 spark-2.4.5-bin-hadoop2.7.tgz\n",
            "/usr/lib/jvm/java-8-openjdk-amd64/bin\n",
            "/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocjx7B2EXPL3",
        "colab_type": "code",
        "outputId": "72a3f8e1-0e24-4bc6-b40b-cee8917839ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!java -version\n",
        "!python --version\n",
        "!ls /usr/lib/jvm/\n",
        "!echo $JAVA_HOME\n",
        "spark.version\n",
        "!ls /content\n",
        "!echo $PATH"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.6\" 2020-01-14\n",
            "OpenJDK Runtime Environment (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1, mixed mode, sharing)\n",
            "Python 3.6.9\n",
            "default-java\t\t   java-11-openjdk-amd64     java-8-openjdk-amd64\n",
            "java-1.11.0-openjdk-amd64  java-1.8.0-openjdk-amd64\n",
            "/usr/lib/jvm/java-8-openjdk-amd64\n",
            "drive  sample_data  spark-2.4.5-bin-hadoop2.7  spark-2.4.5-bin-hadoop2.7.tgz\n",
            "/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7afsWutGu3PZ",
        "colab_type": "text"
      },
      "source": [
        "## Step 1 - Load the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Da0U58DFVmcb"
      },
      "source": [
        "### Data for Ratings\n",
        "I first read the data, split into tokens and create a structured DataFrame. Then I register a temporary view so I can query from it. Also, I split it into a training and a test set. \n",
        "\n",
        "I then have a first glance at the data - checking for minimum and maximum ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zE39AsRoVmcf",
        "outputId": "4068d79f-05db-4c7e-8d63-06bf25873d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType\n",
        "spark = SparkSession.builder.getOrCreate() # create a SparkSession \n",
        "# this gets us an RDD. (could also be done with RDD.textFile in this case)\n",
        "lines = spark.read.text(\"/content/drive/My Drive/Colab Notebooks/data/movielens/u.data\").rdd\n",
        "# now split the lines at the '\\t'\n",
        "parts = lines.map(lambda row: row.value.split(\"\\t\"))\n",
        "\n",
        "parts.collect()\n",
        "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
        "                                     rating=float(p[2]), timestamp=int(p[3])))\n",
        "ratings = spark.createDataFrame(ratingsRDD)\n",
        "ratings.createOrReplaceTempView('ratings') # register the DataFrame so that we can use it with Spark SQL.\n",
        "\n",
        "#this is the whole data frame \n",
        "ratings.show(20)\n",
        "\n",
        "(training, test) = ratings.randomSplit([0.8, 0.2]) # split into test and training set\n",
        "training.printSchema() # just for testing, should show the four columns\n",
        "print(training.count()) # just for testing, should be around 1200\n",
        "\n",
        "\n",
        "# #This is the training data \n",
        "# training.show()\n",
        "\n",
        "\n",
        "# #This is the test data \n",
        "# test.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+---------+------+\n",
            "|movieId|rating|timestamp|userId|\n",
            "+-------+------+---------+------+\n",
            "|    242|   3.0|881250949|   196|\n",
            "|    302|   3.0|891717742|   186|\n",
            "|    377|   1.0|878887116|    22|\n",
            "|     51|   2.0|880606923|   244|\n",
            "|    346|   1.0|886397596|   166|\n",
            "|    474|   4.0|884182806|   298|\n",
            "|    265|   2.0|881171488|   115|\n",
            "|    465|   5.0|891628467|   253|\n",
            "|    451|   3.0|886324817|   305|\n",
            "|     86|   3.0|883603013|     6|\n",
            "|    257|   2.0|879372434|    62|\n",
            "|   1014|   5.0|879781125|   286|\n",
            "|    222|   5.0|876042340|   200|\n",
            "|     40|   3.0|891035994|   210|\n",
            "|     29|   3.0|888104457|   224|\n",
            "|    785|   3.0|879485318|   303|\n",
            "|    387|   5.0|879270459|   122|\n",
            "|    274|   2.0|879539794|   194|\n",
            "|   1042|   4.0|874834944|   291|\n",
            "|   1184|   2.0|892079237|   234|\n",
            "+-------+------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- movieId: long (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: long (nullable = true)\n",
            " |-- userId: long (nullable = true)\n",
            "\n",
            "79987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5UqLQASdnjC",
        "colab_type": "code",
        "outputId": "220d7d61-1526-4071-d4b5-9aee9d39d1ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#checking min and max rating \n",
        "max_rating = spark.sql(\"SELECT max(rating) FROM ratings\")\n",
        "max_rating.show()\n",
        "\n",
        "\n",
        "min_rating = spark.sql(\"SELECT min(rating) FROM ratings\")\n",
        "min_rating.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|max(rating)|\n",
            "+-----------+\n",
            "|        5.0|\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|min(rating)|\n",
            "+-----------+\n",
            "|        1.0|\n",
            "+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhelrx--um3E",
        "colab_type": "text"
      },
      "source": [
        "### Data for movie titles\n",
        "I also read in the data for the movie titles, so I can match the movie ids with their names later on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7gxrful1ibb",
        "colab_type": "code",
        "outputId": "0ee7b92f-8e85-455d-c703-bc7726c11213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#for movie titles\n",
        "m_cols = ['movie_id', 'title', 'release_date']\n",
        "movies = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/movielens/u.item\", sep=\"|\", names=m_cols, usecols=range(3), encoding=\"iso-8859-1\")\n",
        "\n",
        "\n",
        "movies\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>title</th>\n",
              "      <th>release_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1677</th>\n",
              "      <td>1678</td>\n",
              "      <td>Mat' i syn (1997)</td>\n",
              "      <td>06-Feb-1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1678</th>\n",
              "      <td>1679</td>\n",
              "      <td>B. Monkey (1998)</td>\n",
              "      <td>06-Feb-1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1679</th>\n",
              "      <td>1680</td>\n",
              "      <td>Sliding Doors (1998)</td>\n",
              "      <td>01-Jan-1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1680</th>\n",
              "      <td>1681</td>\n",
              "      <td>You So Crazy (1994)</td>\n",
              "      <td>01-Jan-1994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>1682</td>\n",
              "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
              "      <td>08-Mar-1996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1682 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      movie_id                                      title release_date\n",
              "0            1                           Toy Story (1995)  01-Jan-1995\n",
              "1            2                           GoldenEye (1995)  01-Jan-1995\n",
              "2            3                          Four Rooms (1995)  01-Jan-1995\n",
              "3            4                          Get Shorty (1995)  01-Jan-1995\n",
              "4            5                             Copycat (1995)  01-Jan-1995\n",
              "...        ...                                        ...          ...\n",
              "1677      1678                          Mat' i syn (1997)  06-Feb-1998\n",
              "1678      1679                           B. Monkey (1998)  06-Feb-1998\n",
              "1679      1680                       Sliding Doors (1998)  01-Jan-1998\n",
              "1680      1681                        You So Crazy (1994)  01-Jan-1994\n",
              "1681      1682  Scream of Stone (Schrei aus Stein) (1991)  08-Mar-1996\n",
              "\n",
              "[1682 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uGJDZMctVmcv"
      },
      "source": [
        "# Step 2 - Create a baseline\n",
        "\n",
        "Now I take a very simple estimate as the baseline: I calculate the mean of all ratings.    \n",
        "\n",
        "The average can be calculated with the SQL `AVG` command, within an SQL `SELECT` statement. \n",
        "\n",
        "Then I calculate the MSE with respect to the average (as predictor) and the RMSE as a naive baseline to compare the trained model against. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k9FB2exsVmcx",
        "outputId": "c782cd14-49e7-4634-e887-e3b46735a67e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Average rating in total \n",
        "SQL1 = 'SELECT AVG(rating) FROM ratings'\n",
        "row = spark.sql(SQL1).collect()[0] # get the single row with the result\n",
        "#row #average rating = 3.529\n",
        "\n",
        "meanRating = row['avg(rating)'] # access Row as a map \n",
        "print('meanRating',meanRating)\n",
        "\n",
        "#Average rating per movie ???\n",
        "se_rdd = test.rdd.map(lambda row: Row(se = pow(row['rating']-meanRating,2)) ) \n",
        "se_df = spark.createDataFrame(se_rdd) \n",
        "# #se_df.show()\n",
        "se_df.createOrReplaceTempView('se')\n",
        "print('se_df',se_df)\n",
        "\n",
        "#Would select average rating for each movie, but not what we need \n",
        "# SQL2 = 'SELECT * FROM se'\n",
        "# row = spark.sql(SQL2).collect()\n",
        "# row\n",
        "\n",
        "#Get average rating for all movies altogether \n",
        "SQL2 = 'SELECT AVG(se) FROM se'\n",
        "row = spark.sql(SQL2).collect()[0]\n",
        "row\n",
        "\n",
        "meanSE = row['avg(se)'] # access Row as a map \n",
        "print('RMSE',pow(meanSE,0.5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "meanRating 3.52986\n",
            "se_df DataFrame[se: double]\n",
            "RMSE 1.1215431288226416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BcvJZND5Vmc4"
      },
      "source": [
        "## Step 3 - Train an ALS Estimator and perform Cross Validation\n",
        "\n",
        "Now I create an ALS estimator and a parameter grid to explore different values for the `rank` and `regParam` parameter of the ALS. Then I build a cross-validator to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zpPgO80HVmc6",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit #to cross validate & fine tune hyperparameters of our model \n",
        "from pyspark.ml.evaluation import RegressionEvaluator # to measure performance of ALS model \n",
        "from pyspark.ml.recommendation import ALS #import ALS algorithm \n",
        "\n",
        " \n",
        "als = ALS(userCol=\"userId\",\n",
        "          itemCol=\"movieId\", \n",
        "          ratingCol=\"rating\",\n",
        "          coldStartStrategy=\"drop\",\n",
        "          nonnegative = True) #don't want negative predictions\n",
        "\n",
        "#Fine tune hyperparameters: \n",
        "# maxIter: here not given, would be max iterations between X, Y to minimize the error\n",
        "# RegParam: Regularization Parameter to prevent ALS from overfitting to the data \n",
        "# rank of X, Y matrices\n",
        "paramGrid = ParamGridBuilder().addGrid(als.regParam, [0.03,0.1,0.3]).addGrid(als.rank, [3,10,30]).build()\n",
        "\n",
        "#Define evaluator as RMSE\n",
        "#tell ALS which is the label column and what we want to call the prediction column\n",
        "regEval = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "\n",
        "\n",
        "#Build cross validation using CrossValidator  \n",
        "crossVal = CrossValidator(\n",
        "          estimator=als,\n",
        "          estimatorParamMaps=paramGrid, \n",
        "          evaluator=regEval)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JTvVhTN3Vmc_"
      },
      "source": [
        "## Step 4 - Fit and Evaluate The Model\n",
        "\n",
        "I fit the model and find the parameters for the best model. \n",
        "Once I have found the best model, I obtain its' parameters and also the RMSE (my evaluation metric). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXkEsPvq8CCr",
        "colab_type": "code",
        "outputId": "f1bd3bb7-d684-4144-c77f-3b9a48d313e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#fit ALS model to training data\n",
        "model = crossVal.fit(training)\n",
        "\n",
        "#Extract best model from tuning exercise using ParamGridBuilder \n",
        "best_model = model.bestModel \n",
        "\n",
        "#fitting the best model (from above) to the test data  --> generates predictions\n",
        "predictions = best_model.transform(test)\n",
        "#get RMSE \n",
        "rmse = regEval.evaluate(predictions)\n",
        "\n",
        "\n",
        "#Print evaluation metrics and model parameters\n",
        "print(\"RMSE= \" + str(rmse))\n",
        "print(\"***Best model***\")\n",
        "print(\"Rank: \" + str(best_model.rank))\n",
        "print(\"MaxIter: \" + str(best_model._java_obj.parent().getMaxIter()))\n",
        "print(\"RegParam: \" + str(best_model._java_obj.parent().getRegParam())) \n",
        "\n",
        "\n",
        "#RMSE = 0.9366 --> reasonably reliable "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE= 0.9102374612423101\n",
            "***Best model***\n",
            "Rank: 30\n",
            "MaxIter: 10\n",
            "RegParam: 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAUPyqf1yOvt",
        "colab_type": "text"
      },
      "source": [
        "## Step 5 - Use the model to find the predictions for our users "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ESfl-bsxdsN",
        "colab_type": "text"
      },
      "source": [
        "### Predictions\n",
        "I first want to get a glance at the predictions and compare them with the actual ratings to see how far I am off. As I can see below, the predictions are reasonably close (as the RMSE value from above suggests as well). By using recommendForAllUsers(5), I can get an array of the 5 highest recommendations for each user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MBpK-8FAaNA",
        "colab_type": "code",
        "outputId": "77a4b87a-3d27-4c17-831c-b9e29b6bf37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#To see how far off our predictions are \n",
        "predictions.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+---------+------+----------+\n",
            "|movieId|rating|timestamp|userId|prediction|\n",
            "+-------+------+---------+------+----------+\n",
            "|    148|   3.0|879540276|   406| 2.6706975|\n",
            "|    148|   3.0|891543129|    27| 2.8232176|\n",
            "|    148|   2.0|880843892|   916| 2.4764628|\n",
            "|    148|   4.0|889492989|   663| 3.1737113|\n",
            "|    148|   4.0|876544781|   330| 4.0028377|\n",
            "|    148|   5.0|893212730|   416| 3.6113138|\n",
            "|    148|   3.0|884133284|   435|  2.875884|\n",
            "|    148|   4.0|880387474|   923| 3.6291358|\n",
            "|    148|   3.0|879110346|   455| 2.9570184|\n",
            "|    148|   2.0|880167030|   880| 3.1370335|\n",
            "|    148|   4.0|890862563|   834| 3.4727056|\n",
            "|    148|   5.0|888817717|   532| 3.9184709|\n",
            "|    148|   3.0|891228196|   234| 2.2788446|\n",
            "|    148|   5.0|879563367|   459| 3.3802338|\n",
            "|    148|   1.0|888907015|   293| 2.1969743|\n",
            "|    148|   4.0|884646436|   396| 3.5099092|\n",
            "|    148|   1.0|874951482|    21|  2.294134|\n",
            "|    148|   3.0|880434755|   203|  3.164443|\n",
            "|    148|   2.0|882608961|   592| 2.6451952|\n",
            "|    148|   4.0|880044944|   378| 2.9454608|\n",
            "+-------+------+---------+------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8jGB7ldBERQ",
        "colab_type": "code",
        "outputId": "13839a93-19a4-47a6-90df-e5a9dff05bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#Now want to make actual recommendations: \n",
        "#Get top 5 recommendations for all users \n",
        "#predictions can be larger than 5, as they are simply predictions \n",
        "\n",
        "user_recs = best_model.recommendForAllUsers(5)\n",
        "user_recs.show()\n",
        "\n",
        "#Register as temporary view\n",
        "user_recs.createOrReplaceTempView('user_recs') \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+\n",
            "|userId|     recommendations|\n",
            "+------+--------------------+\n",
            "|   471|[[1155, 6.445314]...|\n",
            "|   463|[[814, 4.503483],...|\n",
            "|   833|[[1491, 5.538618]...|\n",
            "|   496|[[1491, 4.4210076...|\n",
            "|   148|[[1589, 5.4492717...|\n",
            "|   540|[[1467, 5.0062723...|\n",
            "|   392|[[814, 5.312068],...|\n",
            "|   243|[[814, 4.9330974]...|\n",
            "|   623|[[814, 4.871832],...|\n",
            "|   737|[[1491, 6.254104]...|\n",
            "|   897|[[1589, 5.479496]...|\n",
            "|   858|[[1449, 4.8004155...|\n",
            "|    31|[[1491, 6.3782377...|\n",
            "|   516|[[814, 5.2516212]...|\n",
            "|   580|[[1589, 5.566204]...|\n",
            "|   251|[[814, 4.9980354]...|\n",
            "|   451|[[1589, 6.1134114...|\n",
            "|    85|[[814, 4.6332707]...|\n",
            "|   137|[[1589, 6.3322535...|\n",
            "|   808|[[814, 5.700057],...|\n",
            "+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le2Cx1GSySEX",
        "colab_type": "text"
      },
      "source": [
        "### Selected Users\n",
        "As I only want to show the recommendations for a few users (given by the teaching team), I have to read in the csv file with the selected user ids and first create a PySpark Dataframe and then register a temporary view so I can use it with Spark SQL. \n",
        "\n",
        "I then join the selected user ids onto the recommendations from above to get a frame which xhows me the top 5 recommendations for each of the selected users.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZcWIxU_QkIq",
        "colab_type": "code",
        "outputId": "e7418c76-e78d-42f3-f868-235e9fe4d17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#read in UserIds for recommendations\n",
        "selected_user_ids = spark.read.text('/content/drive/My Drive/Colab Notebooks/data/movielens/user_predictions.csv').rdd\n",
        "\n",
        "selected_user_ids = spark.createDataFrame(selected_user_ids)\n",
        "\n",
        "# register the DataFrame so that we can use it with Spark SQL\n",
        "selected_user_ids.createOrReplaceTempView('selected_user_ids')\n",
        "\n",
        "\n",
        "selected_user_ids = spark.sql(\"SELECT value from selected_user_ids\")\n",
        "\n",
        "#rename column \n",
        "selected_user_ids = selected_user_ids.withColumnRenamed(\"value\", \"userId\")\n",
        "\n",
        "# Check that it is a PySpark DataFrame \n",
        "type(selected_user_ids)\n",
        "\n",
        "selected_user_ids.show()\n",
        "\n",
        "\n",
        "selected_user_ids.columns\n",
        "\n",
        "# register the DataFrame so that we can use it with Spark SQL\n",
        "selected_user_ids.createOrReplaceTempView('selected_user_ids')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|userId|\n",
            "+------+\n",
            "|   198|\n",
            "|    11|\n",
            "|   314|\n",
            "|   184|\n",
            "|   163|\n",
            "|   710|\n",
            "|   881|\n",
            "|   504|\n",
            "|   267|\n",
            "|   653|\n",
            "+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHN6aQusSDwU",
        "colab_type": "code",
        "outputId": "7c19cd05-c0fa-482a-af20-ca4101cce7f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#Combine the two frames \n",
        "combined_frame = spark.sql(\"SELECT s.userId, u.recommendations FROM selected_user_ids as s LEFT JOIN user_recs AS u ON s.userId = u.userId\")\n",
        "combined_frame.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+\n",
            "|userId|     recommendations|\n",
            "+------+--------------------+\n",
            "|   881|[[1467, 4.5301466...|\n",
            "|   163|[[814, 4.0768776]...|\n",
            "|   504|[[814, 5.122557],...|\n",
            "|   314|[[113, 5.4674745]...|\n",
            "|   267|[[1467, 5.4449453...|\n",
            "|   653|[[1467, 3.8005152...|\n",
            "|   710|[[1491, 4.895296]...|\n",
            "|    11|[[814, 4.9344387]...|\n",
            "|   198|[[1449, 4.3232374...|\n",
            "|   184|[[814, 4.9805717]...|\n",
            "+------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ4yTnX5y-Or",
        "colab_type": "text"
      },
      "source": [
        "### Finalizing User_recs data frame \n",
        "\n",
        "Lastly, I want to tweak the final data frame, so that it shows me actual titles for each of the recommended movie ids for each user.\n",
        "\n",
        "First, I convert the frame from above into a Pandas Data Frame and I use a \n",
        "for loop to assign each recommended movie to a different column on a per user id basis.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaX9p1M8uo84",
        "colab_type": "code",
        "outputId": "5faf8126-0e68-4f60-853b-355d5ff39b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "#Convert into a Pandas DF for easy usability\n",
        "user_recs_pandas = combined_frame.toPandas()\n",
        "\n",
        "user_recs_pandas['userId']\n",
        "\n",
        "user_recs_pandas['recommendations']\n",
        "\n",
        "\n",
        "movie_rec_for_each_customer = []\n",
        "\n",
        "\n",
        "for i in user_recs_pandas['recommendations']: \n",
        "    first_movie = (i[0][0])\n",
        "    second_movie = (i[1][0])\n",
        "    third_movie = (i[2][0])\n",
        "    fourth_movie = (i[3][0])\n",
        "    fifth_movie = (i[4][0])\n",
        "    combined_movie_recs = [first_movie, second_movie, third_movie, fourth_movie, fifth_movie]\n",
        "    movie_rec_for_each_customer.append(combined_movie_recs)\n",
        "\n",
        "movie_rec_for_each_customer\n",
        "\n",
        "recommended_movies = pd.DataFrame(movie_rec_for_each_customer, index=user_recs_pandas['userId'])\n",
        "\n",
        "recommended_movies.columns = ['movie_1', 'movie_2', 'movie_3', 'movie_4', 'movie_5']\n",
        "\n",
        "recommended_movies\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_1</th>\n",
              "      <th>movie_2</th>\n",
              "      <th>movie_3</th>\n",
              "      <th>movie_4</th>\n",
              "      <th>movie_5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>1467</td>\n",
              "      <td>113</td>\n",
              "      <td>814</td>\n",
              "      <td>1589</td>\n",
              "      <td>1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>814</td>\n",
              "      <td>113</td>\n",
              "      <td>1662</td>\n",
              "      <td>867</td>\n",
              "      <td>1599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>814</td>\n",
              "      <td>113</td>\n",
              "      <td>1662</td>\n",
              "      <td>1467</td>\n",
              "      <td>1599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>113</td>\n",
              "      <td>1269</td>\n",
              "      <td>1589</td>\n",
              "      <td>1662</td>\n",
              "      <td>1192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>1467</td>\n",
              "      <td>1500</td>\n",
              "      <td>1491</td>\n",
              "      <td>1367</td>\n",
              "      <td>1449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>653</th>\n",
              "      <td>1467</td>\n",
              "      <td>1589</td>\n",
              "      <td>1500</td>\n",
              "      <td>1607</td>\n",
              "      <td>1397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>1491</td>\n",
              "      <td>1449</td>\n",
              "      <td>1512</td>\n",
              "      <td>1367</td>\n",
              "      <td>814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>814</td>\n",
              "      <td>1599</td>\n",
              "      <td>1449</td>\n",
              "      <td>1651</td>\n",
              "      <td>1650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>1449</td>\n",
              "      <td>814</td>\n",
              "      <td>1491</td>\n",
              "      <td>1367</td>\n",
              "      <td>1512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>814</td>\n",
              "      <td>1449</td>\n",
              "      <td>1512</td>\n",
              "      <td>1358</td>\n",
              "      <td>1599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        movie_1  movie_2  movie_3  movie_4  movie_5\n",
              "userId                                             \n",
              "881        1467      113      814     1589     1500\n",
              "163         814      113     1662      867     1599\n",
              "504         814      113     1662     1467     1599\n",
              "314         113     1269     1589     1662     1192\n",
              "267        1467     1500     1491     1367     1449\n",
              "653        1467     1589     1500     1607     1397\n",
              "710        1491     1449     1512     1367      814\n",
              "11          814     1599     1449     1651     1650\n",
              "198        1449      814     1491     1367     1512\n",
              "184         814     1449     1512     1358     1599"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22EMHc9h0fu8",
        "colab_type": "text"
      },
      "source": [
        "I then need to find the movies dataframe, which contains the movie ids and their titles and I convert the frame into a dictionary.\n",
        "With this dictionary I can replace the movie ids with their titles which gives me my final data frame of the 5 top movies for each of the selected user ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDSIRZBvpnii",
        "colab_type": "code",
        "outputId": "a0e2cbef-f075-482c-9a1c-3b5ed60af72f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#Just for checking what the movies df looks like again. \n",
        "movies\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>title</th>\n",
              "      <th>release_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1677</th>\n",
              "      <td>1678</td>\n",
              "      <td>Mat' i syn (1997)</td>\n",
              "      <td>06-Feb-1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1678</th>\n",
              "      <td>1679</td>\n",
              "      <td>B. Monkey (1998)</td>\n",
              "      <td>06-Feb-1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1679</th>\n",
              "      <td>1680</td>\n",
              "      <td>Sliding Doors (1998)</td>\n",
              "      <td>01-Jan-1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1680</th>\n",
              "      <td>1681</td>\n",
              "      <td>You So Crazy (1994)</td>\n",
              "      <td>01-Jan-1994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>1682</td>\n",
              "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
              "      <td>08-Mar-1996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1682 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      movie_id                                      title release_date\n",
              "0            1                           Toy Story (1995)  01-Jan-1995\n",
              "1            2                           GoldenEye (1995)  01-Jan-1995\n",
              "2            3                          Four Rooms (1995)  01-Jan-1995\n",
              "3            4                          Get Shorty (1995)  01-Jan-1995\n",
              "4            5                             Copycat (1995)  01-Jan-1995\n",
              "...        ...                                        ...          ...\n",
              "1677      1678                          Mat' i syn (1997)  06-Feb-1998\n",
              "1678      1679                           B. Monkey (1998)  06-Feb-1998\n",
              "1679      1680                       Sliding Doors (1998)  01-Jan-1998\n",
              "1680      1681                        You So Crazy (1994)  01-Jan-1994\n",
              "1681      1682  Scream of Stone (Schrei aus Stein) (1991)  08-Mar-1996\n",
              "\n",
              "[1682 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLRzgBNjj1Ne",
        "colab_type": "code",
        "outputId": "0f090857-c8d9-4bf3-ab6e-27c99a94ffcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        }
      },
      "source": [
        "#get dictionary of ids & movies\n",
        "rename_dict = movies.set_index('movie_id').to_dict()['title']\n",
        "rename_dict\n",
        "\n",
        "#replace values with titles \n",
        "recommended_movies = recommended_movies.replace(rename_dict)\n",
        "\n",
        "recommended_movies"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_1</th>\n",
              "      <th>movie_2</th>\n",
              "      <th>movie_3</th>\n",
              "      <th>movie_4</th>\n",
              "      <th>movie_5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>Saint of Fort Washington, The (1993)</td>\n",
              "      <td>Horseman on the Roof, The (Hussard sur le toit...</td>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Schizopolis (1996)</td>\n",
              "      <td>Santa with Muscles (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Horseman on the Roof, The (Hussard sur le toit...</td>\n",
              "      <td>Rough Magic (1995)</td>\n",
              "      <td>Whole Wide World, The (1996)</td>\n",
              "      <td>Someone Else's America (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Horseman on the Roof, The (Hussard sur le toit...</td>\n",
              "      <td>Rough Magic (1995)</td>\n",
              "      <td>Saint of Fort Washington, The (1993)</td>\n",
              "      <td>Someone Else's America (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>Horseman on the Roof, The (Hussard sur le toit...</td>\n",
              "      <td>Love in the Afternoon (1957)</td>\n",
              "      <td>Schizopolis (1996)</td>\n",
              "      <td>Rough Magic (1995)</td>\n",
              "      <td>Boys of St. Vincent, The (1993)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>Saint of Fort Washington, The (1993)</td>\n",
              "      <td>Santa with Muscles (1996)</td>\n",
              "      <td>Tough and Deadly (1995)</td>\n",
              "      <td>Faust (1994)</td>\n",
              "      <td>Pather Panchali (1955)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>653</th>\n",
              "      <td>Saint of Fort Washington, The (1993)</td>\n",
              "      <td>Schizopolis (1996)</td>\n",
              "      <td>Santa with Muscles (1996)</td>\n",
              "      <td>Hurricane Streets (1998)</td>\n",
              "      <td>Of Human Bondage (1934)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>Tough and Deadly (1995)</td>\n",
              "      <td>Pather Panchali (1955)</td>\n",
              "      <td>World of Apu, The (Apur Sansar) (1959)</td>\n",
              "      <td>Faust (1994)</td>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Someone Else's America (1995)</td>\n",
              "      <td>Pather Panchali (1955)</td>\n",
              "      <td>Spanish Prisoner, The (1997)</td>\n",
              "      <td>Butcher Boy, The (1998)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>Pather Panchali (1955)</td>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Tough and Deadly (1995)</td>\n",
              "      <td>Faust (1994)</td>\n",
              "      <td>World of Apu, The (Apur Sansar) (1959)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>Great Day in Harlem, A (1994)</td>\n",
              "      <td>Pather Panchali (1955)</td>\n",
              "      <td>World of Apu, The (Apur Sansar) (1959)</td>\n",
              "      <td>The Deadly Cure (1996)</td>\n",
              "      <td>Someone Else's America (1995)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  movie_1  ...                                 movie_5\n",
              "userId                                                     ...                                        \n",
              "881                  Saint of Fort Washington, The (1993)  ...               Santa with Muscles (1996)\n",
              "163                         Great Day in Harlem, A (1994)  ...           Someone Else's America (1995)\n",
              "504                         Great Day in Harlem, A (1994)  ...           Someone Else's America (1995)\n",
              "314     Horseman on the Roof, The (Hussard sur le toit...  ...         Boys of St. Vincent, The (1993)\n",
              "267                  Saint of Fort Washington, The (1993)  ...                  Pather Panchali (1955)\n",
              "653                  Saint of Fort Washington, The (1993)  ...                 Of Human Bondage (1934)\n",
              "710                               Tough and Deadly (1995)  ...           Great Day in Harlem, A (1994)\n",
              "11                          Great Day in Harlem, A (1994)  ...                 Butcher Boy, The (1998)\n",
              "198                                Pather Panchali (1955)  ...  World of Apu, The (Apur Sansar) (1959)\n",
              "184                         Great Day in Harlem, A (1994)  ...           Someone Else's America (1995)\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    }
  ]
}