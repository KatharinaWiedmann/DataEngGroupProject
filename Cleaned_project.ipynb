{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team: Data Magicians\n",
    "Members:\n",
    "<p>\n",
    "Arda Putra Ryandika\n",
    "</p>\n",
    "<p>\n",
    "Atthaya Busayaruengrat (Hong)\n",
    "</p>\n",
    "<p>\n",
    "Jingxue (Vera) Cao\n",
    "</p>\n",
    "<p>\n",
    "Katharina Wiedmann  \n",
    "</p>\n",
    "<p>\n",
    "Ying Tung (Debbie) Lau\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "In this project, we are taking three sources of movie review data (csv, tsv, web scraping) and aiming to create weak labelling functions based on the data. The objective of the project is to compare the performance of a machine learning based classifier with that of the combination of weak labelling functions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Review Data\n",
    "\n",
    "We split the work of obtaining data to three group members (Hong, Debbie, Vera) . Hong was responsible for scraping movie reviews from the rotten tomato website, while Debbie and Vera sought for other data formats like tsv and csv to ensure the sufficiency of data sample. \n",
    "\n",
    "The dataset contains two columns: one is the text review posted by people, another is the label 1 or 0. 1 indicates a positive review (fresh), and 0 indicates an non-positive review (not fresh).\n",
    "\n",
    "The final dataset consists of 15000 reviews in total, with 5000 from web scrapping, 5000 from csv file, and 5000 from tsv file. \n",
    "\n",
    "We further sampled 2000 data points for labelling function development (development data set) and made sure the positive and non-positive reviews had the same amounts. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building classifiers \n",
    "\n",
    "Arda was responsible for building a NLP classifier, which will be later applied to compare with the labelling function classifier. This model was done by utilizing tokens generated from two types of reviews and fed as features. This NLP classifier yielded 70% accuracy on the testing set. \n",
    "Arda also implemented the spark on Faculty so that the following labelling functions can be implemented in a spark environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Labelling functions\n",
    "\n",
    "Meanwhile, the rest of the team members worked on generating weak labelling functions based on the findings in data exploration. \n",
    "\n",
    "During data exploration, as implementing spark slowed down the computation process as it partitions the dataset, we chose to use pandas to notice any patterns and differences in positive and non-positive reviews. We faced a few challenges in this stage. For example, we built a lemmatization function on the word count dataframe to avoid classifier bias caused by word inflections. However, many words were converted into completely different words incorrectly. Due to the mis-correction on words, we decided not to use lemmatization. \n",
    "\n",
    "As for building the labelling functions, Katie looked for stop words in the review first and counted the word occurrences in positive reviews and negative reviews. By identifying the difference in the word occurrences, we built our labelling functions to separate positive and non-positive reviews based on exclusive words. \n",
    "\n",
    "We also looked for capital letters mentioned in each type of reviews, but since the capital letters were irrelevant to emotions and most didn’t make sense for understanding, we decided not to create a labelling function based on it.\n",
    "\n",
    "As we noticed keywords like “too” and “far” occurred more often in a specific type of reviews, so other labelling functions were created based on the keywords. \n",
    "Similarly, exclamation mark and question mark also appeared more often in one type of reviews, so we created labelling functions based on them as well.\n",
    "\n",
    "After finalising the labeling functions, Arda built a classifier to combine the labeling functions together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "<>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub\n",
    "Every time we made a change, we used terminal in Faculty to push the changes to our group repository. \n",
    "After committing the change, we used “git status” to double check the state of repository. Using “git diff” also enables us to see all the changes in repository.\n",
    "\n",
    "Link to GitHub repository:\n",
    "https://github.com/KatharinaWiedmann/DataEngGroupProject.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIRA board \n",
    "We used JIRA to manage the progress of our project and record our meeting topics. The brief of meetings is shown as below:\n",
    "<p>\n",
    "First meeting:\n",
    "•\tRotten Tomatoes labelling functions - good movie or not (positive/ negative rating). \n",
    "•\tTwitter data: Labelling whether someone is a Boris Johnson supporter or not. \n",
    "•\tYouTube comments: positive or negative comment \n",
    "•\tPromotion emails - is an email a spam email or a genuine email. \n",
    "</p>\n",
    "<p>\n",
    "Second meeting:\n",
    "•\tLabelling functions (Vera, Debbie, Katie) \n",
    "•\tClassifier (Arda) \n",
    "•\tWeb Scraping (Hong) \n",
    "•\tGitHub (Katie)\n",
    "</p>\n",
    "<p>\n",
    "Third meeting:\n",
    "•\tRewriting labelling functions (SparkLFApplier - done together)\n",
    "•\tCombining labelling functions (Hong & Katie)\n",
    "•\tAnalyzing summary/ results labelling functions (Hong & Katie)\n",
    "•\tPlug in classifier (Arda)\n",
    "•\tCompare results between using labelling functions and not labelling functions (Arda)\n",
    "•\tIterate on Mark-up/ write-down (Vera)\n",
    "•\tJIRA cleanup & additional notes (Katie)\n",
    "•\tGithub reminder - don't forget to push/ pull (everyone)\n",
    "•\tMake sensitivity analysis work (Debbie) \n",
    "•\tnt function (Hong)\n",
    "</p>\n",
    "\n",
    "Further details can be found at:\n",
    "http://csjira2.cs.ucl.ac.uk:8080/secure/RapidBoard.jspa?rapidView=316&view=detail&selectedIssue=DED-16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas==0.24.2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-0.24.2              |   py36he6710b0_0         8.5 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.5 MB\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  pandas                               1.0.1-py36h0573a6f_0 --> 0.24.2-py36he6710b0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pandas-0.24.2        | 8.5 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pandas==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install networkx==2.3.0\n",
    "# run once and then need to restart the kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    gunicorn-20.0.4            |           py36_0         125 KB\n",
      "    libssh2-1.9.0              |       h1ba5d50_1         269 KB\n",
      "    nb_conda_kernels-2.2.2     |           py36_0          39 KB\n",
      "    plotly-4.5.2               |             py_0         1.6 MB\n",
      "    setuptools-46.0.0          |           py36_0         519 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.5 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  gunicorn                                    19.9.0-py36_0 --> 20.0.4-py36_0\n",
      "  libssh2                                  1.8.2-h1ba5d50_0 --> 1.9.0-h1ba5d50_1\n",
      "  nb_conda_kernels                             2.1.1-py36_1 --> 2.2.2-py36_0\n",
      "  pandas                              0.24.2-py36he6710b0_0 --> 1.0.1-py36h0573a6f_0\n",
      "  plotly                                         4.5.0-py_0 --> 4.5.2-py_0\n",
      "  setuptools                                  45.2.0-py36_0 --> 46.0.0-py36_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "gunicorn-20.0.4      | 125 KB    | ##################################### | 100% \n",
      "setuptools-46.0.0    | 519 KB    | ##################################### | 100% \n",
      "nb_conda_kernels-2.2 | 39 KB     | ##################################### | 100% \n",
      "libssh2-1.9.0        | 269 KB    | ##################################### | 100% \n",
      "plotly-4.5.2         | 1.6 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: - b'+ /opt/anaconda/envs/Python3/bin/python -m nb_conda_kernels.install --disable --prefix=/opt/anaconda/envs/Python3\\nDisabling nb_conda_kernels...\\nDisabled nb_conda_kernels\\n'\n",
      "/ b'Enabling nb_conda_kernels...\\nStatus: enabled\\n'\n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda upgrade --all -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - networkx==2.3.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    networkx-2.3               |             py_0         1.1 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.1 MB\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  networkx                                         2.4-py_0 --> 2.3-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "networkx-2.3         | 1.1 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install networkx==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#needs to show version 2.3\n",
    "\n",
    "import networkx as nx\n",
    "nx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - snorkel==0.9.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
      "    certifi-2019.11.28         |   py36h9f0ad1d_1         149 KB  conda-forge\n",
      "    cudatoolkit-10.0.130       |                0       261.2 MB\n",
      "    cudnn-7.6.5                |       cuda10.0_0       165.0 MB\n",
      "    libprotobuf-3.11.3         |       h8b12597_0         4.8 MB  conda-forge\n",
      "    ninja-1.10.0               |       hdb11119_1         1.9 MB  conda-forge\n",
      "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
      "    pandas-0.24.2              |   py36hb3f55d8_1        11.1 MB  conda-forge\n",
      "    protobuf-3.11.3            |   py36he1b5a44_0         696 KB  conda-forge\n",
      "    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n",
      "    pytorch-1.1.0              |cuda100py36he554f03_0       196.2 MB\n",
      "    scikit-learn-0.21.3        |   py36hd81dba3_0         5.0 MB\n",
      "    snorkel-0.9.0              |             py_0          85 KB  conda-forge\n",
      "    tensorboardx-1.9           |             py_0          75 KB  conda-forge\n",
      "    tqdm-4.43.0                |             py_0          47 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       648.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0\n",
      "  cudnn              pkgs/main/linux-64::cudnn-7.6.5-cuda10.0_0\n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.11.3-h8b12597_0\n",
      "  ninja              conda-forge/linux-64::ninja-1.10.0-hdb11119_1\n",
      "  protobuf           conda-forge/linux-64::protobuf-3.11.3-py36he1b5a44_0\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.6-1_cp36m\n",
      "  pytorch            pkgs/main/linux-64::pytorch-1.1.0-cuda100py36he554f03_0\n",
      "  snorkel            conda-forge/noarch::snorkel-0.9.0-py_0\n",
      "  tensorboardx       conda-forge/noarch::tensorboardx-1.9-py_0\n",
      "  tqdm               conda-forge/noarch::tqdm-4.43.0-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi              pkgs/main::certifi-2019.11.28-py36_0 --> conda-forge::certifi-2019.11.28-py36h9f0ad1d_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
      "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
      "  pandas             pkgs/main::pandas-1.0.1-py36h0573a6f_0 --> conda-forge::pandas-0.24.2-py36hb3f55d8_1\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  scikit-learn                        0.22.1-py36hd81dba3_0 --> 0.21.3-py36hd81dba3_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "tensorboardx-1.9     | 75 KB     | ##################################### | 100% \n",
      "ninja-1.10.0         | 1.9 MB    | ##################################### | 100% \n",
      "cudnn-7.6.5          | 165.0 MB  | ##################################### | 100% \n",
      "ca-certificates-2019 | 145 KB    | ##################################### | 100% \n",
      "cudatoolkit-10.0.130 | 261.2 MB  | ##################################### | 100% \n",
      "python_abi-3.6       | 4 KB      | ##################################### | 100% \n",
      "certifi-2019.11.28   | 149 KB    | ##################################### | 100% \n",
      "pytorch-1.1.0        | 196.2 MB  | ##################################### | 100% \n",
      "pandas-0.24.2        | 11.1 MB   | ##################################### | 100% \n",
      "snorkel-0.9.0        | 85 KB     | ##################################### | 100% \n",
      "scikit-learn-0.21.3  | 5.0 MB    | ##################################### | 100% \n",
      "protobuf-3.11.3      | 696 KB    | ##################################### | 100% \n",
      "openssl-1.1.1d       | 2.1 MB    | ##################################### | 100% \n",
      "tqdm-4.43.0          | 47 KB     | ##################################### | 100% \n",
      "libprotobuf-3.11.3   | 4.8 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install snorkel==0.9.0 -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - textblob\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    textblob-0.15.3            |             py_0         595 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         595 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  textblob           conda-forge/noarch::textblob-0.15.3-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "textblob-0.15.3      | 595 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier,LabelModel\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from itertools import repeat\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n",
      "<pyspark.sql.session.SparkSession object at 0x7f0dd9209d30>\n"
     ]
    }
   ],
   "source": [
    "#Spark \n",
    "\n",
    "# Spark Environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "import pyspark\n",
    "\n",
    "number_cores = 4\n",
    "memory_gb = 16\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "print(sc)\n",
    "\n",
    "# get the context\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "print(spark) \n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse all from DVD releases page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = 'https://www.rottentomatoes.com/api/private/v2.0/browse?maxTomato=100&services=amazon%3Bhbo_go%3Bitunes%3Bnetflix_iw%3Bvudu%3Bamazon_prime%3Bfandango_now&certified&sortBy=release&type=dvd-streaming-all&page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get movie url\n",
    "movie_url = []\n",
    "start_page = 1 ; end_page = 1\n",
    "while start_page <= end_page:\n",
    "#     time.sleep(7)\n",
    "    url = main + str(start_page)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code !=200:\n",
    "        print('Request error')\n",
    "        break\n",
    "    file = json.loads(response.text)\n",
    "    for i in file['results']:\n",
    "        movie_url = movie_url + [i['url']]\n",
    "    start_page +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples for the url:\n",
      "\n",
      "/m/frozen_ii\n",
      "/m/playmobil_the_movie\n",
      "/m/charlies_angels_2019\n",
      "\n",
      "Number of movies in list: 32\n"
     ]
    }
   ],
   "source": [
    "print('Examples for the url:\\n')\n",
    "for i in range(3):\n",
    "    print(movie_url[i])\n",
    "print('\\nNumber of movies in list: {}'.format(len(movie_url)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into lists of 50 movies to do the scraping\n",
    "movie_url_split = [movie_url[i:i+50] for i in range(0,600,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_url_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reviews from the web\n",
    "reviews = []\n",
    "titles = []\n",
    "ratings = []\n",
    "for split in movie_url_split: # Loop through each split\n",
    "#     time.sleep(7)\n",
    "    for title in split: # Loop through each movie title\n",
    "        url = 'https://www.rottentomatoes.com'+title\n",
    "#         time.sleep(7)\n",
    "        response = requests.get(url)\n",
    "        # Check the request status code\n",
    "        if response.status_code != 200:\n",
    "            print('Request error')\n",
    "            break\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Get labels from each review (fresh vs. rotten)\n",
    "        fresh_rotten = soup.find_all(class_=\"review_quote\")\n",
    "        \n",
    "        # Get movie title\n",
    "        title = soup.find(class_=\"mop-ratings-wrap__title mop-ratings-wrap__title--top\").getText()\n",
    "        \n",
    "        # Get reviews\n",
    "        review = soup.find_all('blockquote')\n",
    "        for i in review:\n",
    "            j = str(i.contents[1])\n",
    "            j = j.replace(\"<p>\\n                    \\n                        \",\"\")\n",
    "            j = j.replace(\"\\n                    \\n                </p>\",\"\")\n",
    "            reviews = reviews + [j]\n",
    "            titles = titles + [title]\n",
    "        \n",
    "        # Identify labels\n",
    "        for i in fresh_rotten:\n",
    "            temp = str(i.findChildren()[2])\n",
    "            if re.search('rotten',temp):\n",
    "                ratings = ratings + ['rotten']\n",
    "            else:\n",
    "                ratings = ratings + ['fresh']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame to store the scraped data\n",
    "df = pd.DataFrame([titles,reviews,ratings],index = ['title','review','rating']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 327 entries, 0 to 328\n",
      "Data columns (total 3 columns):\n",
      "title     327 non-null object\n",
      "review    327 non-null object\n",
      "rating    327 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 10.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Clean the data (drop duplicates, check missing values etc.)\n",
    "df = df.drop_duplicates()\n",
    "df = df.replace([None],np.nan)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>A distressingly unnecessary (and fairly tediou...</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>Frozen II is the exact kind of sequel that mor...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>[A]n ultimately satisfying story of more matur...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                             review  rating\n",
       "0  Frozen II  A distressingly unnecessary (and fairly tediou...  rotten\n",
       "1  Frozen II  Frozen II is the exact kind of sequel that mor...   fresh\n",
       "2  Frozen II  [A]n ultimately satisfying story of more matur...   fresh"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV files\n",
    "# df.to_csv('web_scraping_rotten_tomatoes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Preparing TSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TSV file\n",
    "tsv_reviews = pd.read_csv('/project/reviews.tsv', sep='\\t', header=0, encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>fresh</th>\n",
       "      <th>critic</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A distinctly gallows take on contemporary fina...</td>\n",
       "      <td>3/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>PJ Nabarro</td>\n",
       "      <td>0</td>\n",
       "      <td>Patrick Nabarro</td>\n",
       "      <td>November 10, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>It's an allegory in search of a meaning that n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotten</td>\n",
       "      <td>Annalee Newitz</td>\n",
       "      <td>0</td>\n",
       "      <td>io9.com</td>\n",
       "      <td>May 23, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>... life lived in a bubble in financial dealin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Sean Axmaker</td>\n",
       "      <td>0</td>\n",
       "      <td>Stream on Demand</td>\n",
       "      <td>January 4, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Continuing along a line introduced in last yea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Daniel Kasman</td>\n",
       "      <td>0</td>\n",
       "      <td>MUBI</td>\n",
       "      <td>November 16, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>... a perverse twist on neorealism...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Cinema Scope</td>\n",
       "      <td>October 12, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review rating   fresh  \\\n",
       "0   3  A distinctly gallows take on contemporary fina...    3/5   fresh   \n",
       "1   3  It's an allegory in search of a meaning that n...    NaN  rotten   \n",
       "2   3  ... life lived in a bubble in financial dealin...    NaN   fresh   \n",
       "3   3  Continuing along a line introduced in last yea...    NaN   fresh   \n",
       "4   3             ... a perverse twist on neorealism...     NaN   fresh   \n",
       "\n",
       "           critic  top_critic         publisher               date  \n",
       "0      PJ Nabarro           0   Patrick Nabarro  November 10, 2018  \n",
       "1  Annalee Newitz           0           io9.com       May 23, 2018  \n",
       "2    Sean Axmaker           0  Stream on Demand    January 4, 2018  \n",
       "3   Daniel Kasman           0              MUBI  November 16, 2017  \n",
       "4             NaN           0      Cinema Scope   October 12, 2017  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract review and fresh columns\n",
    "tsv_reviews = pd.DataFrame(tsv_reviews, columns = ['review', 'fresh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>fresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A distinctly gallows take on contemporary fina...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's an allegory in search of a meaning that n...</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... life lived in a bubble in financial dealin...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Continuing along a line introduced in last yea...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>... a perverse twist on neorealism...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review   fresh\n",
       "0  A distinctly gallows take on contemporary fina...   fresh\n",
       "1  It's an allegory in search of a meaning that n...  rotten\n",
       "2  ... life lived in a bubble in financial dealin...   fresh\n",
       "3  Continuing along a line introduced in last yea...   fresh\n",
       "4             ... a perverse twist on neorealism...    fresh"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    5563\n",
       "fresh        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN rows in reviews\n",
    "index_name = tsv_reviews[(tsv_reviews['review'].isnull())].index\n",
    "tsv_reviews.drop(index_name, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    0\n",
       "fresh     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename fresh as 1 and rotten as 0\n",
    "tsv_reviews['fresh'].replace({'fresh':'1', 'rotten':'0'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 11663 to 43278\n",
      "Data columns (total 2 columns):\n",
      "Review       5000 non-null object\n",
      "Freshness    5000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Rename columns\n",
    "tsv_reviews.rename(columns={'fresh':'Freshness','review':'Review'},inplace=True)\n",
    "tsv_reviews = tsv_reviews.sample(5000)\n",
    "#take 5000\n",
    "tsv_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Preparing CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Freshness                                             Review\n",
       "0          1   Manakamana doesn't answer any questions, yet ...\n",
       "1          1   Wilfully offensive and powered by a chest-thu...\n",
       "2          0   It would be difficult to imagine material mor...\n",
       "3          0   Despite the gusto its star brings to the role...\n",
       "4          0   If there was a good idea at the core of this ..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file\n",
    "csv_reviews= pd.read_csv('/project/rotten_tomatoes_reviews.csv')\n",
    "csv_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360008</th>\n",
       "      <td>A modern-day, screwball reimagining of Thomas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282820</th>\n",
       "      <td>Evans makes Mr. Brooks the CEO of a box facto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243035</th>\n",
       "      <td>Trite and boring portrait of rich and self-ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14495</th>\n",
       "      <td>Charlize Theron and Kim Bassinger star in an ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138710</th>\n",
       "      <td>The soft and derivative script by newcomer Gu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "360008   A modern-day, screwball reimagining of Thomas...          1\n",
       "282820   Evans makes Mr. Brooks the CEO of a box facto...          0\n",
       "243035   Trite and boring portrait of rich and self-ab...          0\n",
       "14495    Charlize Theron and Kim Bassinger star in an ...          1\n",
       "138710   The soft and derivative script by newcomer Gu...          0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 360008 to 319989\n",
      "Data columns (total 2 columns):\n",
      "Review       5000 non-null object\n",
      "Freshness    5000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Swap Freshness and Review \n",
    "columns_titles = [\"Review\",\"Freshness\"]\n",
    "csv_reviews=csv_reviews.reindex(columns=columns_titles)\n",
    "csv_reviews = csv_reviews.sample(5000)\n",
    "\n",
    "csv_reviews.head()\n",
    "csv_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping & Preparing scrapped data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>Babenco's cinematic farewell isn't perfect by ...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>This is a good film if you are looking for som...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>My Hindu Friend is a celebration of life, love...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>I wouldn't miss it; it's a film that's more th...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>...surreal, reflective (though never sentiment...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              title  \\\n",
       "0           0  My Hindu Friend (Meu amigo Hindu)   \n",
       "1           1  My Hindu Friend (Meu amigo Hindu)   \n",
       "2           2  My Hindu Friend (Meu amigo Hindu)   \n",
       "3           3  My Hindu Friend (Meu amigo Hindu)   \n",
       "4           4  My Hindu Friend (Meu amigo Hindu)   \n",
       "\n",
       "                                              review rating  \n",
       "0  Babenco's cinematic farewell isn't perfect by ...  fresh  \n",
       "1  This is a good film if you are looking for som...  fresh  \n",
       "2  My Hindu Friend is a celebration of life, love...  fresh  \n",
       "3  I wouldn't miss it; it's a film that's more th...  fresh  \n",
       "4  ...surreal, reflective (though never sentiment...  fresh  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Web Scraping Data\n",
    "web_scraping_reviews= pd.read_csv('/project/web_scraping_rotten_tomatoes.csv')\n",
    "web_scraping_reviews.head()\n",
    "\n",
    "web_scraping_reviews = web_scraping_reviews.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>312</td>\n",
       "      <td>Inherit the Viper</td>\n",
       "      <td>\"Inherit the Viper\" isn't surprising, but it's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>1951</td>\n",
       "      <td>Liam Gallagher: As It Was</td>\n",
       "      <td>... essentially a filmed press release from pu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>1618</td>\n",
       "      <td>The Farewell</td>\n",
       "      <td>The Farewell is among 2019's best films. It be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>545</td>\n",
       "      <td>Leslie Jones: Time Machine</td>\n",
       "      <td>Giving Jones an hour or more in the spotlight ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>The Trouble with You (En liberté!)</td>\n",
       "      <td>...the type of commercial French filmmaking wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                               title  \\\n",
       "312          312                   Inherit the Viper   \n",
       "1951        1951           Liam Gallagher: As It Was   \n",
       "1618        1618                        The Farewell   \n",
       "545          545          Leslie Jones: Time Machine   \n",
       "29            29  The Trouble with You (En liberté!)   \n",
       "\n",
       "                                                 Review Freshness  \n",
       "312   \"Inherit the Viper\" isn't surprising, but it's...         1  \n",
       "1951  ... essentially a filmed press release from pu...         0  \n",
       "1618  The Farewell is among 2019's best films. It be...         1  \n",
       "545   Giving Jones an hour or more in the spotlight ...         1  \n",
       "29    ...the type of commercial French filmmaking wh...         1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename fresh as 1 and rotten as 0\n",
    "web_scraping_reviews['rating'].replace({'fresh':'1', 'rotten':'0'}, inplace = True)\n",
    "\n",
    "#Rename Rating to Review \n",
    "web_scraping_reviews.rename(columns={'rating':'Freshness', 'review':'Review'},inplace=True)\n",
    "web_scraping_reviews.head()\n",
    "\n",
    "# Extract Review and Freshness columns\n",
    "web_scraping_reviews= pd.DataFrame(web_scraping_reviews, columns = ['Review', 'Freshness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>\"Inherit the Viper\" isn't surprising, but it's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>... essentially a filmed press release from pu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>The Farewell is among 2019's best films. It be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Giving Jones an hour or more in the spotlight ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>...the type of commercial French filmmaking wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review Freshness\n",
       "312   \"Inherit the Viper\" isn't surprising, but it's...         1\n",
       "1951  ... essentially a filmed press release from pu...         0\n",
       "1618  The Farewell is among 2019's best films. It be...         1\n",
       "545   Giving Jones an hour or more in the spotlight ...         1\n",
       "29    ...the type of commercial French filmmaking wh...         1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_scraping_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all the data together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360008</th>\n",
       "      <td>A modern-day, screwball reimagining of Thomas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282820</th>\n",
       "      <td>Evans makes Mr. Brooks the CEO of a box facto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243035</th>\n",
       "      <td>Trite and boring portrait of rich and self-ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14495</th>\n",
       "      <td>Charlize Theron and Kim Bassinger star in an ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138710</th>\n",
       "      <td>The soft and derivative script by newcomer Gu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review Freshness\n",
       "360008   A modern-day, screwball reimagining of Thomas...         1\n",
       "282820   Evans makes Mr. Brooks the CEO of a box facto...         0\n",
       "243035   Trite and boring portrait of rich and self-ab...         0\n",
       "14495    Charlize Theron and Kim Bassinger star in an ...         1\n",
       "138710   The soft and derivative script by newcomer Gu...         0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv_reviews.info()\n",
    "# tsv_reviews.info()\n",
    "# web_scraping_reviews.info()\n",
    "\n",
    "\n",
    "\n",
    "# Concat two files into all_reviews\n",
    "all_reviews=pd.concat([csv_reviews, tsv_reviews,web_scraping_reviews],axis=0, sort=False)\n",
    "all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into test and training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews['Freshness'] = all_reviews['Freshness'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(all_reviews,test_size=0.2,stratify = all_reviews['Freshness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 446760 to 122956\n",
      "Data columns (total 2 columns):\n",
      "Review       12000 non-null object\n",
      "Freshness    12000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 281.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000 entries, 5704 to 208474\n",
      "Data columns (total 2 columns):\n",
      "Review       3000 non-null object\n",
      "Freshness    3000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 70.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446760</th>\n",
       "      <td>An excessively convoluted rehash of its prede...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44418</th>\n",
       "      <td>Osment's the weak link in the movie and becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27216</th>\n",
       "      <td>If you want to see some spectacularly adorable...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24133</th>\n",
       "      <td>Not only do we rarely get to participate in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19332</th>\n",
       "      <td>You never know what to expect from Martin McDo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "446760   An excessively convoluted rehash of its prede...          0\n",
       "44418   Osment's the weak link in the movie and becaus...          1\n",
       "27216   If you want to see some spectacularly adorable...          1\n",
       "24133   Not only do we rarely get to participate in th...          0\n",
       "19332   You never know what to expect from Martin McDo...          1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid off training labels \n",
    "train = train.drop('Freshness', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1785\n",
       "0    1215\n",
       "Name: Freshness, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Freshness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>It won't have much cinematic impact...but I qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5314</th>\n",
       "      <td>Serenity is a film that seems to reject unders...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272692</th>\n",
       "      <td>The rare kind of spellbinding, wonderful film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201190</th>\n",
       "      <td>John Ford's most complete vision about the pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30750</th>\n",
       "      <td>Lampoons ethnocentrism and celebrates the valu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "3154    It won't have much cinematic impact...but I qu...          1\n",
       "5314    Serenity is a film that seems to reject unders...          1\n",
       "272692   The rare kind of spellbinding, wonderful film...          1\n",
       "201190   John Ford's most complete vision about the pa...          0\n",
       "30750   Lampoons ethnocentrism and celebrates the valu...          1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From labelled test set, extract a sample to find out about which labelling functions could be written\n",
    "#Not sure how big the development split_ can be --> take sample of 1000 data points \n",
    "\n",
    "development_split = test.sample(2000,random_state=42)\n",
    "development_split.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test2000.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1000 = pd.merge(test,test2000,how='left',on = 'Review')\n",
    "# test1000 = test1000[test1000.Freshness_y.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1000.drop('Freshness_y',axis=1, inplace=True)\n",
    "# test1000.columns = ['Review','Freshness']\n",
    "# test1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1000.to_csv('1000_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>It won't have much cinematic impact...but I qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5314</th>\n",
       "      <td>Serenity is a film that seems to reject unders...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272692</th>\n",
       "      <td>The rare kind of spellbinding, wonderful film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201190</th>\n",
       "      <td>John Ford's most complete vision about the pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30750</th>\n",
       "      <td>Lampoons ethnocentrism and celebrates the valu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50054</th>\n",
       "      <td>Everything about Benson Lee's predictable danc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34473</th>\n",
       "      <td>The talented cast is left high and dry by writ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6679</th>\n",
       "      <td>The film dares its viewers to consider that--f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>While [All the Bright Places] remains sensitiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11272</th>\n",
       "      <td>Great fights. You wouldn't think of Damon as a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45169</th>\n",
       "      <td>Supremacy is briskly paced and the screenwriti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27674</th>\n",
       "      <td>In these linked vignettes, Another Year paint...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331453</th>\n",
       "      <td>Ultimately \"Shopgirl\" is an attractive but em...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>At its core, Harpoon isn't aiming for deep sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>A cloned human is created by no god, but a hum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33175</th>\n",
       "      <td>Hitchcock once famously said that a good filmm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>Killerman is the story of how an antihero is c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313249</th>\n",
       "      <td>Arguably one of the most important Egyptian f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29073</th>\n",
       "      <td>The breezy manner with which the musical sends...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79331</th>\n",
       "      <td>Very nearly as inventive and fascinating as i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54223</th>\n",
       "      <td>'Snakes are definitely a mid-air danger,' said...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37444</th>\n",
       "      <td>Despite the supposed passion that such materia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46597</th>\n",
       "      <td>The comedy and drama simply don't jive and the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47151</th>\n",
       "      <td>It is a fable, albeit a dark and twisted one d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Filmmaker Juan Cabral presents a muddled philo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20273</th>\n",
       "      <td>Middlebrow self-consciousness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27951</th>\n",
       "      <td>There is something adorably British about Nick...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444915</th>\n",
       "      <td>uses its R rating as perhaps an eight-year-ol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>Will leave old and new fans satisfied. [Full r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36072</th>\n",
       "      <td>It's hard to say what the creators of \"Space ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40328</th>\n",
       "      <td>The chicken and his dad seem to feel a bit li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Modern horror comedy that resonates due to the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286196</th>\n",
       "      <td>It's hardly surprising that Beresford's retur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52478</th>\n",
       "      <td>A bit shapeless as a story but relies on the c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>Joan Stanley's story of means and ends opens i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52199</th>\n",
       "      <td>Del's repeatedly attacked by bad robots, marke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>Critters Attack! might entertain the biggest B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Give it a spin, but just be warned, it's more ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53508</th>\n",
       "      <td>Cameron Crowe remains, as always, uncool. And ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13962</th>\n",
       "      <td>Surprisingly adapted from a novel, Date is sac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11116</th>\n",
       "      <td>Bereford makes the best of a workmanlike scrip...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21553</th>\n",
       "      <td>Never terribly clever, but always intestinall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51144</th>\n",
       "      <td>...moves you the most when it pauses to liste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24641</th>\n",
       "      <td>The film loses the most credibility.. near the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>Earthquake Bird is somewhat laborious in makin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51623</th>\n",
       "      <td>The use of digital effects to place Wayans' fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17123</th>\n",
       "      <td>When you stop looking at the forest, you'll se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232827</th>\n",
       "      <td>The film is sweet, simplified and a bit syrup...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12583</th>\n",
       "      <td>[Empire of the Sun] has too much childish buoy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448810</th>\n",
       "      <td>A predictably woeful affair that achieves the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30206</th>\n",
       "      <td>...a meditation on the nature of celebrity and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449774</th>\n",
       "      <td>There's something tedious about this film, pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117159</th>\n",
       "      <td>The protagonists' aimless drug- and sex-fuell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374699</th>\n",
       "      <td>With no Michael Sheen this time around and Ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372176</th>\n",
       "      <td>Ek Thi Daayan starts out as a well-acted, wel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173907</th>\n",
       "      <td>Canopy succeeds on its own modest, limited te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31535</th>\n",
       "      <td>Jesus Is Magic manages to push hot buttons wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>A potentially provocative concept becomes lost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4189</th>\n",
       "      <td>Better at personalizing the experiences and co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41164</th>\n",
       "      <td>It's difficult to say which is worse--Allcroft...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "3154    It won't have much cinematic impact...but I qu...          1\n",
       "5314    Serenity is a film that seems to reject unders...          1\n",
       "272692   The rare kind of spellbinding, wonderful film...          1\n",
       "201190   John Ford's most complete vision about the pa...          0\n",
       "30750   Lampoons ethnocentrism and celebrates the valu...          1\n",
       "50054   Everything about Benson Lee's predictable danc...          0\n",
       "34473   The talented cast is left high and dry by writ...          0\n",
       "6679    The film dares its viewers to consider that--f...          1\n",
       "5863    While [All the Bright Places] remains sensitiv...          0\n",
       "11272   Great fights. You wouldn't think of Damon as a...          1\n",
       "45169   Supremacy is briskly paced and the screenwriti...          1\n",
       "27674    In these linked vignettes, Another Year paint...          1\n",
       "331453   Ultimately \"Shopgirl\" is an attractive but em...          0\n",
       "1890    At its core, Harpoon isn't aiming for deep sta...          1\n",
       "290     A cloned human is created by no god, but a hum...          1\n",
       "33175   Hitchcock once famously said that a good filmm...          0\n",
       "1068    Killerman is the story of how an antihero is c...          0\n",
       "313249   Arguably one of the most important Egyptian f...          1\n",
       "29073   The breezy manner with which the musical sends...          1\n",
       "79331    Very nearly as inventive and fascinating as i...          1\n",
       "54223   'Snakes are definitely a mid-air danger,' said...          0\n",
       "37444   Despite the supposed passion that such materia...          0\n",
       "46597   The comedy and drama simply don't jive and the...          0\n",
       "47151   It is a fable, albeit a dark and twisted one d...          1\n",
       "93      Filmmaker Juan Cabral presents a muddled philo...          0\n",
       "20273                       Middlebrow self-consciousness          0\n",
       "27951   There is something adorably British about Nick...          1\n",
       "444915   uses its R rating as perhaps an eight-year-ol...          0\n",
       "4839    Will leave old and new fans satisfied. [Full r...          1\n",
       "36072    It's hard to say what the creators of \"Space ...          0\n",
       "...                                                   ...        ...\n",
       "40328    The chicken and his dad seem to feel a bit li...          1\n",
       "944     Modern horror comedy that resonates due to the...          1\n",
       "286196   It's hardly surprising that Beresford's retur...          1\n",
       "52478   A bit shapeless as a story but relies on the c...          1\n",
       "3126    Joan Stanley's story of means and ends opens i...          1\n",
       "52199   Del's repeatedly attacked by bad robots, marke...          0\n",
       "3918    Critters Attack! might entertain the biggest B...          0\n",
       "957     Give it a spin, but just be warned, it's more ...          1\n",
       "53508   Cameron Crowe remains, as always, uncool. And ...          1\n",
       "13962   Surprisingly adapted from a novel, Date is sac...          0\n",
       "11116   Bereford makes the best of a workmanlike scrip...          1\n",
       "21553    Never terribly clever, but always intestinall...          1\n",
       "51144    ...moves you the most when it pauses to liste...          1\n",
       "24641   The film loses the most credibility.. near the...          0\n",
       "1359    Earthquake Bird is somewhat laborious in makin...          1\n",
       "51623   The use of digital effects to place Wayans' fa...          0\n",
       "17123   When you stop looking at the forest, you'll se...          1\n",
       "232827   The film is sweet, simplified and a bit syrup...          1\n",
       "12583   [Empire of the Sun] has too much childish buoy...          0\n",
       "448810   A predictably woeful affair that achieves the...          0\n",
       "30206   ...a meditation on the nature of celebrity and...          1\n",
       "449774   There's something tedious about this film, pa...          0\n",
       "117159   The protagonists' aimless drug- and sex-fuell...          0\n",
       "374699   With no Michael Sheen this time around and Ch...          0\n",
       "372176   Ek Thi Daayan starts out as a well-acted, wel...          1\n",
       "173907   Canopy succeeds on its own modest, limited te...          1\n",
       "31535    Jesus Is Magic manages to push hot buttons wi...          1\n",
       "1466    A potentially provocative concept becomes lost...          0\n",
       "4189    Better at personalizing the experiences and co...          1\n",
       "41164   It's difficult to say which is worse--Allcroft...          0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For finding labelling functions: \n",
    "development_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       2000\n",
       "Freshness    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_split.to_csv('development_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# development_split = pd.read_csv('development_split.csv',index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       2000\n",
       "Freshness    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>It won't have much cinematic impact...but I qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5314</th>\n",
       "      <td>Serenity is a film that seems to reject unders...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272692</th>\n",
       "      <td>The rare kind of spellbinding, wonderful film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201190</th>\n",
       "      <td>John Ford's most complete vision about the pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30750</th>\n",
       "      <td>Lampoons ethnocentrism and celebrates the valu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "3154    It won't have much cinematic impact...but I qu...          1\n",
       "5314    Serenity is a film that seems to reject unders...          1\n",
       "272692   The rare kind of spellbinding, wonderful film...          1\n",
       "201190   John Ford's most complete vision about the pa...          0\n",
       "30750   Lampoons ethnocentrism and celebrates the valu...          1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       823\n",
       "Freshness    823\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Might have to get rid off index?\n",
    "\n",
    "development_split[development_split['Freshness'] !=1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1177\n",
       "0     823\n",
       "Name: Freshness, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split['Freshness'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_split = pd.read_csv('development_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3154</td>\n",
       "      <td>It won't have much cinematic impact...but I qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5314</td>\n",
       "      <td>Serenity is a film that seems to reject unders...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>272692</td>\n",
       "      <td>The rare kind of spellbinding, wonderful film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30750</td>\n",
       "      <td>Lampoons ethnocentrism and celebrates the valu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6679</td>\n",
       "      <td>The film dares its viewers to consider that--f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Review  Freshness\n",
       "0        3154  It won't have much cinematic impact...but I qu...          1\n",
       "1        5314  Serenity is a film that seems to reject unders...          1\n",
       "2      272692   The rare kind of spellbinding, wonderful film...          1\n",
       "4       30750  Lampoons ethnocentrism and celebrates the valu...          1\n",
       "7        6679  The film dares its viewers to consider that--f...          1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201190</td>\n",
       "      <td>John Ford's most complete vision about the pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50054</td>\n",
       "      <td>Everything about Benson Lee's predictable danc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34473</td>\n",
       "      <td>The talented cast is left high and dry by writ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5863</td>\n",
       "      <td>While [All the Bright Places] remains sensitiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>331453</td>\n",
       "      <td>Ultimately \"Shopgirl\" is an attractive but em...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                             Review  Freshness\n",
       "3       201190   John Ford's most complete vision about the pa...          0\n",
       "5        50054  Everything about Benson Lee's predictable danc...          0\n",
       "6        34473  The talented cast is left high and dry by writ...          0\n",
       "8         5863  While [All the Bright Places] remains sensitiv...          0\n",
       "12      331453   Ultimately \"Shopgirl\" is an attractive but em...          0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split_fresh = development_split[development_split['Freshness'] == 1]\n",
    "development_split_rotten = development_split[development_split['Freshness'] == 0]\n",
    "development_split_fresh.head()\n",
    "development_split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1177 entries, 0 to 1998\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    1177 non-null int64\n",
      "Review        1177 non-null object\n",
      "Freshness     1177 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 36.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 823 entries, 3 to 1999\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    823 non-null int64\n",
      "Review        823 non-null object\n",
      "Freshness     823 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 25.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# fresh reviews \n",
    "development_split_fresh.info()\n",
    "# rotten reviews \n",
    "development_split_rotten.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation \n",
    "def remove_punctuation(dataframe):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in dataframe.Review.str.lower():\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    it wont have much cinematic impactbut i quite ...\n",
       "1    serenity is a film that seems to reject unders...\n",
       "2     the rare kind of spellbinding wonderful film ...\n",
       "3    lampoons ethnocentrism and celebrates the valu...\n",
       "4    the film dares its viewers to consider thatfor...\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from fresh reviews & turn into Series\n",
    "split_fresh= pd.Series(remove_punctuation(development_split_fresh))\n",
    "split_fresh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordList = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\\\n",
    "                \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\\\n",
    "                \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\",\\\n",
    "                \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\",\\\n",
    "                \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\",\\\n",
    "                \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\",\\\n",
    "                \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\",\\\n",
    "                \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\\\n",
    "                \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords from fresh\n",
    "\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_fresh.replace(replacements, regex=True, inplace=True)\n",
    "split_fresh.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization and Count again\n",
    "def stem_recount(df):\n",
    "    import pandas as pd\n",
    "    # Lemmatization\n",
    "    from nltk import LancasterStemmer\n",
    "    st = LancasterStemmer()\n",
    "    newdf = df.copy()\n",
    "    for i in range(0,len(df)):\n",
    "        newdf.iloc[i,0] = st.stem(str(df.iloc[i,0])) \n",
    "        # Plz make sure the word column is the first column in df when using this function\n",
    "    \n",
    "    # Recount\n",
    "    duplicate = newdf[newdf.duplicated(['index'])]\n",
    "    # Plz make sure the 'index' is the column name consisting of words\n",
    "    for i in range(0,len(newdf)):\n",
    "        if i >= len(duplicate):\n",
    "            break\n",
    "        if newdf.iloc[i,0] == duplicate.iloc[i,0]:\n",
    "            newdf.iloc[i,1] = newdf.iloc[i,1] + duplicate.iloc[i,1]\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_fresh = split_fresh.str.split(expand=True).stack().value_counts()\n",
    "common_words_fresh_df = pd.DataFrame(common_words_fresh)\n",
    "common_words_fresh_df = common_words_fresh_df.rename({0:'Occurence good review'}, axis='columns')\n",
    "new_common_words_fresh_df = common_words_fresh_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movy</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lik</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ful</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>span</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>film</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>review</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>good</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tim</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ev</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>best</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fun</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>funny</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>comedy</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gre</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mak</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>may</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lov</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>way</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>charact</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>us</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lif</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>yet</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>direct</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>doesnt</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ther</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>much</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>littl</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>clev</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>merciless</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>insufficy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>stat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>amand</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>reunit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>diary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>am</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6001</th>\n",
       "      <td>warn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>wint</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003</th>\n",
       "      <td>duel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>shangha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>oneofakind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6006</th>\n",
       "      <td>biograph</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>magn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6008</th>\n",
       "      <td>profess</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6009</th>\n",
       "      <td>grab</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>surpass</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>breezy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6012</th>\n",
       "      <td>trad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6013</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>wayn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6015</th>\n",
       "      <td>hang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016</th>\n",
       "      <td>humorless</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>lik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>whiskey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6019</th>\n",
       "      <td>tir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6020</th>\n",
       "      <td>innoc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>fam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6022</th>\n",
       "      <td>nat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6023 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  Occurence good review\n",
       "0           film                    264\n",
       "1           movy                    113\n",
       "2             on                    103\n",
       "3          story                     81\n",
       "4            lik                     67\n",
       "5            ful                     59\n",
       "6           span                     54\n",
       "7           film                     54\n",
       "8         review                     53\n",
       "9           good                     48\n",
       "10           tim                     58\n",
       "11            ev                     44\n",
       "12          best                     44\n",
       "13           fun                     39\n",
       "14         funny                     37\n",
       "15        comedy                     37\n",
       "16           gre                     35\n",
       "17           mak                     34\n",
       "18           may                     34\n",
       "19           lov                     33\n",
       "20           way                     33\n",
       "21       charact                     32\n",
       "22            us                     32\n",
       "23           lif                     32\n",
       "24           yet                     31\n",
       "25        direct                     31\n",
       "26        doesnt                     31\n",
       "27          ther                     31\n",
       "28          much                     31\n",
       "29         littl                     31\n",
       "...          ...                    ...\n",
       "5993        clev                      1\n",
       "5994   merciless                      1\n",
       "5995   insufficy                      1\n",
       "5996        stat                      1\n",
       "5997       amand                      1\n",
       "5998      reunit                      1\n",
       "5999       diary                      1\n",
       "6000          am                      1\n",
       "6001        warn                      1\n",
       "6002        wint                      1\n",
       "6003        duel                      1\n",
       "6004     shangha                      1\n",
       "6005  oneofakind                      1\n",
       "6006    biograph                      1\n",
       "6007        magn                      1\n",
       "6008     profess                      1\n",
       "6009        grab                      1\n",
       "6010     surpass                      1\n",
       "6011      breezy                      1\n",
       "6012        trad                      1\n",
       "6013          10                      1\n",
       "6014        wayn                      1\n",
       "6015        hang                      1\n",
       "6016   humorless                      1\n",
       "6017         lik                      1\n",
       "6018     whiskey                      1\n",
       "6019         tir                      1\n",
       "6020       innoc                      1\n",
       "6021         fam                      1\n",
       "6022         nat                      1\n",
       "\n",
       "[6023 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_recount(new_common_words_fresh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>films</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characters</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yet</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doesnt</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theres</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inspiring</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respect</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refreshing</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obvious</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uneven</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treat</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dialogue</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationships</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understands</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seeing</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unapologetically</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imaginative</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essential</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talented</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christmas</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forced</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tour</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carry</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violent</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grownups</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broken</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cry</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wild</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indie</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nostalgia</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eye</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>found</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>787 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Occurence good review\n",
       "film                                210\n",
       "movie                               113\n",
       "one                                 103\n",
       "story                                81\n",
       "like                                 67\n",
       "full                                 59\n",
       "spanish                              54\n",
       "films                                54\n",
       "review                               53\n",
       "good                                 48\n",
       "time                                 44\n",
       "even                                 44\n",
       "best                                 44\n",
       "fun                                  39\n",
       "funny                                37\n",
       "comedy                               37\n",
       "great                                35\n",
       "make                                 34\n",
       "may                                  34\n",
       "love                                 33\n",
       "way                                  33\n",
       "characters                           32\n",
       "us                                   32\n",
       "life                                 32\n",
       "yet                                  31\n",
       "director                             31\n",
       "doesnt                               31\n",
       "theres                               31\n",
       "much                                 31\n",
       "little                               31\n",
       "...                                 ...\n",
       "career                                4\n",
       "inspiring                             4\n",
       "respect                               4\n",
       "refreshing                            4\n",
       "obvious                               4\n",
       "uneven                                4\n",
       "treat                                 4\n",
       "dialogue                              4\n",
       "relationships                         4\n",
       "understands                           4\n",
       "seeing                                4\n",
       "unapologetically                      4\n",
       "imaginative                           4\n",
       "essential                             4\n",
       "talented                              4\n",
       "christmas                             4\n",
       "forced                                4\n",
       "tour                                  4\n",
       "carry                                 4\n",
       "violent                               4\n",
       "grownups                              4\n",
       "head                                  4\n",
       "broken                                4\n",
       "cry                                   4\n",
       "wild                                  4\n",
       "indie                                 4\n",
       "nostalgia                             4\n",
       "eye                                   4\n",
       "found                                 4\n",
       "sex                                   4\n",
       "\n",
       "[787 rows x 1 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get most common words in positive reviews \n",
    "top_common_words_fresh = common_words_fresh_df[common_words_fresh_df['Occurence good review'] >=4]\n",
    "top_common_words_fresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** EXPLAIN WHY WE DONT USE LEMMATIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b> Reason for not using Lemmatization </b>\n",
    "\n",
    "<p>\n",
    "    Before counting the occurance of words in the movie review, we noticed that inflections in words may result in different occurances and thus generating bias during counting. For example, \"enjoy\" and \"enjoyed\" share the same root but would be counted separately if not using Lemmatization.\n",
    "    </p> \n",
    "    \n",
    "<p>\n",
    "    The function \"stem_recount\" takes the root of a word and recounts the occurences. However, it posed a disadvantage of mis-normalizing words into other completely different words. For example, \"movie\" was identified as \"movy\", and \"like\" was identified as \"lik\". We thought this disadvantage exceeds the benefits of correcting word inflection, so we decided to not implement it.\n",
    "    </p> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     john fords most complete vision about the pas...\n",
       "1    everything about benson lees predictable dance...\n",
       "2    the talented cast is left high and dry by writ...\n",
       "3    while all the bright places remains sensitive ...\n",
       "4     ultimately shopgirl is an attractive but empt...\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from rotten & turn into Series\n",
    "split_rotten= pd.Series(remove_punctuation(development_split_rotten))\n",
    "split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords from negative reviews\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_rotten.replace(replacements, regex=True, inplace=True)\n",
    "split_rotten.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get most common words in negative reviews \n",
    "\n",
    "common_words_rotten = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "common_words_rotten_df = pd.DataFrame(common_words_rotten)\n",
    "common_words_rotten_df = common_words_rotten_df.rename({0:'Occurence bad review'}, axis='columns')\n",
    "top_common_words_rotten = common_words_rotten_df[common_words_rotten_df['Occurence bad review'] >=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Occurence bad review\n",
       "film                    122\n",
       "movie                   114\n",
       "much                     58\n",
       "too                      54\n",
       "like                     51"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_common_words_rotten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of good and bad reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "We want to find out which of the words in the good list only appear in the good movies (and not in the bad movies), vice versa and base labeling functions on these findings. We first ened to prepare the data accordingly, before we can write the labelling functions.\n",
    "    <div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fresh_words_exclusive = top_common_words_fresh.merge(top_common_words_rotten, indicator='i', how='outer', left_index=True,\\\n",
    "                                                         right_index=True).query('i == \"left_only\"').drop('i', 1)\n",
    "\n",
    "top_rotten_words_exclusive = top_common_words_rotten.merge(top_common_words_fresh, indicator='i', how='outer', left_index=True,\\\n",
    "                                                           right_index=True).query('i == \"left_only\"').drop('i', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absurd</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accomplished</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>across</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acted</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Occurence good review  Occurence bad review\n",
       "able                            6.0                   NaN\n",
       "absurd                          5.0                   NaN\n",
       "accomplished                    5.0                   NaN\n",
       "across                          4.0                   NaN\n",
       "acted                           7.0                   NaN"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_fresh_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>achieve</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appealing</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barely</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Occurence bad review  Occurence good review\n",
       "achieve                     4.0                    NaN\n",
       "air                         5.0                    NaN\n",
       "appealing                   4.0                    NaN\n",
       "attempt                     7.0                    NaN\n",
       "barely                      5.0                    NaN"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rotten_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'absurd',\n",
       " 'accomplished',\n",
       " 'across',\n",
       " 'acted',\n",
       " 'actor',\n",
       " 'addition',\n",
       " 'adventure',\n",
       " 'age',\n",
       " 'albeit',\n",
       " 'allows',\n",
       " 'alone',\n",
       " 'already',\n",
       " 'although',\n",
       " 'america',\n",
       " 'among',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'answers',\n",
       " 'anyone',\n",
       " 'apart',\n",
       " 'appears',\n",
       " 'artist',\n",
       " 'artists',\n",
       " 'aside',\n",
       " 'assured',\n",
       " 'atmospheric',\n",
       " 'beautifully',\n",
       " 'become',\n",
       " 'behind',\n",
       " 'betrayal',\n",
       " 'bizarre',\n",
       " 'black',\n",
       " 'bleak',\n",
       " 'blockbuster',\n",
       " 'blow',\n",
       " 'boasts',\n",
       " 'body',\n",
       " 'boldly',\n",
       " 'brave',\n",
       " 'breaks',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'broken',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'brutal',\n",
       " 'budget',\n",
       " 'cage',\n",
       " 'camera',\n",
       " 'capable',\n",
       " 'captivating',\n",
       " 'captures',\n",
       " 'career',\n",
       " 'carry',\n",
       " 'casts',\n",
       " 'change',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'cheap',\n",
       " 'chemistry',\n",
       " 'children',\n",
       " 'chilling',\n",
       " 'cinematography',\n",
       " 'classic',\n",
       " 'clever',\n",
       " 'clift',\n",
       " 'comedic',\n",
       " 'coming',\n",
       " 'comingofage',\n",
       " 'community',\n",
       " 'compelling',\n",
       " 'contemporary',\n",
       " 'conventional',\n",
       " 'cool',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'crafted',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creates',\n",
       " 'creation',\n",
       " 'crude',\n",
       " 'cry',\n",
       " 'cultural',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'cursing',\n",
       " 'dark',\n",
       " 'david',\n",
       " 'de',\n",
       " 'deal',\n",
       " 'death',\n",
       " 'debut',\n",
       " 'decade',\n",
       " 'deep',\n",
       " 'deeply',\n",
       " 'delight',\n",
       " 'delightful',\n",
       " 'deliver',\n",
       " 'depth',\n",
       " 'deserve',\n",
       " 'deserves',\n",
       " 'designed',\n",
       " 'directors',\n",
       " 'disappointed',\n",
       " 'disney',\n",
       " 'documentary',\n",
       " 'dramatic',\n",
       " 'dramedy',\n",
       " 'due',\n",
       " 'early',\n",
       " 'easily',\n",
       " 'eastwood',\n",
       " 'emotion',\n",
       " 'endearing',\n",
       " 'engrossing',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'essential',\n",
       " 'ever',\n",
       " 'excellent',\n",
       " 'exercise',\n",
       " 'experiences',\n",
       " 'extraordinary',\n",
       " 'extremely',\n",
       " 'eyes',\n",
       " 'fabulous',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'faith',\n",
       " 'fall',\n",
       " 'familiar',\n",
       " 'fan',\n",
       " 'fantastic',\n",
       " 'fascinating',\n",
       " 'fast',\n",
       " 'feet',\n",
       " 'female',\n",
       " 'fiction',\n",
       " 'figures',\n",
       " 'final',\n",
       " 'five',\n",
       " 'focus',\n",
       " 'force',\n",
       " 'forced',\n",
       " 'foreign',\n",
       " 'form',\n",
       " 'formula',\n",
       " 'found',\n",
       " 'four',\n",
       " 'friendship',\n",
       " 'funnier',\n",
       " 'furious',\n",
       " 'future',\n",
       " 'genius',\n",
       " 'getting',\n",
       " 'girl',\n",
       " 'girls',\n",
       " 'giving',\n",
       " 'god',\n",
       " 'gore',\n",
       " 'got',\n",
       " 'gothic',\n",
       " 'grace',\n",
       " 'grim',\n",
       " 'grownups',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'happen',\n",
       " 'harrowing',\n",
       " 'haunting',\n",
       " 'head',\n",
       " 'heartbreaking',\n",
       " 'heartfelt',\n",
       " 'heartwarming',\n",
       " 'hell',\n",
       " 'hilarious',\n",
       " 'hill',\n",
       " 'hit',\n",
       " 'hits',\n",
       " 'hold',\n",
       " 'holiday',\n",
       " 'home',\n",
       " 'honest',\n",
       " 'hope',\n",
       " 'hour',\n",
       " 'human',\n",
       " 'images',\n",
       " 'imaginative',\n",
       " 'imagine',\n",
       " 'impact',\n",
       " 'important',\n",
       " 'impressive',\n",
       " 'includes',\n",
       " 'incredibly',\n",
       " 'indie',\n",
       " 'inspirational',\n",
       " 'inspired',\n",
       " 'inspiring',\n",
       " 'intense',\n",
       " 'intimate',\n",
       " 'intriguing',\n",
       " 'introduction',\n",
       " 'issues',\n",
       " 'ive',\n",
       " 'jackson',\n",
       " 'jane',\n",
       " 'job',\n",
       " 'joy',\n",
       " 'justice',\n",
       " 'keeps',\n",
       " 'kinds',\n",
       " 'known',\n",
       " 'late',\n",
       " 'latest',\n",
       " 'laugh',\n",
       " 'lies',\n",
       " 'likeable',\n",
       " 'limited',\n",
       " 'line',\n",
       " 'live',\n",
       " 'lively',\n",
       " 'lives',\n",
       " 'location',\n",
       " 'lovely',\n",
       " 'low',\n",
       " 'mad',\n",
       " 'magic',\n",
       " 'marriage',\n",
       " 'martin',\n",
       " 'meditation',\n",
       " 'meets',\n",
       " 'members',\n",
       " 'michael',\n",
       " 'mix',\n",
       " 'modern',\n",
       " 'modest',\n",
       " 'moment',\n",
       " 'moore',\n",
       " 'move',\n",
       " 'musical',\n",
       " 'mustsee',\n",
       " 'name',\n",
       " 'nature',\n",
       " 'netflixs',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'nostalgia',\n",
       " 'notes',\n",
       " 'number',\n",
       " 'occasional',\n",
       " 'oddly',\n",
       " 'ones',\n",
       " 'opening',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'overcome',\n",
       " 'packs',\n",
       " 'part',\n",
       " 'parts',\n",
       " 'passion',\n",
       " 'past',\n",
       " 'paul',\n",
       " 'payoff',\n",
       " 'perfect',\n",
       " 'period',\n",
       " 'personal',\n",
       " 'peter',\n",
       " 'physical',\n",
       " 'pieces',\n",
       " 'places',\n",
       " 'playing',\n",
       " 'pleasant',\n",
       " 'pleasure',\n",
       " 'plus',\n",
       " 'poignant',\n",
       " 'politics',\n",
       " 'portrait',\n",
       " 'possibly',\n",
       " 'powerful',\n",
       " 'presents',\n",
       " 'product',\n",
       " 'profoundly',\n",
       " 'project',\n",
       " 'proves',\n",
       " 'provides',\n",
       " 'quality',\n",
       " 'queer',\n",
       " 'quiet',\n",
       " 'quietly',\n",
       " 'range',\n",
       " 'rare',\n",
       " 'reality',\n",
       " 'recent',\n",
       " 'refreshing',\n",
       " 'refreshingly',\n",
       " 'relationships',\n",
       " 'release',\n",
       " 'relevant',\n",
       " 'remarkable',\n",
       " 'reminder',\n",
       " 'respect',\n",
       " 'return',\n",
       " 'rich',\n",
       " 'ride',\n",
       " 'riveting',\n",
       " 'rock',\n",
       " 'role',\n",
       " 'romance',\n",
       " 'romcom',\n",
       " 'room',\n",
       " 'rough',\n",
       " 'run',\n",
       " 'running',\n",
       " 'rural',\n",
       " 'russell',\n",
       " 'satisfying',\n",
       " 'school',\n",
       " 'scifi',\n",
       " 'score',\n",
       " 'season',\n",
       " 'seeing',\n",
       " 'seen',\n",
       " 'sequences',\n",
       " 'seriously',\n",
       " 'serves',\n",
       " 'seth',\n",
       " 'sets',\n",
       " 'setting',\n",
       " 'sex',\n",
       " 'share',\n",
       " 'shot',\n",
       " 'shows',\n",
       " 'side',\n",
       " 'silly',\n",
       " 'simple',\n",
       " 'since',\n",
       " 'skill',\n",
       " 'slick',\n",
       " 'smart',\n",
       " 'smith',\n",
       " 'social',\n",
       " 'society',\n",
       " 'solid',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'sort',\n",
       " 'sound',\n",
       " 'spectacular',\n",
       " 'speed',\n",
       " 'spin',\n",
       " 'sports',\n",
       " 'stand',\n",
       " 'stands',\n",
       " 'starts',\n",
       " 'stop',\n",
       " 'stories',\n",
       " 'striking',\n",
       " 'struggles',\n",
       " 'studio',\n",
       " 'stuff',\n",
       " 'stunning',\n",
       " 'stylish',\n",
       " 'subtle',\n",
       " 'succeeds',\n",
       " 'summer',\n",
       " 'supporting',\n",
       " 'sure',\n",
       " 'surprise',\n",
       " 'surprising',\n",
       " 'survival',\n",
       " 'survive',\n",
       " 'sweet',\n",
       " 'talent',\n",
       " 'team',\n",
       " 'telling',\n",
       " 'tender',\n",
       " 'tense',\n",
       " 'theme',\n",
       " 'thought',\n",
       " 'thoughtful',\n",
       " 'today',\n",
       " 'told',\n",
       " 'top',\n",
       " 'touching',\n",
       " 'tour',\n",
       " 'traditional',\n",
       " 'transgender',\n",
       " 'treat',\n",
       " 'tribute',\n",
       " 'trilogy',\n",
       " 'tropes',\n",
       " 'truly',\n",
       " 'unapologetically',\n",
       " 'understands',\n",
       " 'unexpected',\n",
       " 'unique',\n",
       " 'used',\n",
       " 'uses',\n",
       " 'utterly',\n",
       " 'vibe',\n",
       " 'viewers',\n",
       " 'violent',\n",
       " 'visual',\n",
       " 'visually',\n",
       " 'visuals',\n",
       " 'wanted',\n",
       " 'war',\n",
       " 'warm',\n",
       " 'ways',\n",
       " 'western',\n",
       " 'whose',\n",
       " 'wish',\n",
       " 'within',\n",
       " 'wonderful',\n",
       " 'wonderfully',\n",
       " 'wont',\n",
       " 'worthy',\n",
       " 'writerdirector',\n",
       " 'yarn',\n",
       " 'yes']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only positive words \n",
    "top_fresh_words_exclusive_list = top_fresh_words_exclusive['Occurence good review'].index.tolist()\n",
    "top_fresh_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolutely',\n",
       " 'addition',\n",
       " 'adventure',\n",
       " 'affectionate',\n",
       " 'amazing',\n",
       " 'ambition',\n",
       " 'art',\n",
       " 'artist',\n",
       " 'arts',\n",
       " 'atmosphere',\n",
       " 'attractive',\n",
       " 'awards',\n",
       " 'balance',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'bond',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'captivating',\n",
       " 'captures',\n",
       " 'celebration',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'christmas',\n",
       " 'classic',\n",
       " 'clever',\n",
       " 'committed',\n",
       " 'consistently',\n",
       " 'contemporary',\n",
       " 'conventional',\n",
       " 'convincingly',\n",
       " 'creates',\n",
       " 'creating',\n",
       " 'crowdpleaser',\n",
       " 'cult',\n",
       " 'decade',\n",
       " 'decades',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'deeply',\n",
       " 'definitely',\n",
       " 'delightful',\n",
       " 'delightfully',\n",
       " 'depth',\n",
       " 'deserves',\n",
       " 'design',\n",
       " 'details',\n",
       " 'different',\n",
       " 'diverse',\n",
       " 'dramatic',\n",
       " 'early',\n",
       " 'elegant',\n",
       " 'emotionally',\n",
       " 'engaging',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'equal',\n",
       " 'especially',\n",
       " 'exploration',\n",
       " 'extraordinary',\n",
       " 'extremely',\n",
       " 'familiar',\n",
       " 'famous',\n",
       " 'fan',\n",
       " 'fantastic',\n",
       " 'fantasy',\n",
       " 'fascinating',\n",
       " 'felt',\n",
       " 'filled',\n",
       " 'finest',\n",
       " 'frank',\n",
       " 'fresh',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'gags',\n",
       " 'gorgeous',\n",
       " 'grand',\n",
       " 'happy',\n",
       " 'heart',\n",
       " 'hilarious',\n",
       " 'honest',\n",
       " 'hope',\n",
       " 'huge',\n",
       " 'impact',\n",
       " 'insightful',\n",
       " 'inspiring',\n",
       " 'intelligent',\n",
       " 'intense',\n",
       " 'intrigue',\n",
       " 'joy',\n",
       " 'laugh',\n",
       " 'loved',\n",
       " 'mature',\n",
       " 'mind',\n",
       " 'mystery',\n",
       " 'nostalgia',\n",
       " 'novel',\n",
       " 'opening',\n",
       " 'passion',\n",
       " 'perfect',\n",
       " 'performers',\n",
       " 'personal',\n",
       " 'pleasure',\n",
       " 'poignant',\n",
       " 'power',\n",
       " 'powerful',\n",
       " 'precisely',\n",
       " 'profound',\n",
       " 'project',\n",
       " 'proves',\n",
       " 'provide',\n",
       " 'provocative',\n",
       " 'psychological',\n",
       " 'quality',\n",
       " 'remarkable',\n",
       " 'reveals',\n",
       " 'rich',\n",
       " 'riveting',\n",
       " 'satisfying',\n",
       " 'sharp',\n",
       " 'simple',\n",
       " 'smart',\n",
       " 'smile',\n",
       " 'stunning',\n",
       " 'succeeds',\n",
       " 'supernatural',\n",
       " 'surprise',\n",
       " 'surprises',\n",
       " 'surprising',\n",
       " 'surprisingly',\n",
       " 'sweet',\n",
       " 'talents',\n",
       " 'thoughtful',\n",
       " 'thrills',\n",
       " 'touch',\n",
       " 'touching',\n",
       " 'tragedy',\n",
       " 'tragic',\n",
       " 'tribute',\n",
       " 'unique',\n",
       " 'universal',\n",
       " 'warm',\n",
       " 'watchable',\n",
       " 'welcome',\n",
       " 'wit',\n",
       " 'witty',\n",
       " 'wonderful',\n",
       " 'worthwhile',\n",
       " 'worthy']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_fresh_words_exclusive = ['absolutely',\n",
    " 'addition',\n",
    " 'adventure',\n",
    " 'affectionate',\n",
    " 'amazing',\n",
    " 'ambition',\n",
    " 'art',\n",
    " 'artist',\n",
    " 'arts',\n",
    " 'atmosphere',\n",
    " 'attractive',\n",
    " 'awards',\n",
    " 'balance',\n",
    " 'beautiful',\n",
    " 'beautifully',\n",
    " 'beauty',\n",
    " 'bond',\n",
    " 'bright',\n",
    " 'brilliant',\n",
    " 'captivating',\n",
    " 'captures',\n",
    " 'celebration',\n",
    " 'charm',\n",
    " 'charming',\n",
    " 'christmas',\n",
    " 'classic',\n",
    " 'clever',\n",
    " 'committed',\n",
    " 'consistently',\n",
    " 'contemporary',\n",
    " 'conventional',\n",
    " 'convincingly',\n",
    " 'creates',\n",
    " 'creating',\n",
    " 'crowdpleaser',\n",
    " 'cult',\n",
    " 'decade',\n",
    " 'decades',\n",
    " 'deep',\n",
    " 'deeper',\n",
    " 'deeply',\n",
    " 'definitely',\n",
    " 'delightful',\n",
    " 'delightfully',\n",
    " 'depth',\n",
    " 'deserves',\n",
    " 'design',\n",
    " 'details',\n",
    " 'different',\n",
    " 'diverse',\n",
    " 'dramatic',\n",
    " 'early',\n",
    " 'elegant',\n",
    " 'emotionally',\n",
    " 'engaging',\n",
    " 'enjoyable',\n",
    " 'enjoyed',\n",
    " 'equal',\n",
    " 'especially',\n",
    " 'exploration',\n",
    " 'extraordinary',\n",
    " 'extremely',\n",
    " 'familiar',\n",
    " 'famous',\n",
    " 'fan',\n",
    " 'fantastic',\n",
    " 'fantasy',\n",
    " 'fascinating',\n",
    " 'felt',\n",
    " 'filled',\n",
    " 'finest',\n",
    " 'frank',\n",
    " 'fresh',\n",
    " 'friends',\n",
    " 'friendship',\n",
    " 'gags',\n",
    " 'gorgeous',\n",
    " 'grand',\n",
    " 'happy',\n",
    " 'heart',\n",
    " 'hilarious',\n",
    " 'honest',\n",
    " 'hope',\n",
    " 'huge',\n",
    " 'impact',\n",
    " 'insightful',\n",
    " 'inspiring',\n",
    " 'intelligent',\n",
    " 'intense',\n",
    " 'intrigue',\n",
    " 'joy',\n",
    " 'laugh',\n",
    " 'loved',\n",
    " 'mature',\n",
    " 'mind',\n",
    " 'mystery',\n",
    " 'nostalgia',\n",
    " 'novel',\n",
    " 'opening',\n",
    " 'passion',\n",
    " 'perfect',\n",
    " 'performers',\n",
    " 'personal',\n",
    " 'pleasure',\n",
    " 'poignant',\n",
    " 'power',\n",
    " 'powerful',\n",
    " 'precisely',\n",
    " 'profound',\n",
    " 'project',\n",
    " 'proves',\n",
    " 'provide',\n",
    " 'provocative',\n",
    " 'psychological',\n",
    " 'quality',\n",
    " 'remarkable',\n",
    " 'reveals',\n",
    " 'rich',\n",
    " 'riveting',\n",
    " 'satisfying',\n",
    " 'sharp',\n",
    " 'simple',\n",
    " 'smart',\n",
    " 'smile',\n",
    " 'stunning',\n",
    " 'succeeds',\n",
    " 'supernatural',\n",
    " 'surprise',\n",
    " 'surprises',\n",
    " 'surprising',\n",
    " 'surprisingly',\n",
    " 'sweet',\n",
    " 'talents',\n",
    " 'thoughtful',\n",
    " 'thrills',\n",
    " 'touch',\n",
    " 'touching',\n",
    " 'tragedy',\n",
    " 'tragic',\n",
    " 'tribute',\n",
    " 'unique',\n",
    " 'universal',\n",
    " 'warm',\n",
    " 'watchable',\n",
    " 'welcome',\n",
    " 'wit',\n",
    " 'witty',\n",
    " 'wonderful',\n",
    " 'worthwhile',\n",
    " 'worthy']\n",
    "\n",
    "top_fresh_words_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['achieve',\n",
       " 'air',\n",
       " 'appealing',\n",
       " 'attempt',\n",
       " 'barely',\n",
       " 'battle',\n",
       " 'bland',\n",
       " 'bloody',\n",
       " 'built',\n",
       " 'bythenumbers',\n",
       " 'call',\n",
       " 'cannot',\n",
       " 'care',\n",
       " 'case',\n",
       " 'central',\n",
       " 'chance',\n",
       " 'clichés',\n",
       " 'complex',\n",
       " 'complicated',\n",
       " 'concept',\n",
       " 'concerned',\n",
       " 'conflict',\n",
       " 'core',\n",
       " 'couldnt',\n",
       " 'dance',\n",
       " 'danger',\n",
       " 'derivative',\n",
       " 'difficult',\n",
       " 'disappointing',\n",
       " 'disappointment',\n",
       " 'disturbing',\n",
       " 'dull',\n",
       " 'effects',\n",
       " 'efforts',\n",
       " 'else',\n",
       " 'empathy',\n",
       " 'entirely',\n",
       " 'epic',\n",
       " 'eventually',\n",
       " 'except',\n",
       " 'excessive',\n",
       " 'execution',\n",
       " 'expectations',\n",
       " 'failure',\n",
       " 'felt',\n",
       " 'fight',\n",
       " 'filled',\n",
       " 'filmmaker',\n",
       " 'finally',\n",
       " 'finish',\n",
       " 'flat',\n",
       " 'follow',\n",
       " 'front',\n",
       " 'fury',\n",
       " 'gags',\n",
       " 'game',\n",
       " 'generic',\n",
       " 'genuine',\n",
       " 'genuinely',\n",
       " 'grave',\n",
       " 'happens',\n",
       " 'heavy',\n",
       " 'hot',\n",
       " 'identity',\n",
       " 'imagination',\n",
       " 'impossible',\n",
       " 'intentions',\n",
       " 'involved',\n",
       " 'justify',\n",
       " 'knows',\n",
       " 'lacks',\n",
       " 'largely',\n",
       " 'lazy',\n",
       " 'leached',\n",
       " 'loses',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'meant',\n",
       " 'melodrama',\n",
       " 'mess',\n",
       " 'message',\n",
       " 'messy',\n",
       " 'moon',\n",
       " 'mystery',\n",
       " 'needed',\n",
       " 'neither',\n",
       " 'none',\n",
       " 'pacing',\n",
       " 'pain',\n",
       " 'parents',\n",
       " 'perhaps',\n",
       " 'poor',\n",
       " 'predecessor',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'promise',\n",
       " 'pull',\n",
       " 'quickly',\n",
       " 'rarely',\n",
       " 'reason',\n",
       " 'reasonably',\n",
       " 'red',\n",
       " 'remains',\n",
       " 'remotely',\n",
       " 'ridiculous',\n",
       " 'rote',\n",
       " 'sadly',\n",
       " 'satire',\n",
       " 'save',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'screenplay',\n",
       " 'serve',\n",
       " 'several',\n",
       " 'shouldnt',\n",
       " 'space',\n",
       " 'spirit',\n",
       " 'stepping',\n",
       " 'stick',\n",
       " 'success',\n",
       " 'suffers',\n",
       " 'surface',\n",
       " 'taken',\n",
       " 'talk',\n",
       " 'taste',\n",
       " 'terrible',\n",
       " 'themes',\n",
       " 'third',\n",
       " 'throughout',\n",
       " 'title',\n",
       " 'tough',\n",
       " 'towards',\n",
       " 'understand',\n",
       " 'unfortunately',\n",
       " 'unfunny',\n",
       " 'uninspired',\n",
       " 'vapid',\n",
       " 'video',\n",
       " 'viewing',\n",
       " 'vision',\n",
       " 'weight',\n",
       " 'word',\n",
       " 'worst',\n",
       " 'written',\n",
       " 'zero']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only negative words \n",
    "top_rotten_words_exclusive_list = top_rotten_words_exclusive['Occurence bad review'].index.tolist()\n",
    "top_rotten_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attempt',\n",
       " 'awkward',\n",
       " 'barely',\n",
       " 'basically',\n",
       " 'bizarre',\n",
       " 'bland',\n",
       " 'boring',\n",
       " 'clumsy',\n",
       " 'comedic',\n",
       " 'disappointing',\n",
       " 'disappointingly',\n",
       " 'disappointment',\n",
       " 'disaster',\n",
       " 'dull',\n",
       " 'effort',\n",
       " 'failed',\n",
       " 'fails',\n",
       " 'generic',\n",
       " 'irritating',\n",
       " 'lacking',\n",
       " 'manic',\n",
       " 'missing',\n",
       " 'nobody',\n",
       " 'noir',\n",
       " 'none',\n",
       " 'painfully',\n",
       " 'pointless',\n",
       " 'poorly',\n",
       " 'problem',\n",
       " 'shallow',\n",
       " 'shame',\n",
       " 'sloppy',\n",
       " 'slow',\n",
       " 'suffers',\n",
       " 'superficial',\n",
       " 'try',\n",
       " 'unfortunately',\n",
       " 'unfunny',\n",
       " 'worst']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_rotten_words_exclusive = [\n",
    " 'attempt',\n",
    " 'awkward',\n",
    " 'barely',\n",
    " 'basically',\n",
    " 'bizarre',\n",
    " 'bland',\n",
    " 'boring',\n",
    " 'clumsy',\n",
    " 'comedic',\n",
    " 'disappointing',\n",
    " 'disappointingly',\n",
    " 'disappointment',\n",
    " 'disaster',\n",
    " 'dull',\n",
    " 'effort',\n",
    " 'failed',\n",
    " 'fails',\n",
    " 'generic',\n",
    " 'irritating',\n",
    " 'lacking',\n",
    " 'manic',\n",
    " 'missing',\n",
    " 'nobody',\n",
    " 'noir',\n",
    " 'none',\n",
    " 'painfully',\n",
    " 'pointless',\n",
    " 'poorly',\n",
    " 'problem',\n",
    " 'shallow',\n",
    " 'shame',\n",
    " 'sloppy',\n",
    " 'slow',\n",
    " 'suffers',\n",
    " 'superficial',\n",
    " 'try',\n",
    " 'unfortunately',\n",
    " 'unfunny',\n",
    " 'worst']\n",
    "top_rotten_words_exclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Word Occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A. Good / bad exclusive words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.apply.spark import SparkLFApplier\n",
    "\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SQLContext \n",
    "import pandas as pd \n",
    "sqlc=SQLContext(sc) \n",
    "df=pd.read_csv('/project/development_split.csv',index_col = 'Unnamed: 0')\n",
    "df_with_punctuation = df.copy()\n",
    "df['Review'] = remove_punctuation(df)\n",
    "development_split=sqlc.createDataFrame(df)\n",
    "development_split_with_punctuation=sqlc.createDataFrame(df_with_punctuation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|              Review|Freshness|\n",
      "+--------------------+---------+\n",
      "|it wont have much...|        1|\n",
      "|serenity is a fil...|        1|\n",
      "| the rare kind of...|        1|\n",
      "| john fords most ...|        0|\n",
      "|lampoons ethnocen...|        1|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "development_split.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# development_split = pd.read_csv('/project/development_split.csv')\n",
    "ABSTAIN = -1\n",
    "NOTFRESH = 0\n",
    "FRESH = 1\n",
    "\n",
    "@labeling_function()\n",
    "def fresh(x):\n",
    "    for word in top_fresh_words_exclusive:\n",
    "        word = \" \" +word+\" \"\n",
    "        if word in str(x).lower():\n",
    "            return FRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def rotten(x):\n",
    "    for word in top_rotten_words_exclusive:\n",
    "        word = \" \" +word+\" \"\n",
    "        if word in str(x).lower():\n",
    "            return NOTFRESH\n",
    "    return ABSTAIN\n",
    "#return NOTFRESH if \"best\" in x.str.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [fresh]\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       ...,\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresh coverage:35.1%\n"
     ]
    }
   ],
   "source": [
    "coverage_fresh = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"fresh coverage:{:.1%}\".format(coverage_fresh[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [rotten]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten coverage:8.0%\n"
     ]
    }
   ],
   "source": [
    "coverage_rotten = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"rotten coverage:{:.1%}\".format(coverage_rotten[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Word 'too' occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "too                     30"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "too                    54"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def keyword_too(x):\n",
    "    return NOTFRESH if 'too' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [keyword_too]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword too coverage:4.5%\n"
     ]
    }
   ],
   "source": [
    "coverage_keyword_too = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword too coverage:{:.1%}\".format(coverage_keyword_too[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Word 'far' occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "far                     13"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "far                    13"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def keyword_far(x):\n",
    "    return FRESH if 'far' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [keyword_far]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword far coverage:2.6%\n"
     ]
    }
   ],
   "source": [
    "coverage_keyword_far = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword far coverage:{:.1%}\".format(coverage_keyword_far[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. \"n't\" words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration on the n't\n",
    "# Word occurancy that with punctuation with it\n",
    "\n",
    "# Word occurrences dataframe for fresh reviews\n",
    "development_split_fresh_1 = split_fresh.str.split(expand=True).stack().value_counts()\n",
    "development_split_fresh_df = pd.DataFrame(development_split_fresh_1).reset_index()\n",
    "\n",
    "# Words occurrences dataframe for rotten reviews\n",
    "development_split_rotten_1 = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "development_split_rotten_df = pd.DataFrame(development_split_rotten_1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "\n",
    "def t(x):\n",
    "    if re.search(\"'t\",str(x).lower()):\n",
    "        return NOTFRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [t]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword far coverage:14.7%\n"
     ]
    }
   ],
   "source": [
    "coverage_t = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword far coverage:{:.1%}\".format(coverage_t[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Occurenes of good & bad words from external list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "We also want to look at an imported list of postive and negative words and see whether we can base the labelling functions on them.\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing good and bad words & preparing for labelling function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POSITIVE WORDS \n",
    "#positive words from --> DON't DELETE! NEED TO CITE PROPERLY http://ptrckprry.com/course/ssd/data/positive-words.txt\n",
    "positive_word = pd.read_csv('/project/positive_words.csv')\n",
    "\n",
    "#sample 500 words \n",
    "positive_word = positive_word.sample(500)\n",
    "\n",
    "#convert it into a list \n",
    "positive_word= positive_word['a+'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "#NEGATIVE WORDS \n",
    "#negative words from --> HONG?? \n",
    "negative_word = pd.read_csv('/project/negative_words.csv')\n",
    "\n",
    "#sample 500 words \n",
    "negative_word = negative_word.sample(500)\n",
    "\n",
    "#convert it into a list \n",
    "negative_word= negative_word['2-faces'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def negative(x): \n",
    "    for word in negative_word:\n",
    "        word = \" \" + word + \" \"\n",
    "        if word in str(x).lower():\n",
    "            return NOTFRESH \n",
    "    return ABSTAIN \n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def positive(x):\n",
    "    for word in positive_word:\n",
    "        word = \" \" + word + \" \"\n",
    "        if word in str(x).lower():\n",
    "            return FRESH \n",
    "    return ABSTAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [negative]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative words coverage:6.9%\n"
     ]
    }
   ],
   "source": [
    "coverage_negative = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"negative words coverage:{:.1%}\".format(coverage_negative[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [positive]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive words coverage:28.1%\n"
     ]
    }
   ],
   "source": [
    "coverage_positive = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"positive words coverage:{:.1%}\".format(coverage_positive[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Punctuation occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn review column into Series\n",
    "development_split_fresh_series = pd.Series(development_split_fresh.Review)\n",
    "development_split_rotten_series = pd.Series(development_split_rotten.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive reviews\n",
    "# Split reviews into word\n",
    "fresh_split = pd.Series(development_split_fresh_series.str.split(expand=True).stack())\n",
    "fresh_words = [i for i in fresh_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in fresh_words]\n",
    "fresh_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative reviews\n",
    "# Split reviews into word\n",
    "rotten_split = pd.Series(development_split_rotten_series.str.split(expand=True).stack())\n",
    "rotten_words = [i for i in rotten_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in rotten_words]\n",
    "rotten_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into a flattened list\n",
    "fresh_flattened_list = [y for x in fresh_split_words for y in x]\n",
    "rotten_flattened_list = [y for x in rotten_split_words for y in x]\n",
    "\n",
    "# Count the occurancy of each character\n",
    "# Positive reviews\n",
    "fresh_split_characters = pd.Series(fresh_flattened_list).value_counts()\n",
    "fresh_split_characters = pd.DataFrame(fresh_split_characters).reset_index()\n",
    "\n",
    "# Negative reviews\n",
    "rotten_split_characters = pd.Series(rotten_flattened_list).value_counts()\n",
    "rotten_split_characters = pd.DataFrame(rotten_split_characters).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Question mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>?</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "60     ?  17"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>?</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "52     ?  32"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Are you looking for a hilariously erotic thriller comedy? Sit down and let the weirdness of Blood Paradise wash over you.', ' I Spit on Your Grave improves on Meir Zarchi?s 1978 original, but that?s not saying much.', \" The movie's main purpose seems to be to make audiences squirm uncomfortably. Yelp and shriek in armchair-clawing glee? Not likely.\"]\n"
     ]
    }
   ],
   "source": [
    "list_with_question_mark = []\n",
    "for review in development_split_rotten.Review:\n",
    "    if '?' in review:\n",
    "        list_with_question_mark.append(review)\n",
    "        \n",
    "print (list_with_question_mark[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def question_mark(x):\n",
    "    return NOTFRESH if '?' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lfs = [question_mark]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split_with_punctuation.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question mark coverage:2.1%\n"
     ]
    }
   ],
   "source": [
    "coverage_question_mark = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"question mark coverage:{:.1%}\".format(coverage_question_mark[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Exclamation mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  0\n",
       "74     !  5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  0\n",
       "74     !  3"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def exclamation_mark(x):\n",
    "    return FRESH if '!' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lfs = [exclamation_mark]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split_with_punctuation.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclamation mark coverage:0.4%\n"
     ]
    }
   ],
   "source": [
    "coverage_exclamation_mark = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"exclamation mark coverage:{:.1%}\".format(coverage_exclamation_mark[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Combining labelling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Next, we want to combine all the labelling functions into one and apply them to the training set. However, as the labelling functions around the punctuation have very low coverages, we decided not to include these.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [fresh,\n",
    "       rotten,\n",
    "       keyword_too,\n",
    "       keyword_far,\n",
    "       t,\n",
    "       negative,\n",
    "       positive]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446760</th>\n",
       "      <td>An excessively convoluted rehash of its prede...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44418</th>\n",
       "      <td>Osment's the weak link in the movie and becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27216</th>\n",
       "      <td>If you want to see some spectacularly adorable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24133</th>\n",
       "      <td>Not only do we rarely get to participate in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19332</th>\n",
       "      <td>You never know what to expect from Martin McDo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>There are genuinely imaginative special effect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435470</th>\n",
       "      <td>...dissects contemporary adolescence with a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>It's convivial, imaginative, and always cinema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>\"Ma\" is poorly written, but Spencer lifts it u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150646</th>\n",
       "      <td>Balance out the few highs and many, scatologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>Shin infuses an intoxicating blend of grime, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9267</th>\n",
       "      <td>An unappealing comedy with a derisive and dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>It feels like the ideal fit for Netflix and as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168258</th>\n",
       "      <td>The Mummy is the perfect movie if you love mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53446</th>\n",
       "      <td>Sporadically tests one's sugar endurance, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>Sure, Tracy Oliver's screenplay is simplistic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48909</th>\n",
       "      <td>James Marsh's Project Nim ruminates on ideas o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14912</th>\n",
       "      <td>It speaks to its entire audience, without ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>The Wedding Guest has all the right pieces the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26862</th>\n",
       "      <td>A beast of a movie is gifted a superfluous-but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105143</th>\n",
       "      <td>Like a fun house mirror, Burger's story is ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451206</th>\n",
       "      <td>There are moments of mad genius here, and a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>It's frantic stuff, slight and cheesy but ende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>A featherweight film with a lot of heart but n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12420</th>\n",
       "      <td>Darker than expected but with a good theme: mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13927</th>\n",
       "      <td>An answered prayer for those who believe that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33756</th>\n",
       "      <td>Whatever failings the film may have, none can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>The movie is sometimes charged with real tensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39069</th>\n",
       "      <td>If you want a turn-on, turn-off Caligula. Stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>Conspicuous assets are the striking color phot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>Room for Rent is an enthralling psychological ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>The Sound of My Voice is entirely satisfying a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032</th>\n",
       "      <td>As a partner piece to Hamlet, it's an interest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23833</th>\n",
       "      <td>David O. Russell continues to prove just how w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>Acceptably uneven.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22297</th>\n",
       "      <td>Being a baseball fan involves repeatedly exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40606</th>\n",
       "      <td>I wish that director/co-writer Todd Phillips....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43127</th>\n",
       "      <td>Another stunning martial arts masterpiece from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31647</th>\n",
       "      <td>The kind of boot-strap-pulling, tear-duct-tick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381264</th>\n",
       "      <td>Vanessa Hudgens and Alyson Michalka played mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>Directed by Jeremy Sims, Wayne is snapshot of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243035</th>\n",
       "      <td>Trite and boring portrait of rich and self-ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71237</th>\n",
       "      <td>There's a fascinating and terrifying story to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>An action movie without suspense, a message wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>On paper, Don't Let Go's premise - a supernatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252</th>\n",
       "      <td>There are some clever touches in the script, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Military idolatry and craven female objectific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>So-so sequel is full of blood but not much cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20902</th>\n",
       "      <td>Be prepared for long intervals of holding your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10748</th>\n",
       "      <td>When you wrap a movie around a gimmick, the wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20556</th>\n",
       "      <td>It's tense, compelling and steeped in an urban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25608</th>\n",
       "      <td>Burns' latest demonstrates the workmanlike ski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20793</th>\n",
       "      <td>One of the toughest movies ever made, an uncom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39327</th>\n",
       "      <td>Making the transition from long-arc TV series...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314508</th>\n",
       "      <td>The whole thing leaves you with an appalling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363750</th>\n",
       "      <td>Vampire movies were always cool, but it took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367127</th>\n",
       "      <td>Very much a child of today's Hollywood, it's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144060</th>\n",
       "      <td>Above all, Iñárritu's \"Birdman\" is a celebrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21108</th>\n",
       "      <td>Your reaction to the whole thing probably depe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122956</th>\n",
       "      <td>Paul Thomas Anderson is here to honor everyth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review\n",
       "446760   An excessively convoluted rehash of its prede...\n",
       "44418   Osment's the weak link in the movie and becaus...\n",
       "27216   If you want to see some spectacularly adorable...\n",
       "24133   Not only do we rarely get to participate in th...\n",
       "19332   You never know what to expect from Martin McDo...\n",
       "3438    There are genuinely imaginative special effect...\n",
       "435470   ...dissects contemporary adolescence with a w...\n",
       "2880    It's convivial, imaginative, and always cinema...\n",
       "3264    \"Ma\" is poorly written, but Spencer lifts it u...\n",
       "150646   Balance out the few highs and many, scatologi...\n",
       "5795    Shin infuses an intoxicating blend of grime, c...\n",
       "9267     An unappealing comedy with a derisive and dis...\n",
       "1699    It feels like the ideal fit for Netflix and as...\n",
       "168258   The Mummy is the perfect movie if you love mi...\n",
       "53446   Sporadically tests one's sugar endurance, but ...\n",
       "3439    Sure, Tracy Oliver's screenplay is simplistic ...\n",
       "48909   James Marsh's Project Nim ruminates on ideas o...\n",
       "14912   It speaks to its entire audience, without ever...\n",
       "3779    The Wedding Guest has all the right pieces the...\n",
       "26862   A beast of a movie is gifted a superfluous-but...\n",
       "105143   Like a fun house mirror, Burger's story is ne...\n",
       "451206   There are moments of mad genius here, and a w...\n",
       "34      It's frantic stuff, slight and cheesy but ende...\n",
       "1265    A featherweight film with a lot of heart but n...\n",
       "12420   Darker than expected but with a good theme: mo...\n",
       "13927    An answered prayer for those who believe that...\n",
       "33756   Whatever failings the film may have, none can ...\n",
       "24983   The movie is sometimes charged with real tensi...\n",
       "39069   If you want a turn-on, turn-off Caligula. Stay...\n",
       "5915    Conspicuous assets are the striking color phot...\n",
       "...                                                   ...\n",
       "5529    Room for Rent is an enthralling psychological ...\n",
       "1023    The Sound of My Voice is entirely satisfying a...\n",
       "4032    As a partner piece to Hamlet, it's an interest...\n",
       "23833   David O. Russell continues to prove just how w...\n",
       "19973                                  Acceptably uneven.\n",
       "22297   Being a baseball fan involves repeatedly exper...\n",
       "40606    I wish that director/co-writer Todd Phillips....\n",
       "43127   Another stunning martial arts masterpiece from...\n",
       "31647   The kind of boot-strap-pulling, tear-duct-tick...\n",
       "381264   Vanessa Hudgens and Alyson Michalka played mo...\n",
       "2796    Directed by Jeremy Sims, Wayne is snapshot of ...\n",
       "243035   Trite and boring portrait of rich and self-ab...\n",
       "71237    There's a fascinating and terrifying story to...\n",
       "5334    An action movie without suspense, a message wi...\n",
       "962     On paper, Don't Let Go's premise - a supernatu...\n",
       "4252    There are some clever touches in the script, f...\n",
       "588     Military idolatry and craven female objectific...\n",
       "371     So-so sequel is full of blood but not much cha...\n",
       "20902   Be prepared for long intervals of holding your...\n",
       "10748   When you wrap a movie around a gimmick, the wr...\n",
       "20556   It's tense, compelling and steeped in an urban...\n",
       "25608   Burns' latest demonstrates the workmanlike ski...\n",
       "20793   One of the toughest movies ever made, an uncom...\n",
       "39327    Making the transition from long-arc TV series...\n",
       "314508   The whole thing leaves you with an appalling ...\n",
       "363750   Vampire movies were always cool, but it took ...\n",
       "367127   Very much a child of today's Hollywood, it's ...\n",
       "144060   Above all, Iñárritu's \"Birdman\" is a celebrat...\n",
       "21108   Your reaction to the whole thing probably depe...\n",
       "122956   Paul Thomas Anderson is here to honor everyth...\n",
       "\n",
       "[12000 rows x 1 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prepared = train.copy()\n",
    "\n",
    "train_prepared\n",
    "train_prepared['Review'] = remove_punctuation(train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotten</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_too</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_far</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.0760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.0325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.2810</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>0.0755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             j Polarity  Coverage  Overlaps  Conflicts\n",
       "fresh        0      [1]    0.3515    0.1925     0.0990\n",
       "rotten       1      [0]    0.0800    0.0525     0.0380\n",
       "keyword_too  2      [0]    0.0450    0.0285     0.0215\n",
       "keyword_far  3      [1]    0.0260    0.0200     0.0100\n",
       "t            4      [0]    0.1470    0.0890     0.0760\n",
       "negative     5      [0]    0.0690    0.0430     0.0325\n",
       "positive     6      [1]    0.2810    0.1685     0.0755"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "LFAnalysis(L=sample_L, lfs = lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [fresh,\n",
    "       rotten,\n",
    "       keyword_too,\n",
    "       keyword_far,\n",
    "       t,\n",
    "       negative,\n",
    "       positive]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "\n",
    "L_train=sqlc.createDataFrame(train_prepared)\n",
    "\n",
    "#is this next line correct?\n",
    "L_test = sqlc.createDataFrame(test)\n",
    "\n",
    "# type(L_train)\n",
    "L_train = applier.apply(L_train.rdd)\n",
    "\n",
    "#is this next line correct?\n",
    "L_test = applier.apply(L_test.rdd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [ 1, -1, -1, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [ 1, -1, -1, ..., -1, -1, -1],\n",
       "       [ 1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.copy()\n",
    "train2['predicted_train'] = preds_train\n",
    "train2.to_csv('12000_predicted_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#needs to show version 2.3\n",
    "import networkx as nx\n",
    "nx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelling according to weights \n",
    "from snorkel.labeling import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to be checked \n",
    "L_test = L_test\n",
    "Y_test = test['Freshness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   59.8%\n",
      "Label Model Accuracy:     59.8%\n"
     ]
    }
   ],
   "source": [
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "\n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install py4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 2.4.5\n",
      "Python version: 3.6.10 |Anaconda, Inc.| (default, Jan  7 2020, 21:14:29) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark import SQLContext, SparkConf\n",
    "\n",
    "print('Spark version:', sc.version)\n",
    "\n",
    "print('Python version:', sys.version)\n",
    "\n",
    "#Apparently PySpark does not work with Python 3.6.10\n",
    "#This is why we get the Java4 Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "\n",
    "# @preprocessor(memoize=True)\n",
    "# def textblob_sentiment(x):\n",
    "#     scores = TextBlob(x.text)\n",
    "#     x.polarity = scores.sentiment.polarity\n",
    "#     x.subjectivity = scores.sentiment.subjectivity\n",
    "#     return x\n",
    "\n",
    "# #pick a reasonable threshold \n",
    "# #Using a lower threshold than other examples as this could be a good indicator for determining official sources vs general negative sentiment\n",
    "# @labeling_function()\n",
    "# def textblob_polarity(x):\n",
    "#     return NOTFRESH if x.polarity > 0.8 else ABSTAIN\n",
    "\n",
    "# #do the same for the subjectivity scores. \n",
    "# #Using a higher threshold than other examples as this could be a good indicator for determining official sources\n",
    "# #This will run faster than the last cell, since we memoized the Preprocessor outputs.\n",
    "# @labeling_function()\n",
    "# def textblob_subjectivity(x):\n",
    "#     return FRESH if x.subjectivity >= 0.6 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(text):\n",
    "    x = {}\n",
    "    x[\"polarity\"] = TextBlob(text).sentiment.polarity\n",
    "    x[\"subjectivity\"] = TextBlob(text).sentiment.subjectivity\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @labeling_function(pre=[textblob_sentiment])\n",
    "# def textblob_polarity(x):\n",
    "#     x = getSentiment(x.text)\n",
    "#     return FRESH if x.polarity > 0.8 else ABSTAIN\n",
    "\n",
    "# @labeling_function(pre=[textblob_sentiment])\n",
    "# def textblob_subjectivity(x):\n",
    "#     x = getSentiment(x.text)\n",
    "#     return FRESH if x.subjectivity >= 0.5 else ABSTAIN\n",
    "\n",
    "\n",
    "\n",
    "#pick a reasonable threshold \n",
    "#Using a lower threshold than other examples as this could be a good indicator for determining official sources vs general negative sentiment\n",
    "#@labeling_function(pre=[textblob_sentiment])\n",
    "@labeling_function()\n",
    "def textblob_polarity(x):\n",
    "    x = getSentiment(x.Review)\n",
    "    return FRESH if x[\"polarity\"] > 0.8 else ABSTAIN\n",
    "\n",
    "#do the same for the subjectivity scores. \n",
    "#Using a higher threshold than other examples as this could be a good indicator for determining official sources\n",
    "#This will run faster than the last cell, since we memoized the Preprocessor outputs.\n",
    "#@labeling_function(pre=[textblob_sentiment])\n",
    "@labeling_function()\n",
    "def textblob_subjectivity(x):\n",
    "    x = getSentiment(x.Review)\n",
    "    return FRESH if x[\"subjectivity\"] >= 0.5 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|              Review|Freshness|\n",
      "+--------------------+---------+\n",
      "|it wont have much...|        1|\n",
      "|serenity is a fil...|        1|\n",
      "| the rare kind of...|        1|\n",
      "| john fords most ...|        0|\n",
      "|lampoons ethnocen...|        1|\n",
      "|everything about ...|        0|\n",
      "|the talented cast...|        0|\n",
      "|the film dares it...|        1|\n",
      "|while all the bri...|        0|\n",
      "|great fights you ...|        1|\n",
      "|supremacy is bris...|        1|\n",
      "| in these linked ...|        1|\n",
      "| ultimately shopg...|        0|\n",
      "|at its core harpo...|        1|\n",
      "|a cloned human is...|        1|\n",
      "|hitchcock once fa...|        0|\n",
      "|killerman is the ...|        0|\n",
      "| arguably one of ...|        1|\n",
      "|the breezy manner...|        1|\n",
      "| very nearly as i...|        1|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "development_split.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split[development_split.Review == \"\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Freshness|\n",
      "+---------+\n",
      "|0        |\n",
      "|1        |\n",
      "+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.select('Freshness').distinct().show(truncate=False)\n",
    "\n",
    "development_split[development_split.Freshness == None].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [\n",
    "       textblob_polarity,\n",
    "       textblob_subjectivity\n",
    "      ]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "\n",
    "sample_L = applier.apply(development_split.rdd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>textblob_polarity</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       j Polarity  Coverage  Overlaps  Conflicts\n",
       "textblob_polarity      0      [1]     0.009    0.0055        0.0\n",
       "textblob_subjectivity  1      [1]     0.567    0.0055        0.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(sample_L, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n",
      "<pyspark.sql.session.SparkSession object at 0x7f0dd9209d30>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "# Spark Environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import pyspark\n",
    "\n",
    "number_cores = 4\n",
    "memory_gb = 16\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "print(sc)\n",
    "\n",
    "# get the context\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "print(spark) \n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/faculty/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/faculty/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/faculty/.cache/pip/wheels/b4/77/b4/b38806c8087e0860cfeabab1f96b60c48346d8db59a9254787/langid-1.1.6-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from langid) (1.18.1)\n",
      "Installing collected packages: langid\n",
      "Successfully installed langid-1.1.6\n"
     ]
    }
   ],
   "source": [
    "# Download files\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "!pip install langid\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import preproc as pp\n",
    "\n",
    "# Register all the functions in Preproc with Spark Context\n",
    "check_lang_udf = udf(pp.check_lang, StringType())\n",
    "remove_stops_udf = udf(pp.remove_stops, StringType())\n",
    "remove_features_udf = udf(pp.remove_features, StringType())\n",
    "tag_and_remove_udf = udf(pp.tag_and_remove, StringType())\n",
    "lemmatize_udf = udf(pp.lemmatize, StringType())\n",
    "check_blanks_udf = udf(pp.check_blanks, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|it wont have much...|    1|\n",
      "|serenity is a fil...|    1|\n",
      "| the rare kind of...|    1|\n",
      "| john fords most ...|    0|\n",
      "|lampoons ethnocen...|    1|\n",
      "|everything about ...|    0|\n",
      "|the talented cast...|    0|\n",
      "|the film dares it...|    1|\n",
      "|while all the bri...|    0|\n",
      "|great fights you ...|    1|\n",
      "|supremacy is bris...|    1|\n",
      "| in these linked ...|    1|\n",
      "| ultimately shopg...|    0|\n",
      "|at its core harpo...|    1|\n",
      "|a cloned human is...|    1|\n",
      "|hitchcock once fa...|    0|\n",
      "|killerman is the ...|    0|\n",
      "| arguably one of ...|    1|\n",
      "|the breezy manner...|    1|\n",
      "| very nearly as i...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Read the data (Spark)\n",
    "review_df = development_split\n",
    "\n",
    "# Rename Column\n",
    "review_df = review_df.withColumnRenamed('Review','text')\n",
    "review_df = review_df.withColumnRenamed('Freshness','label')\n",
    "review_df = review_df.withColumnRenamed('_c0','index')\n",
    "\n",
    "# Remove Null\n",
    "review_df = review_df.filter(review_df.label. isNotNull())\n",
    "\n",
    "# Change data type to Integer\n",
    "review_df = review_df.withColumn(\"label\", review_df[\"label\"].cast(IntegerType()))\n",
    "\n",
    "# Show df information\n",
    "review_df.show()\n",
    "review_df.printSchema()\n",
    "review_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|much cinematic im...|    1|\n",
      "|serenity film see...|    1|\n",
      "|rare kind spellbi...|    1|\n",
      "|john ford complet...|    0|\n",
      "|lampoon ethnocent...|    1|\n",
      "|everything benson...|    0|\n",
      "|talented cast lea...|    0|\n",
      "|film dare viewer ...|    1|\n",
      "|bright place rema...|    0|\n",
      "|great fight would...|    1|\n",
      "|supremacy pace sc...|    1|\n",
      "|link vignette yea...|    1|\n",
      "|shopgirl attracti...|    0|\n",
      "|core harpoon isnt...|    1|\n",
      "|clone human creat...|    1|\n",
      "|hitchcock say goo...|    0|\n",
      "|killerman story a...|    0|\n",
      "|important egyptia...|    1|\n",
      "|breezy manner mus...|    1|\n",
      "|inventive fascina...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove stop words to reduce dimensionality\n",
    "review_df = review_df.withColumn(\"text\", remove_stops_udf(review_df[\"text\"]))\n",
    "\n",
    "# remove other non essential words\n",
    "review_df = review_df.withColumn(\"text\", remove_features_udf(review_df[\"text\"]))\n",
    "\n",
    "# tag the words remaining and keep only Nouns, Verbs and Adjectives\n",
    "review_df = review_df.withColumn(\"text\", tag_and_remove_udf(review_df[\"text\"]))\n",
    "\n",
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "review_df = review_df.withColumn(\"text\", lemmatize_udf(review_df[\"text\"]))\n",
    "\n",
    "review_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Freshness|\n",
      "+---------+\n",
      "|        0|\n",
      "|        1|\n",
      "+---------+\n",
      "\n",
      "+-----+----------+--------------------+-----+\n",
      "|index|Unnamed: 0|                text|label|\n",
      "+-----+----------+--------------------+-----+\n",
      "|    0|         1|A cornball drone ...|    0|\n",
      "|    1|         3|I don't like impo...|    0|\n",
      "|    2|         4| The Void marks a...|    1|\n",
      "|    3|         5|The only way to l...|    0|\n",
      "|    4|         9| a tame and insul...|    0|\n",
      "|    5|        10|How sorry can you...|    0|\n",
      "|    6|        11|\"Though not parti...|    1|\n",
      "|    7|        16|\"\"\"Blood\"\" [chapt...|    1|\n",
      "|    8|        19|The lack of empat...|    0|\n",
      "|    9|        21|This modern fanta...|    1|\n",
      "|   10|        22|The best film I'v...|    0|\n",
      "|   11|        27| After being surp...|    0|\n",
      "|   12|        34|  An inert thriller.|    0|\n",
      "|   13|        35|What cannot be ar...|    1|\n",
      "|   14|        36|Amid the glut of ...|    1|\n",
      "|   15|        38|It is ultimately ...|    0|\n",
      "|   16|        40|I laughed frequen...|    0|\n",
      "|   17|        42|Fighting with My ...|    1|\n",
      "|   18|        46|Weinstein walks a...|    1|\n",
      "|   19|        47|[A] frenetic jumb...|    0|\n",
      "+-----+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[index: string, Unnamed: 0: string, text: string, label: string]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+-----+\n",
      "|index|Unnamed: 0|                text|label|\n",
      "+-----+----------+--------------------+-----+\n",
      "|    0|         1|A cornball drone ...|    0|\n",
      "|    1|         3|I don't like impo...|    0|\n",
      "|    2|         4| The Void marks a...|    1|\n",
      "|    3|         5|The only way to l...|    0|\n",
      "|    4|         9| a tame and insul...|    0|\n",
      "|    5|        10|How sorry can you...|    0|\n",
      "|    6|        11|\"Though not parti...|    1|\n",
      "|    7|        16|\"\"\"Blood\"\" [chapt...|    1|\n",
      "|    8|        19|The lack of empat...|    0|\n",
      "|    9|        21|This modern fanta...|    1|\n",
      "|   10|        22|The best film I'v...|    0|\n",
      "|   11|        27| After being surp...|    0|\n",
      "|   12|        34|  An inert thriller.|    0|\n",
      "|   13|        35|What cannot be ar...|    1|\n",
      "|   14|        36|Amid the glut of ...|    1|\n",
      "|   15|        38|It is ultimately ...|    0|\n",
      "|   16|        40|I laughed frequen...|    0|\n",
      "|   17|        42|Fighting with My ...|    1|\n",
      "|   18|        46|Weinstein walks a...|    1|\n",
      "|   19|        47|[A] frenetic jumb...|    0|\n",
      "+-----+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- Unnamed: 0: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specify Training and Test data\n",
    "training_df = review_df\n",
    "test_df = sqlContext.read.csv('/project/1000_labels_v2.csv', header=True,sep = '~')\n",
    "test_df.select('Freshness').distinct().show()\n",
    "# Rename Column\n",
    "test_df = test_df.withColumnRenamed('Review','text')\n",
    "test_df = test_df.withColumnRenamed('Freshness','label')\n",
    "test_df = test_df.withColumnRenamed('_c0','index')\n",
    "test_df.show()\n",
    "# Remove Null\n",
    "test_df.filter(test_df.label.isNotNull())\n",
    "# Change data type to Integer\n",
    "test_df = test_df.withColumn(\"label\", test_df[\"label\"].cast(IntegerType()))\n",
    "\n",
    "\n",
    "test_df.show()\n",
    "test_df.printSchema()\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|                text|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|A cornball drone ...|    0|       1.0|\n",
      "|I don't like impo...|    0|       1.0|\n",
      "| The Void marks a...|    1|       0.0|\n",
      "|The only way to l...|    0|       1.0|\n",
      "| a tame and insul...|    0|       0.0|\n",
      "|How sorry can you...|    0|       0.0|\n",
      "|\"Though not parti...|    1|       1.0|\n",
      "|\"\"\"Blood\"\" [chapt...|    1|       1.0|\n",
      "|The lack of empat...|    0|       1.0|\n",
      "|This modern fanta...|    1|       1.0|\n",
      "|The best film I'v...|    0|       1.0|\n",
      "| After being surp...|    0|       1.0|\n",
      "|  An inert thriller.|    0|       1.0|\n",
      "|What cannot be ar...|    1|       1.0|\n",
      "|Amid the glut of ...|    1|       0.0|\n",
      "|It is ultimately ...|    0|       0.0|\n",
      "|I laughed frequen...|    0|       1.0|\n",
      "|Fighting with My ...|    1|       1.0|\n",
      "|Weinstein walks a...|    1|       1.0|\n",
      "|[A] frenetic jumb...|    0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol='words', outputCol=\"features\")\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")\n",
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nb])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)\n",
    "\n",
    "# Error\n",
    "cvModel = cv.fit(training_df)\n",
    "\n",
    "result = cvModel.transform(test_df)\n",
    "prediction_df = result.select(\"text\", \"label\", \"prediction\")\n",
    "prediction_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6446446446446447"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Evaluate the Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(result, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|              Review|predicted_train|\n",
      "+--------------------+---------------+\n",
      "| An excessively c...|              0|\n",
      "|Osment's the weak...|              1|\n",
      "|If you want to se...|              1|\n",
      "|Not only do we ra...|              0|\n",
      "|You never know wh...|              1|\n",
      "|There are genuine...|              0|\n",
      "| ...dissects cont...|              1|\n",
      "|It's convivial, i...|              1|\n",
      "|\"\"\"Ma\"\" is poorly...|              0|\n",
      "|\" Balance out the...|              1|\n",
      "|Shin infuses an i...|              0|\n",
      "| An unappealing c...|              1|\n",
      "|It feels like the...|              1|\n",
      "| The Mummy is the...|              0|\n",
      "|Sporadically test...|              1|\n",
      "|Sure, Tracy Olive...|              1|\n",
      "|James Marsh's Pro...|              1|\n",
      "|It speaks to its ...|              0|\n",
      "|The Wedding Guest...|              0|\n",
      "|A beast of a movi...|              1|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_df_2.select('Review','predicted_train').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"Union can only be performed on tables with the same number of columns, but the first table has 2 columns and the second table has 4 columns;;\\n'Union\\n:- Project [lemmatize(text#10624) AS text#10628, label#10598]\\n:  +- Project [tag_and_remove(text#10620) AS text#10624, label#10598]\\n:     +- Project [remove_features(text#10616) AS text#10620, label#10598]\\n:        +- Project [remove_stops(text#10590) AS text#10616, label#10598]\\n:           +- Project [text#10590, cast(label#10593L as int) AS label#10598]\\n:              +- Filter isnotnull(label#10593L)\\n:                 +- Project [text#10590, Freshness#1L AS label#10593L]\\n:                    +- Project [Review#0 AS text#10590, Freshness#1L]\\n:                       +- LogicalRDD [Review#0, Freshness#1L], false\\n+- Relation[_c0#10649,Unnamed: 0#10650,Review#10651,predicted_train#10652] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o17219.union.\n: org.apache.spark.sql.AnalysisException: Union can only be performed on tables with the same number of columns, but the first table has 2 columns and the second table has 4 columns;;\n'Union\n:- Project [lemmatize(text#10624) AS text#10628, label#10598]\n:  +- Project [tag_and_remove(text#10620) AS text#10624, label#10598]\n:     +- Project [remove_features(text#10616) AS text#10620, label#10598]\n:        +- Project [remove_stops(text#10590) AS text#10616, label#10598]\n:           +- Project [text#10590, cast(label#10593L as int) AS label#10598]\n:              +- Filter isnotnull(label#10593L)\n:                 +- Project [text#10590, Freshness#1L AS label#10593L]\n:                    +- Project [Review#0 AS text#10590, Freshness#1L]\n:                       +- LogicalRDD [Review#0, Freshness#1L], false\n+- Relation[_c0#10649,Unnamed: 0#10650,Review#10651,predicted_train#10652] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.failAnalysis(CheckAnalysis.scala:43)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.failAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$12.apply(CheckAnalysis.scala:283)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$12.apply(CheckAnalysis.scala:280)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:280)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.Dataset.withSetOperator(Dataset.scala:3424)\n\tat org.apache.spark.sql.Dataset.union(Dataset.scala:1862)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-7af099f0f086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Combine with review_df with 2000 labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mreview_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_df_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Remove Null\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36munion\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0mAlso\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSQL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mresolves\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0mby\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mby\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \"\"\"\n\u001b[0;32m-> 1461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"Union can only be performed on tables with the same number of columns, but the first table has 2 columns and the second table has 4 columns;;\\n'Union\\n:- Project [lemmatize(text#10624) AS text#10628, label#10598]\\n:  +- Project [tag_and_remove(text#10620) AS text#10624, label#10598]\\n:     +- Project [remove_features(text#10616) AS text#10620, label#10598]\\n:        +- Project [remove_stops(text#10590) AS text#10616, label#10598]\\n:           +- Project [text#10590, cast(label#10593L as int) AS label#10598]\\n:              +- Filter isnotnull(label#10593L)\\n:                 +- Project [text#10590, Freshness#1L AS label#10593L]\\n:                    +- Project [Review#0 AS text#10590, Freshness#1L]\\n:                       +- LogicalRDD [Review#0, Freshness#1L], false\\n+- Relation[_c0#10649,Unnamed: 0#10650,Review#10651,predicted_train#10652] csv\\n\""
     ]
    }
   ],
   "source": [
    "# Read the data (Spark)\n",
    "review_df_2 = sqlContext.read.csv('/project/12000_predicted_labels.csv', header=True,sep='~')\n",
    "\n",
    "# Combine with review_df with 2000 labels\n",
    "review_df = review_df.union(review_df_2)\n",
    "\n",
    "# Remove Null\n",
    "review_df = review_df.filter(review_df.predicted_train.isNotNull())\n",
    "\n",
    "review_df = review_df.withColumnRenamed('Review','text')\n",
    "review_df = review_df.withColumnRenamed('predicted_train','label')\n",
    "review_df = review_df.withColumn(\"label\", review_df[\"label\"].cast(IntegerType()))\n",
    "\n",
    "# remove stop words to reduce dimensionality\n",
    "review_df = review_df.withColumn(\"text\", remove_stops_udf(review_df[\"text\"]))\n",
    "\n",
    "# remove other non essential words\n",
    "review_df = review_df.withColumn(\"text\", remove_features_udf(review_df[\"text\"]))\n",
    "\n",
    "# tag the words remaining and keep only Nouns, Verbs and Adjectives\n",
    "review_df = review_df.withColumn(\"text\", tag_and_remove_udf(review_df[\"text\"]))\n",
    "\n",
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "review_df = review_df.withColumn(\"text\", lemmatize_udf(review_df[\"text\"]))\n",
    "\n",
    "training_df = review_df\n",
    "\n",
    "training_df.show()\n",
    "training_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol='words', outputCol=\"features\")\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")\n",
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nb])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)\n",
    "\n",
    "cvModel = cv.fit(training_df)\n",
    "\n",
    "result = cvModel.transform(test_df)\n",
    "prediction_df = result.select(\"text\", \"label\", \"prediction\")\n",
    "\n",
    "#Evaluate the accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(result, {evaluator.metricName: \"accuracy\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
