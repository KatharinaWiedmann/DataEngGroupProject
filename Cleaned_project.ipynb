{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team: Data Magicians\n",
    "Members:\n",
    "<p>\n",
    "Arda Putra Ryandika\n",
    "</p>\n",
    "<p>\n",
    "Atthaya Busayaruengrat (Hong)\n",
    "</p>\n",
    "<p>\n",
    "Jingxue (Vera) Cao\n",
    "</p>\n",
    "<p>\n",
    "Katharina Wiedmann  \n",
    "</p>\n",
    "<p>\n",
    "Ying Tung (Debbie) Lau\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "In this project, we are taking three sources of movie review data (csv, tsv, web scraping) and aiming to create weak labelling functions based on the data. The objective of the project is to compare the performance of a machine learning based classifier with 3000 datapoints compared to 3000 + another 12000 weak labeled datapoints. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Review Data\n",
    "\n",
    "We split the work of obtaining data to three group members (Hong, Debbie, Vera) . Hong was responsible for scraping movie reviews from the rotten tomato website, while Debbie and Vera sought for other data formats like tsv and csv to ensure the sufficiency of data sample. \n",
    "\n",
    "The dataset contains two columns: one is the text review posted by people, another is the label 1 or 0. 1 indicates a positive review (fresh), and 0 indicates an non-positive review (not fresh).\n",
    "\n",
    "The final dataset consists of 15000 reviews in total, with 5000 from web scrapping, 5000 from csv file, and 5000 from tsv file. \n",
    "\n",
    "We further sampled 2000 data points for labelling function development (development data set) and made sure the positive and non-positive reviews had the same amounts. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building classifiers \n",
    "\n",
    "Arda was responsible for building a NLP classifier, which will be later applied to compare with the labelling function classifier. This model was done by utilizing tokens generated from two types of reviews and fed as features. This NLP classifier yielded 70% accuracy on the testing set. \n",
    "Arda also implemented the spark on Faculty so that the following labelling functions can be implemented in a spark environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Labelling functions\n",
    "\n",
    "Meanwhile, the rest of the team members worked on generating weak labelling functions based on the findings in data exploration. \n",
    "\n",
    "During data exploration, as implementing spark slowed down the computation process as it partitions the dataset, we chose to use pandas to notice any patterns and differences in positive and non-positive reviews. We faced a few challenges in this stage. For example, we built a lemmatization function on the word count dataframe to avoid classifier bias caused by word inflections. However, many words were converted into completely different words incorrectly. Due to the mis-correction on words, we decided not to use lemmatization. \n",
    "\n",
    "As for building the labelling functions, Katie looked for stop words in the review first and counted the word occurrences in positive reviews and negative reviews. By identifying the difference in the word occurrences, we built our labelling functions to separate positive and non-positive reviews based on exclusive words. \n",
    "\n",
    "We also looked for capital letters mentioned in each type of reviews, but since the capital letters were irrelevant to emotions and most didn’t make sense for understanding, we decided not to create a labelling function based on it.\n",
    "\n",
    "As we noticed keywords like “too” and “far” occurred more often in a specific type of reviews, so other labelling functions were created based on the keywords. \n",
    "Similarly, exclamation mark and question mark also appeared more often in one type of reviews, so we created labelling functions based on them as well.\n",
    "\n",
    "After finalising the labeling functions, Arda built a classifier to combine the labeling functions together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "<>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub\n",
    "Every time we made a change, we used terminal in Faculty to push the changes to our group repository. \n",
    "After committing the change, we used “git status” to double check the state of repository. Using “git diff” also enables us to see all the changes in repository.\n",
    "\n",
    "Link to GitHub repository:\n",
    "https://github.com/KatharinaWiedmann/DataEngGroupProject.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIRA board \n",
    "We used JIRA to manage the progress of our project and record our meeting topics. The brief of meetings is shown as below:\n",
    "<p>\n",
    "First meeting:\n",
    "•\tRotten Tomatoes labelling functions - good movie or not (positive/ negative rating). \n",
    "•\tTwitter data: Labelling whether someone is a Boris Johnson supporter or not. \n",
    "•\tYouTube comments: positive or negative comment \n",
    "•\tPromotion emails - is an email a spam email or a genuine email. \n",
    "</p>\n",
    "<p>\n",
    "Second meeting:\n",
    "•\tLabelling functions (Vera, Debbie, Katie) \n",
    "•\tClassifier (Arda) \n",
    "•\tWeb Scraping (Hong) \n",
    "•\tGitHub (Katie)\n",
    "</p>\n",
    "<p>\n",
    "Third meeting:\n",
    "•\tRewriting labelling functions (SparkLFApplier - done together)\n",
    "•\tCombining labelling functions (Hong & Katie)\n",
    "•\tAnalyzing summary/ results labelling functions (Hong & Katie)\n",
    "•\tPlug in classifier (Arda)\n",
    "•\tCompare results between using labelling functions and not labelling functions (Arda)\n",
    "•\tIterate on Mark-up/ write-down (Vera)\n",
    "•\tJIRA cleanup & additional notes (Katie)\n",
    "•\tGithub reminder - don't forget to push/ pull (everyone)\n",
    "•\tMake sensitivity analysis work (Debbie) \n",
    "•\tnt function (Hong)\n",
    "</p>\n",
    "\n",
    "Further details can be found at:\n",
    "http://csjira2.cs.ucl.ac.uk:8080/secure/RapidBoard.jspa?rapidView=316&view=detail&selectedIssue=DED-16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pandas==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    libprotobuf-3.11.4         |       hd408876_0         2.9 MB\n",
      "    ninja-1.9.0                |   py36hfd86e86_0         1.2 MB\n",
      "    protobuf-3.11.4            |   py36he6710b0_0         635 KB\n",
      "    tqdm-4.42.1                |             py_0          56 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.8 MB\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  python_abi-3.6-1_cp36m\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  libprotobuf        conda-forge::libprotobuf-3.11.3-h8b12~ --> pkgs/main::libprotobuf-3.11.4-hd408876_0\n",
      "  networkx                                         2.3-py_0 --> 2.4-py_0\n",
      "  protobuf           conda-forge::protobuf-3.11.3-py36he1b~ --> pkgs/main::protobuf-3.11.4-py36he6710b0_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ninja                conda-forge::ninja-1.10.0-hdb11119_1 --> pkgs/main::ninja-1.9.0-py36hfd86e86_0\n",
      "  tqdm                        conda-forge::tqdm-4.43.0-py_0 --> pkgs/main::tqdm-4.42.1-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "tqdm-4.42.1          | 56 KB     | ##################################### | 100% \n",
      "protobuf-3.11.4      | 635 KB    | ##################################### | 100% \n",
      "libprotobuf-3.11.4   | 2.9 MB    | ##################################### | 100% \n",
      "ninja-1.9.0          | 1.2 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda upgrade --all -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - networkx==2.3.0\n",
      "\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  networkx                                         2.4-py_0 --> 2.3-py_0\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install networkx==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#needs to show version 2.3\n",
    "\n",
    "import networkx as nx\n",
    "nx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - snorkel==0.9.0\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.6-1_cp36m\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi              pkgs/main::certifi-2019.11.28-py36_0 --> conda-forge::certifi-2019.11.28-py36h9f0ad1d_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
      "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install snorkel==0.9.0 -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier,LabelModel\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from itertools import repeat\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n",
      "<pyspark.sql.session.SparkSession object at 0x7f0dd9209d30>\n"
     ]
    }
   ],
   "source": [
    "#Spark \n",
    "\n",
    "# Spark Environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "import pyspark\n",
    "\n",
    "number_cores = 4\n",
    "memory_gb = 16\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "print(sc)\n",
    "\n",
    "# get the context\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "print(spark) \n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse all from DVD releases page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = 'https://www.rottentomatoes.com/api/private/v2.0/browse?maxTomato=100&services=amazon%3Bhbo_go%3Bitunes%3Bnetflix_iw%3Bvudu%3Bamazon_prime%3Bfandango_now&certified&sortBy=release&type=dvd-streaming-all&page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get movie url\n",
    "movie_url = []\n",
    "start_page = 1 ; end_page = 1\n",
    "while start_page <= end_page:\n",
    "#     time.sleep(7)\n",
    "    url = main + str(start_page)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code !=200:\n",
    "        print('Request error')\n",
    "        break\n",
    "    file = json.loads(response.text)\n",
    "    for i in file['results']:\n",
    "        movie_url = movie_url + [i['url']]\n",
    "    start_page +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples for the url:\n",
      "\n",
      "/m/frozen_ii\n",
      "/m/playmobil_the_movie\n",
      "/m/charlies_angels_2019\n",
      "\n",
      "Number of movies in list: 32\n"
     ]
    }
   ],
   "source": [
    "print('Examples for the url:\\n')\n",
    "for i in range(3):\n",
    "    print(movie_url[i])\n",
    "print('\\nNumber of movies in list: {}'.format(len(movie_url)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into lists of 50 movies to do the scraping\n",
    "movie_url_split = [movie_url[i:i+50] for i in range(0,600,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_url_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reviews from the web\n",
    "reviews = []\n",
    "titles = []\n",
    "ratings = []\n",
    "for split in movie_url_split: # Loop through each split\n",
    "#     time.sleep(7)\n",
    "    for title in split: # Loop through each movie title\n",
    "        url = 'https://www.rottentomatoes.com'+title\n",
    "#         time.sleep(7)\n",
    "        response = requests.get(url)\n",
    "        # Check the request status code\n",
    "        if response.status_code != 200:\n",
    "            print('Request error')\n",
    "            break\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Get labels from each review (fresh vs. rotten)\n",
    "        fresh_rotten = soup.find_all(class_=\"review_quote\")\n",
    "        \n",
    "        # Get movie title\n",
    "        title = soup.find(class_=\"mop-ratings-wrap__title mop-ratings-wrap__title--top\").getText()\n",
    "        \n",
    "        # Get reviews\n",
    "        review = soup.find_all('blockquote')\n",
    "        for i in review:\n",
    "            j = str(i.contents[1])\n",
    "            j = j.replace(\"<p>\\n                    \\n                        \",\"\")\n",
    "            j = j.replace(\"\\n                    \\n                </p>\",\"\")\n",
    "            reviews = reviews + [j]\n",
    "            titles = titles + [title]\n",
    "        \n",
    "        # Identify labels\n",
    "        for i in fresh_rotten:\n",
    "            temp = str(i.findChildren()[2])\n",
    "            if re.search('rotten',temp):\n",
    "                ratings = ratings + ['rotten']\n",
    "            else:\n",
    "                ratings = ratings + ['fresh']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame to store the scraped data\n",
    "df = pd.DataFrame([titles,reviews,ratings],index = ['title','review','rating']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 329 entries, 0 to 329\n",
      "Data columns (total 3 columns):\n",
      "title     329 non-null object\n",
      "review    329 non-null object\n",
      "rating    329 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 10.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Clean the data (drop duplicates, check missing values etc.)\n",
    "df = df.drop_duplicates()\n",
    "df = df.replace([None],np.nan)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>Frozen II is a worthy follow-up with enough he...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>[Some] sequences have a gleam and a rhythm to ...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>...one of the most beautifully animated films ...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                             review rating\n",
       "0  Frozen II  Frozen II is a worthy follow-up with enough he...  fresh\n",
       "1  Frozen II  [Some] sequences have a gleam and a rhythm to ...  fresh\n",
       "2  Frozen II  ...one of the most beautifully animated films ...  fresh"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV files\n",
    "# df.to_csv('web_scraping_rotten_tomatoes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Preparing TSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TSV file\n",
    "tsv_reviews = pd.read_csv('/project/reviews.tsv', sep='\\t', header=0, encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>fresh</th>\n",
       "      <th>critic</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A distinctly gallows take on contemporary fina...</td>\n",
       "      <td>3/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>PJ Nabarro</td>\n",
       "      <td>0</td>\n",
       "      <td>Patrick Nabarro</td>\n",
       "      <td>November 10, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>It's an allegory in search of a meaning that n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotten</td>\n",
       "      <td>Annalee Newitz</td>\n",
       "      <td>0</td>\n",
       "      <td>io9.com</td>\n",
       "      <td>May 23, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>... life lived in a bubble in financial dealin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Sean Axmaker</td>\n",
       "      <td>0</td>\n",
       "      <td>Stream on Demand</td>\n",
       "      <td>January 4, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Continuing along a line introduced in last yea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Daniel Kasman</td>\n",
       "      <td>0</td>\n",
       "      <td>MUBI</td>\n",
       "      <td>November 16, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>... a perverse twist on neorealism...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Cinema Scope</td>\n",
       "      <td>October 12, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review rating   fresh  \\\n",
       "0   3  A distinctly gallows take on contemporary fina...    3/5   fresh   \n",
       "1   3  It's an allegory in search of a meaning that n...    NaN  rotten   \n",
       "2   3  ... life lived in a bubble in financial dealin...    NaN   fresh   \n",
       "3   3  Continuing along a line introduced in last yea...    NaN   fresh   \n",
       "4   3             ... a perverse twist on neorealism...     NaN   fresh   \n",
       "\n",
       "           critic  top_critic         publisher               date  \n",
       "0      PJ Nabarro           0   Patrick Nabarro  November 10, 2018  \n",
       "1  Annalee Newitz           0           io9.com       May 23, 2018  \n",
       "2    Sean Axmaker           0  Stream on Demand    January 4, 2018  \n",
       "3   Daniel Kasman           0              MUBI  November 16, 2017  \n",
       "4             NaN           0      Cinema Scope   October 12, 2017  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract review and fresh columns\n",
    "tsv_reviews = pd.DataFrame(tsv_reviews, columns = ['review', 'fresh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>fresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A distinctly gallows take on contemporary fina...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's an allegory in search of a meaning that n...</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... life lived in a bubble in financial dealin...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Continuing along a line introduced in last yea...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>... a perverse twist on neorealism...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review   fresh\n",
       "0  A distinctly gallows take on contemporary fina...   fresh\n",
       "1  It's an allegory in search of a meaning that n...  rotten\n",
       "2  ... life lived in a bubble in financial dealin...   fresh\n",
       "3  Continuing along a line introduced in last yea...   fresh\n",
       "4             ... a perverse twist on neorealism...    fresh"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    5563\n",
       "fresh        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN rows in reviews\n",
    "index_name = tsv_reviews[(tsv_reviews['review'].isnull())].index\n",
    "tsv_reviews.drop(index_name, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    0\n",
       "fresh     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename fresh as 1 and rotten as 0\n",
    "tsv_reviews['fresh'].replace({'fresh':'1', 'rotten':'0'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 47761 to 18651\n",
      "Data columns (total 2 columns):\n",
      "Review       5000 non-null object\n",
      "Freshness    5000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Rename columns\n",
    "tsv_reviews.rename(columns={'fresh':'Freshness','review':'Review'},inplace=True)\n",
    "tsv_reviews = tsv_reviews.sample(5000)\n",
    "#take 5000\n",
    "tsv_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Preparing CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Freshness                                             Review\n",
       "0          1   Manakamana doesn't answer any questions, yet ...\n",
       "1          1   Wilfully offensive and powered by a chest-thu...\n",
       "2          0   It would be difficult to imagine material mor...\n",
       "3          0   Despite the gusto its star brings to the role...\n",
       "4          0   If there was a good idea at the core of this ..."
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file\n",
    "csv_reviews= pd.read_csv('/project/rotten_tomatoes_reviews.csv')\n",
    "csv_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463116</th>\n",
       "      <td>Além de contar com as estupendas atuações de ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32549</th>\n",
       "      <td>Seriously undermined by the skeletal script, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152364</th>\n",
       "      <td>Pretty to look at, the film is not quite the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444218</th>\n",
       "      <td>It's a tough job but someone's got to do it i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337897</th>\n",
       "      <td>Stewart plays Cole with her million-dollar ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "463116   Além de contar com as estupendas atuações de ...          1\n",
       "32549    Seriously undermined by the skeletal script, ...          0\n",
       "152364   Pretty to look at, the film is not quite the ...          1\n",
       "444218   It's a tough job but someone's got to do it i...          1\n",
       "337897   Stewart plays Cole with her million-dollar ha...          1"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 463116 to 201237\n",
      "Data columns (total 2 columns):\n",
      "Review       5000 non-null object\n",
      "Freshness    5000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Swap Freshness and Review \n",
    "columns_titles = [\"Review\",\"Freshness\"]\n",
    "csv_reviews=csv_reviews.reindex(columns=columns_titles)\n",
    "csv_reviews = csv_reviews.sample(5000)\n",
    "\n",
    "csv_reviews.head()\n",
    "csv_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping & Preparing scrapped data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>Babenco's cinematic farewell isn't perfect by ...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>This is a good film if you are looking for som...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>My Hindu Friend is a celebration of life, love...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>I wouldn't miss it; it's a film that's more th...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>...surreal, reflective (though never sentiment...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              title  \\\n",
       "0           0  My Hindu Friend (Meu amigo Hindu)   \n",
       "1           1  My Hindu Friend (Meu amigo Hindu)   \n",
       "2           2  My Hindu Friend (Meu amigo Hindu)   \n",
       "3           3  My Hindu Friend (Meu amigo Hindu)   \n",
       "4           4  My Hindu Friend (Meu amigo Hindu)   \n",
       "\n",
       "                                              review rating  \n",
       "0  Babenco's cinematic farewell isn't perfect by ...  fresh  \n",
       "1  This is a good film if you are looking for som...  fresh  \n",
       "2  My Hindu Friend is a celebration of life, love...  fresh  \n",
       "3  I wouldn't miss it; it's a film that's more th...  fresh  \n",
       "4  ...surreal, reflective (though never sentiment...  fresh  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Web Scraping Data\n",
    "web_scraping_reviews= pd.read_csv('/project/web_scraping_rotten_tomatoes.csv')\n",
    "web_scraping_reviews.head()\n",
    "\n",
    "web_scraping_reviews = web_scraping_reviews.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>3553</td>\n",
       "      <td>Brightburn</td>\n",
       "      <td>Brightburn takes a cool premise and executes i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>2566</td>\n",
       "      <td>Corporate Animals</td>\n",
       "      <td>Tries to coast on grisly slapstick and the kin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>3787</td>\n",
       "      <td>The Intruder</td>\n",
       "      <td>It's fun! Is it brilliant or groundbreaking? No.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1784</td>\n",
       "      <td>Eli</td>\n",
       "      <td>Despite some good scares, Eli winds up being m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>4455</td>\n",
       "      <td>Hale County This Morning, This Evening</td>\n",
       "      <td>Much of the imagery is exquisite.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                   title  \\\n",
       "3553        3553                              Brightburn   \n",
       "2566        2566                       Corporate Animals   \n",
       "3787        3787                            The Intruder   \n",
       "1784        1784                                     Eli   \n",
       "4455        4455  Hale County This Morning, This Evening   \n",
       "\n",
       "                                                 Review Freshness  \n",
       "3553  Brightburn takes a cool premise and executes i...         1  \n",
       "2566  Tries to coast on grisly slapstick and the kin...         0  \n",
       "3787   It's fun! Is it brilliant or groundbreaking? No.         0  \n",
       "1784  Despite some good scares, Eli winds up being m...         0  \n",
       "4455                  Much of the imagery is exquisite.         1  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename fresh as 1 and rotten as 0\n",
    "web_scraping_reviews['rating'].replace({'fresh':'1', 'rotten':'0'}, inplace = True)\n",
    "\n",
    "#Rename Rating to Review \n",
    "web_scraping_reviews.rename(columns={'rating':'Freshness', 'review':'Review'},inplace=True)\n",
    "web_scraping_reviews.head()\n",
    "\n",
    "# Extract Review and Freshness columns\n",
    "web_scraping_reviews= pd.DataFrame(web_scraping_reviews, columns = ['Review', 'Freshness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>Brightburn takes a cool premise and executes i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>Tries to coast on grisly slapstick and the kin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>It's fun! Is it brilliant or groundbreaking? No.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>Despite some good scares, Eli winds up being m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>Much of the imagery is exquisite.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review Freshness\n",
       "3553  Brightburn takes a cool premise and executes i...         1\n",
       "2566  Tries to coast on grisly slapstick and the kin...         0\n",
       "3787   It's fun! Is it brilliant or groundbreaking? No.         0\n",
       "1784  Despite some good scares, Eli winds up being m...         0\n",
       "4455                  Much of the imagery is exquisite.         1"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_scraping_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all the data together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463116</th>\n",
       "      <td>Além de contar com as estupendas atuações de ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32549</th>\n",
       "      <td>Seriously undermined by the skeletal script, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152364</th>\n",
       "      <td>Pretty to look at, the film is not quite the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444218</th>\n",
       "      <td>It's a tough job but someone's got to do it i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337897</th>\n",
       "      <td>Stewart plays Cole with her million-dollar ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review Freshness\n",
       "463116   Além de contar com as estupendas atuações de ...         1\n",
       "32549    Seriously undermined by the skeletal script, ...         0\n",
       "152364   Pretty to look at, the film is not quite the ...         1\n",
       "444218   It's a tough job but someone's got to do it i...         1\n",
       "337897   Stewart plays Cole with her million-dollar ha...         1"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat two files into all_reviews\n",
    "all_reviews=pd.concat([csv_reviews, tsv_reviews,web_scraping_reviews],axis=0, sort=False)\n",
    "all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 2)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into test and training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews['Freshness'] = all_reviews['Freshness'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(all_reviews,test_size=0.2,stratify = all_reviews['Freshness'],\\\n",
    "                               random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 60 to 25417\n",
      "Data columns (total 2 columns):\n",
      "Review       12000 non-null object\n",
      "Freshness    12000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 281.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000 entries, 415069 to 26912\n",
      "Data columns (total 2 columns):\n",
      "Review       3000 non-null object\n",
      "Freshness    3000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 70.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid off labels in training data \n",
    "train = train.drop('Freshness', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Tired, crude celebutante parody isn't funny.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377756</th>\n",
       "      <td>There's barely an incident from the right hon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16617</th>\n",
       "      <td>Though probably well-intentioned, Radio comes ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>Existing below the radar is largely what A Bre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121573</th>\n",
       "      <td>A sad, badly made, badly written little flick...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "335          Tired, crude celebutante parody isn't funny.          0\n",
       "377756   There's barely an incident from the right hon...          0\n",
       "16617   Though probably well-intentioned, Radio comes ...          0\n",
       "2139    Existing below the radar is largely what A Bre...          1\n",
       "121573   A sad, badly made, badly written little flick...          0"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From labelled test set\n",
    "#extract a sample to find out about which labelling functions could be written\n",
    "\n",
    "development_split = test.sample(2000,random_state=42)\n",
    "development_split.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Tired, crude celebutante parody isn't funny.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377756</th>\n",
       "      <td>There's barely an incident from the right hon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16617</th>\n",
       "      <td>Though probably well-intentioned, Radio comes ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>Existing below the radar is largely what A Bre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121573</th>\n",
       "      <td>A sad, badly made, badly written little flick...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "335          Tired, crude celebutante parody isn't funny.          0\n",
       "377756   There's barely an incident from the right hon...          0\n",
       "16617   Though probably well-intentioned, Radio comes ...          0\n",
       "2139    Existing below the radar is largely what A Bre...          1\n",
       "121573   A sad, badly made, badly written little flick...          0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick check on development_split df (for finding labeling functions)\n",
    "development_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       2000\n",
       "Freshness    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only necessary to do once \n",
    "# development_split.to_csv('development_split.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>Existing below the radar is largely what A Bre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27283</th>\n",
       "      <td>Strangely, wonderfully, The Artist feels as bo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>Aniara mostly feels like a dramatization of fa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253152</th>\n",
       "      <td>The movie is half clever, half ridiculous, su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27351</th>\n",
       "      <td>With supreme confidence and an informed, infec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "2139    Existing below the radar is largely what A Bre...          1\n",
       "27283   Strangely, wonderfully, The Artist feels as bo...          1\n",
       "5122    Aniara mostly feels like a dramatization of fa...          1\n",
       "253152   The movie is half clever, half ridiculous, su...          1\n",
       "27351   With supreme confidence and an informed, infec...          1"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Tired, crude celebutante parody isn't funny.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377756</th>\n",
       "      <td>There's barely an incident from the right hon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16617</th>\n",
       "      <td>Though probably well-intentioned, Radio comes ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121573</th>\n",
       "      <td>A sad, badly made, badly written little flick...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>Much of what transpires in [Claudio] Giovannes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "335          Tired, crude celebutante parody isn't funny.          0\n",
       "377756   There's barely an incident from the right hon...          0\n",
       "16617   Though probably well-intentioned, Radio comes ...          0\n",
       "121573   A sad, badly made, badly written little flick...          0\n",
       "710     Much of what transpires in [Claudio] Giovannes...          0"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split_fresh = development_split[development_split['Freshness'] == 1]\n",
    "development_split_rotten = development_split[development_split['Freshness'] == 0]\n",
    "development_split_fresh.head()\n",
    "development_split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1187 entries, 2139 to 49607\n",
      "Data columns (total 2 columns):\n",
      "Review       1187 non-null object\n",
      "Freshness    1187 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 27.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 813 entries, 335 to 300854\n",
      "Data columns (total 2 columns):\n",
      "Review       813 non-null object\n",
      "Freshness    813 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 19.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# fresh reviews \n",
    "development_split_fresh.info()\n",
    "# rotten reviews \n",
    "development_split_rotten.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation \n",
    "def remove_punctuation(dataframe):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in dataframe.Review.str.lower():\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    existing below the radar is largely what a bre...\n",
       "1    strangely wonderfully the artist feels as bold...\n",
       "2    aniara mostly feels like a dramatization of fa...\n",
       "3     the movie is half clever half ridiculous surp...\n",
       "4    with supreme confidence and an informed infect...\n",
       "dtype: object"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from fresh reviews & turn into Series\n",
    "split_fresh= pd.Series(remove_punctuation(development_split_fresh))\n",
    "split_fresh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordList = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\\\n",
    "                \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\\\n",
    "                \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\",\\\n",
    "                \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\",\\\n",
    "                \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\",\\\n",
    "                \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\",\\\n",
    "                \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\",\\\n",
    "                \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\\\n",
    "                \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords from fresh\n",
    "\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_fresh.replace(replacements, regex=True, inplace=True)\n",
    "split_fresh.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization and Count again\n",
    "def stem_recount(df):\n",
    "    import pandas as pd\n",
    "    # Lemmatization\n",
    "    from nltk import LancasterStemmer\n",
    "    st = LancasterStemmer()\n",
    "    newdf = df.copy()\n",
    "    for i in range(0,len(df)):\n",
    "        newdf.iloc[i,0] = st.stem(str(df.iloc[i,0])) \n",
    "        # Plz make sure the word column is the first column in df when using this function\n",
    "    \n",
    "    # Recount\n",
    "    duplicate = newdf[newdf.duplicated(['index'])]\n",
    "    # Plz make sure the 'index' is the column name consisting of words\n",
    "    for i in range(0,len(newdf)):\n",
    "        if i >= len(duplicate):\n",
    "            break\n",
    "        if newdf.iloc[i,0] == duplicate.iloc[i,0]:\n",
    "            newdf.iloc[i,1] = newdf.iloc[i,1] + duplicate.iloc[i,1]\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_fresh = split_fresh.str.split(expand=True).stack().value_counts()\n",
    "common_words_fresh_df = pd.DataFrame(common_words_fresh)\n",
    "common_words_fresh_df = common_words_fresh_df.rename({0:'Occurence good review'}, axis='columns')\n",
    "new_common_words_fresh_df = common_words_fresh_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movy</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lik</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ful</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>best</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>film</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>good</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fun</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ev</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>review</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tim</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>span</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>much</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>way</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mak</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stil</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>too</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nev</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>new</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gre</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lov</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>wel</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>comedy</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lif</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>us</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dram</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>may</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>enough</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>categ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6240</th>\n",
       "      <td>intellig</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6241</th>\n",
       "      <td>sugarysweet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6242</th>\n",
       "      <td>jul</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6243</th>\n",
       "      <td>innoc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6244</th>\n",
       "      <td>cadillac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6245</th>\n",
       "      <td>reput</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>housew</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6247</th>\n",
       "      <td>selfsatisfy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>numb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>rec</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6250</th>\n",
       "      <td>wel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6251</th>\n",
       "      <td>unleash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>subst</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>suggest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>altm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6255</th>\n",
       "      <td>walk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6256</th>\n",
       "      <td>cobain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6257</th>\n",
       "      <td>streep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6258</th>\n",
       "      <td>unmitig</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6259</th>\n",
       "      <td>che</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6260</th>\n",
       "      <td>gossip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6261</th>\n",
       "      <td>ve</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6262</th>\n",
       "      <td>actionhunk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>lincoln</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>newel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>fool</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>distinct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>top</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6268</th>\n",
       "      <td>mourn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  Occurence good review\n",
       "0            film                    264\n",
       "1            movy                    106\n",
       "2              on                    101\n",
       "3             lik                     79\n",
       "4           story                     77\n",
       "5             ful                     63\n",
       "6            best                     56\n",
       "7            film                     55\n",
       "8            good                     55\n",
       "9             fun                     49\n",
       "10             ev                     48\n",
       "11         review                     48\n",
       "12            tim                     47\n",
       "13           span                     45\n",
       "14           much                     42\n",
       "15            way                     42\n",
       "16            mak                     41\n",
       "17           stil                     40\n",
       "18            too                     39\n",
       "19            nev                     38\n",
       "20            new                     38\n",
       "21            gre                     38\n",
       "22            lov                     37\n",
       "23            wel                     37\n",
       "24         comedy                     37\n",
       "25            lif                     36\n",
       "26             us                     35\n",
       "27           dram                     34\n",
       "28            may                     34\n",
       "29         enough                     33\n",
       "...           ...                    ...\n",
       "6239        categ                      1\n",
       "6240     intellig                      1\n",
       "6241  sugarysweet                      1\n",
       "6242          jul                      1\n",
       "6243        innoc                      1\n",
       "6244     cadillac                      1\n",
       "6245        reput                      1\n",
       "6246       housew                      1\n",
       "6247  selfsatisfy                      1\n",
       "6248         numb                      1\n",
       "6249          rec                      1\n",
       "6250          wel                      1\n",
       "6251      unleash                      1\n",
       "6252        subst                      1\n",
       "6253      suggest                      1\n",
       "6254         altm                      1\n",
       "6255         walk                      1\n",
       "6256       cobain                      1\n",
       "6257       streep                      1\n",
       "6258      unmitig                      1\n",
       "6259          che                      1\n",
       "6260       gossip                      1\n",
       "6261           ve                      1\n",
       "6262   actionhunk                      1\n",
       "6263      lincoln                      1\n",
       "6264        newel                      1\n",
       "6265         fool                      1\n",
       "6266     distinct                      1\n",
       "6267          top                      1\n",
       "6268        mourn                      1\n",
       "\n",
       "[6269 rows x 2 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_recount(new_common_words_fresh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>films</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drama</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enough</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feelgood</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequences</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finds</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>era</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connections</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chilling</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>montgomery</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptation</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teenage</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appealing</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displays</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traditional</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>took</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depth</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monster</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intensity</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horrors</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>based</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smile</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saying</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quirky</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poetic</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cute</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superb</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worthy</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moment</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hill</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writer</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Occurence good review\n",
       "film                           209\n",
       "movie                          106\n",
       "one                            101\n",
       "like                            79\n",
       "story                           77\n",
       "full                            63\n",
       "best                            56\n",
       "films                           55\n",
       "good                            55\n",
       "fun                             49\n",
       "even                            48\n",
       "review                          48\n",
       "time                            47\n",
       "spanish                         45\n",
       "much                            42\n",
       "way                             42\n",
       "make                            41\n",
       "still                           40\n",
       "too                             39\n",
       "never                           38\n",
       "new                             38\n",
       "great                           38\n",
       "love                            37\n",
       "well                            37\n",
       "comedy                          37\n",
       "life                            36\n",
       "us                              35\n",
       "drama                           34\n",
       "may                             34\n",
       "enough                          33\n",
       "...                            ...\n",
       "feelgood                         4\n",
       "sequences                        4\n",
       "finds                            4\n",
       "era                              4\n",
       "connections                      4\n",
       "chilling                         4\n",
       "montgomery                       4\n",
       "adaptation                       4\n",
       "teenage                          4\n",
       "appealing                        4\n",
       "displays                         4\n",
       "traditional                      4\n",
       "took                             4\n",
       "depth                            4\n",
       "monster                          4\n",
       "queen                            4\n",
       "intensity                        4\n",
       "horrors                          4\n",
       "based                            4\n",
       "smile                            4\n",
       "saying                           4\n",
       "quirky                           4\n",
       "poetic                           4\n",
       "cute                             4\n",
       "superb                           4\n",
       "raw                              4\n",
       "worthy                           4\n",
       "moment                           4\n",
       "hill                             4\n",
       "writer                           4\n",
       "\n",
       "[767 rows x 1 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get most common words in positive reviews \n",
    "top_common_words_fresh = common_words_fresh_df[common_words_fresh_df['Occurence good review'] >=4]\n",
    "top_common_words_fresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b> Reason for not using Lemmatization </b>\n",
    "\n",
    "<p>\n",
    "    Before counting the occurance of words in the movie review, we noticed that inflections in words may result in different occurances and thus generating bias during counting. For example, \"enjoy\" and \"enjoyed\" share the same root but would be counted separately if not using Lemmatization.\n",
    "    </p> \n",
    "    \n",
    "<p>\n",
    "    The function \"stem_recount\" takes the root of a word and recounts the occurences. However, it posed a disadvantage of mis-normalizing words into other completely different words. For example, \"movie\" was identified as \"movy\", and \"like\" was identified as \"lik\". We thought this disadvantage exceeds the benefits of correcting word inflection, so we decided to not implement it.\n",
    "    </p> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            tired crude celebutante parody isnt funny\n",
       "1     theres barely an incident from the right hono...\n",
       "2    though probably wellintentioned radio comes of...\n",
       "3     a sad badly made badly written little flick f...\n",
       "4    much of what transpires in claudio giovannesis...\n",
       "dtype: object"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from rotten & turn into Series\n",
    "split_rotten= pd.Series(remove_punctuation(development_split_rotten))\n",
    "split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords from negative reviews\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_rotten.replace(replacements, regex=True, inplace=True)\n",
    "split_rotten.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get most common words in negative reviews \n",
    "\n",
    "common_words_rotten = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "common_words_rotten_df = pd.DataFrame(common_words_rotten)\n",
    "common_words_rotten_df = common_words_rotten_df.rename({0:'Occurence bad review'}, axis='columns')\n",
    "top_common_words_rotten = common_words_rotten_df[common_words_rotten_df['Occurence bad review'] >=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Occurence bad review\n",
       "film                    115\n",
       "movie                    94\n",
       "like                     58\n",
       "one                      55\n",
       "too                      46"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_common_words_rotten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of good and bad reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "We want to find out which of the words in the good list only appear in the good movies (and not in the bad movies), vice versa and base labeling functions on these findings. We first ened to prepare the data accordingly, before we can write the labelling functions.\n",
    "    <div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fresh_words_exclusive = top_common_words_fresh.merge(top_common_words_rotten, indicator='i', how='outer', left_index=True,\\\n",
    "                                                         right_index=True).query('i == \"left_only\"').drop('i', 1)\n",
    "\n",
    "top_rotten_words_exclusive = top_common_words_rotten.merge(top_common_words_fresh, indicator='i', how='outer', left_index=True,\\\n",
    "                                                           right_index=True).query('i == \"left_only\"').drop('i', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>achievement</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Occurence good review  Occurence bad review\n",
       "2                              4.0                   NaN\n",
       "2019                           5.0                   NaN\n",
       "3                              5.0                   NaN\n",
       "ability                        6.0                   NaN\n",
       "achievement                    5.0                   NaN"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_fresh_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>act</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annie</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempt</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awful</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Occurence bad review  Occurence good review\n",
       "act                       6.0                    NaN\n",
       "annie                     4.0                    NaN\n",
       "answer                    4.0                    NaN\n",
       "attempt                   5.0                    NaN\n",
       "awful                     5.0                    NaN"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rotten_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '2019',\n",
       " '3',\n",
       " 'ability',\n",
       " 'achievement',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'adaptation',\n",
       " 'adults',\n",
       " 'adventure',\n",
       " 'alive',\n",
       " 'alone',\n",
       " 'although',\n",
       " 'amazing',\n",
       " 'america',\n",
       " 'among',\n",
       " 'amp',\n",
       " 'angry',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'apart',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'approach',\n",
       " 'art',\n",
       " 'assured',\n",
       " 'atmosphere',\n",
       " 'attempts',\n",
       " 'attention',\n",
       " 'awkward',\n",
       " 'based',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'begins',\n",
       " 'beyond',\n",
       " 'bill',\n",
       " 'biopic',\n",
       " 'blockbuster',\n",
       " 'body',\n",
       " 'bold',\n",
       " 'bond',\n",
       " 'brilliantly',\n",
       " 'brothers',\n",
       " 'call',\n",
       " 'camera',\n",
       " 'capable',\n",
       " 'captivating',\n",
       " 'captures',\n",
       " 'career',\n",
       " 'celebration',\n",
       " 'center',\n",
       " 'certainly',\n",
       " 'challenging',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'chemistry',\n",
       " 'childhood',\n",
       " 'chilling',\n",
       " 'chinese',\n",
       " 'cinema',\n",
       " 'city',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'clearly',\n",
       " 'clift',\n",
       " 'climax',\n",
       " 'colorful',\n",
       " 'commentary',\n",
       " 'common',\n",
       " 'compassion',\n",
       " 'compelling',\n",
       " 'completely',\n",
       " 'concept',\n",
       " 'connections',\n",
       " 'consistently',\n",
       " 'contemporary',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'crafted',\n",
       " 'create',\n",
       " 'creates',\n",
       " 'creating',\n",
       " 'creative',\n",
       " 'credit',\n",
       " 'cry',\n",
       " 'cultural',\n",
       " 'culture',\n",
       " 'cute',\n",
       " 'dancer',\n",
       " 'date',\n",
       " 'de',\n",
       " 'debut',\n",
       " 'definitely',\n",
       " 'delightful',\n",
       " 'demonstrates',\n",
       " 'depp',\n",
       " 'depth',\n",
       " 'deserves',\n",
       " 'directors',\n",
       " 'displays',\n",
       " 'documentary',\n",
       " 'doubt',\n",
       " 'dream',\n",
       " 'due',\n",
       " 'dumb',\n",
       " 'earnest',\n",
       " 'ease',\n",
       " 'easily',\n",
       " 'edge',\n",
       " 'effective',\n",
       " 'else',\n",
       " 'emotionally',\n",
       " 'endearing',\n",
       " 'engaging',\n",
       " 'english',\n",
       " 'enjoyable',\n",
       " 'ensemble',\n",
       " 'entertained',\n",
       " 'entertainment',\n",
       " 'epic',\n",
       " 'era',\n",
       " 'especially',\n",
       " 'event',\n",
       " 'exactly',\n",
       " 'exciting',\n",
       " 'expected',\n",
       " 'experience',\n",
       " 'expertly',\n",
       " 'exploitation',\n",
       " 'explores',\n",
       " 'extraordinary',\n",
       " 'extremely',\n",
       " 'face',\n",
       " 'faces',\n",
       " 'faith',\n",
       " 'feelgood',\n",
       " 'feeling',\n",
       " 'felt',\n",
       " 'female',\n",
       " 'fiction',\n",
       " 'fight',\n",
       " 'finding',\n",
       " 'finds',\n",
       " 'fine',\n",
       " 'fitting',\n",
       " 'focuses',\n",
       " 'follows',\n",
       " 'footage',\n",
       " 'forget',\n",
       " 'friends',\n",
       " 'funniest',\n",
       " 'game',\n",
       " 'gender',\n",
       " 'genius',\n",
       " 'gentle',\n",
       " 'girl',\n",
       " 'girls',\n",
       " 'grace',\n",
       " 'greatest',\n",
       " 'gripping',\n",
       " 'gritty',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'happen',\n",
       " 'happy',\n",
       " 'haunting',\n",
       " 'heartfelt',\n",
       " 'helps',\n",
       " 'hero',\n",
       " 'highly',\n",
       " 'hilarious',\n",
       " 'hill',\n",
       " 'history',\n",
       " 'holds',\n",
       " 'honest',\n",
       " 'horrors',\n",
       " 'hotel',\n",
       " 'hours',\n",
       " 'however',\n",
       " 'humanity',\n",
       " 'identity',\n",
       " 'imagine',\n",
       " 'impact',\n",
       " 'important',\n",
       " 'impossible',\n",
       " 'including',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'industry',\n",
       " 'inside',\n",
       " 'inspirational',\n",
       " 'intelligent',\n",
       " 'intensity',\n",
       " 'interest',\n",
       " 'intimate',\n",
       " 'issues',\n",
       " 'james',\n",
       " 'job',\n",
       " 'joe',\n",
       " 'journey',\n",
       " 'key',\n",
       " 'kicks',\n",
       " 'kill',\n",
       " 'kings',\n",
       " 'knows',\n",
       " 'land',\n",
       " 'landscape',\n",
       " 'language',\n",
       " 'late',\n",
       " 'laugh',\n",
       " 'laughing',\n",
       " 'laughs',\n",
       " 'lead',\n",
       " 'leading',\n",
       " 'leave',\n",
       " 'leaves',\n",
       " 'lies',\n",
       " 'lives',\n",
       " 'living',\n",
       " 'loud',\n",
       " 'loved',\n",
       " 'lucky',\n",
       " 'major',\n",
       " 'manages',\n",
       " 'mark',\n",
       " 'marvel',\n",
       " 'masterpiece',\n",
       " 'matter',\n",
       " 'mature',\n",
       " 'memorable',\n",
       " 'men',\n",
       " 'mind',\n",
       " 'minds',\n",
       " 'mix',\n",
       " 'monster',\n",
       " 'montgomery',\n",
       " 'moral',\n",
       " 'mother',\n",
       " 'music',\n",
       " 'musical',\n",
       " 'must',\n",
       " 'name',\n",
       " 'nature',\n",
       " 'nonetheless',\n",
       " 'nostalgia',\n",
       " 'offers',\n",
       " 'oldfashioned',\n",
       " 'ones',\n",
       " 'order',\n",
       " 'ordinary',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'parents',\n",
       " 'party',\n",
       " 'past',\n",
       " 'perceptive',\n",
       " 'perfectly',\n",
       " 'personal',\n",
       " 'perspective',\n",
       " 'pixar',\n",
       " 'places',\n",
       " 'players',\n",
       " 'pleasant',\n",
       " 'poetic',\n",
       " 'political',\n",
       " 'portrait',\n",
       " 'powerful',\n",
       " 'procedural',\n",
       " 'provides',\n",
       " 'pure',\n",
       " 'puts',\n",
       " 'queen',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quietly',\n",
       " 'quirky',\n",
       " 'racism',\n",
       " 'rango',\n",
       " 'rare',\n",
       " 'raw',\n",
       " 'ready',\n",
       " 'reality',\n",
       " 'reasons',\n",
       " 'recent',\n",
       " 'recommend',\n",
       " 'redgrave',\n",
       " 'refreshingly',\n",
       " 'relationships',\n",
       " 'remains',\n",
       " 'remarkable',\n",
       " 'reminder',\n",
       " 'return',\n",
       " 'rich',\n",
       " 'ride',\n",
       " 'rock',\n",
       " 'role',\n",
       " 'roles',\n",
       " 'romcom',\n",
       " 'running',\n",
       " 'satire',\n",
       " 'satisfying',\n",
       " 'saying',\n",
       " 'scares',\n",
       " 'scene',\n",
       " 'school',\n",
       " 'science',\n",
       " 'sciencefiction',\n",
       " 'scifi',\n",
       " 'score',\n",
       " 'season',\n",
       " 'sentimental',\n",
       " 'sequences',\n",
       " 'serious',\n",
       " 'shame',\n",
       " 'sharp',\n",
       " 'shot',\n",
       " 'simple',\n",
       " 'since',\n",
       " 'sincere',\n",
       " 'skin',\n",
       " 'slow',\n",
       " 'sly',\n",
       " 'smart',\n",
       " 'smarter',\n",
       " 'smile',\n",
       " 'someone',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soul',\n",
       " 'sounds',\n",
       " 'source',\n",
       " 'space',\n",
       " 'spin',\n",
       " 'spirit',\n",
       " 'sports',\n",
       " 'spot',\n",
       " 'stars',\n",
       " 'start',\n",
       " 'storytelling',\n",
       " 'strange',\n",
       " 'strength',\n",
       " 'striking',\n",
       " 'structure',\n",
       " 'study',\n",
       " 'subject',\n",
       " 'suffering',\n",
       " 'suffers',\n",
       " 'summer',\n",
       " 'superb',\n",
       " 'superhero',\n",
       " 'surprised',\n",
       " 'surprising',\n",
       " 'surprisingly',\n",
       " 'suspense',\n",
       " 'sweet',\n",
       " 'taken',\n",
       " 'taking',\n",
       " 'talk',\n",
       " 'team',\n",
       " 'teenage',\n",
       " 'teens',\n",
       " 'telling',\n",
       " 'terms',\n",
       " 'terrific',\n",
       " 'thanks',\n",
       " 'themes',\n",
       " 'thoughtful',\n",
       " 'thoughtprovoking',\n",
       " 'thrilling',\n",
       " 'thrills',\n",
       " 'throughout',\n",
       " 'timely',\n",
       " 'told',\n",
       " 'took',\n",
       " 'top',\n",
       " 'totally',\n",
       " 'touching',\n",
       " 'traditional',\n",
       " 'travel',\n",
       " 'treat',\n",
       " 'triumph',\n",
       " 'true',\n",
       " 'twists',\n",
       " 'type',\n",
       " 'understanding',\n",
       " 'unflinching',\n",
       " 'unique',\n",
       " 'uses',\n",
       " 'viewing',\n",
       " 'walk',\n",
       " 'warm',\n",
       " 'welcome',\n",
       " 'went',\n",
       " 'western',\n",
       " 'weve',\n",
       " 'whimsical',\n",
       " 'whos',\n",
       " 'wild',\n",
       " 'wilson',\n",
       " 'wonderful',\n",
       " 'wonderfully',\n",
       " 'worlds',\n",
       " 'worthy',\n",
       " 'writer',\n",
       " 'writerdirector',\n",
       " 'yes',\n",
       " 'younger']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only positive words \n",
    "top_fresh_words_exclusive_list = top_fresh_words_exclusive['Occurence good review'].index.tolist()\n",
    "top_fresh_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_fresh_words_exclusive = ['absolutely',\n",
    " 'addition',\n",
    " 'adventure',\n",
    " 'affectionate',\n",
    " 'amazing',\n",
    " 'ambition',\n",
    " 'art',\n",
    " 'artist',\n",
    " 'arts',\n",
    " 'atmosphere',\n",
    " 'attractive',\n",
    " 'awards',\n",
    " 'balance',\n",
    " 'beautiful',\n",
    " 'beautifully',\n",
    " 'beauty',\n",
    " 'bond',\n",
    " 'bright',\n",
    " 'brilliant',\n",
    " 'captivating',\n",
    " 'captures',\n",
    " 'celebration',\n",
    " 'charm',\n",
    " 'charming',\n",
    " 'christmas',\n",
    " 'classic',\n",
    " 'clever',\n",
    " 'committed',\n",
    " 'consistently',\n",
    " 'contemporary',\n",
    " 'conventional',\n",
    " 'convincingly',\n",
    " 'creates',\n",
    " 'creating',\n",
    " 'crowdpleaser',\n",
    " 'cult',\n",
    " 'decade',\n",
    " 'decades',\n",
    " 'deep',\n",
    " 'deeper',\n",
    " 'deeply',\n",
    " 'definitely',\n",
    " 'delightful',\n",
    " 'delightfully',\n",
    " 'depth',\n",
    " 'deserves',\n",
    " 'design',\n",
    " 'details',\n",
    " 'different',\n",
    " 'diverse',\n",
    " 'dramatic',\n",
    " 'early',\n",
    " 'elegant',\n",
    " 'emotionally',\n",
    " 'engaging',\n",
    " 'enjoyable',\n",
    " 'enjoyed',\n",
    " 'equal',\n",
    " 'especially',\n",
    " 'exploration',\n",
    " 'extraordinary',\n",
    " 'extremely',\n",
    " 'familiar',\n",
    " 'famous',\n",
    " 'fan',\n",
    " 'fantastic',\n",
    " 'fantasy',\n",
    " 'fascinating',\n",
    " 'felt',\n",
    " 'filled',\n",
    " 'finest',\n",
    " 'frank',\n",
    " 'fresh',\n",
    " 'friends',\n",
    " 'friendship',\n",
    " 'gags',\n",
    " 'gorgeous',\n",
    " 'grand',\n",
    " 'happy',\n",
    " 'heart',\n",
    " 'hilarious',\n",
    " 'honest',\n",
    " 'hope',\n",
    " 'huge',\n",
    " 'impact',\n",
    " 'insightful',\n",
    " 'inspiring',\n",
    " 'intelligent',\n",
    " 'intense',\n",
    " 'intrigue',\n",
    " 'joy',\n",
    " 'laugh',\n",
    " 'loved',\n",
    " 'mature',\n",
    " 'mind',\n",
    " 'mystery',\n",
    " 'nostalgia',\n",
    " 'novel',\n",
    " 'opening',\n",
    " 'passion',\n",
    " 'perfect',\n",
    " 'performers',\n",
    " 'personal',\n",
    " 'pleasure',\n",
    " 'poignant',\n",
    " 'power',\n",
    " 'powerful',\n",
    " 'precisely',\n",
    " 'profound',\n",
    " 'project',\n",
    " 'proves',\n",
    " 'provide',\n",
    " 'provocative',\n",
    " 'psychological',\n",
    " 'quality',\n",
    " 'remarkable',\n",
    " 'reveals',\n",
    " 'rich',\n",
    " 'riveting',\n",
    " 'satisfying',\n",
    " 'sharp',\n",
    " 'simple',\n",
    " 'smart',\n",
    " 'smile',\n",
    " 'stunning',\n",
    " 'succeeds',\n",
    " 'supernatural',\n",
    " 'surprise',\n",
    " 'surprises',\n",
    " 'surprising',\n",
    " 'surprisingly',\n",
    " 'sweet',\n",
    " 'talents',\n",
    " 'thoughtful',\n",
    " 'thrills',\n",
    " 'touch',\n",
    " 'touching',\n",
    " 'tragedy',\n",
    " 'tragic',\n",
    " 'tribute',\n",
    " 'unique',\n",
    " 'universal',\n",
    " 'warm',\n",
    " 'watchable',\n",
    " 'welcome',\n",
    " 'wit',\n",
    " 'witty',\n",
    " 'wonderful',\n",
    " 'worthwhile',\n",
    " 'worthy']\n",
    "\n",
    "# top_fresh_words_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['act',\n",
       " 'annie',\n",
       " 'answer',\n",
       " 'attempt',\n",
       " 'awful',\n",
       " 'badly',\n",
       " 'barely',\n",
       " 'beginning',\n",
       " 'believe',\n",
       " 'beneath',\n",
       " 'biggest',\n",
       " 'blank',\n",
       " 'book',\n",
       " 'bore',\n",
       " 'boy',\n",
       " 'brain',\n",
       " 'bring',\n",
       " 'bunch',\n",
       " 'camp',\n",
       " 'central',\n",
       " 'cheap',\n",
       " 'cheesy',\n",
       " 'clichés',\n",
       " 'cold',\n",
       " 'coming',\n",
       " 'compared',\n",
       " 'complete',\n",
       " 'contrived',\n",
       " 'couldnt',\n",
       " 'created',\n",
       " 'details',\n",
       " 'disappointing',\n",
       " 'disappointment',\n",
       " 'doom',\n",
       " 'dull',\n",
       " 'early',\n",
       " 'effects',\n",
       " 'effort',\n",
       " 'either',\n",
       " 'ends',\n",
       " 'entire',\n",
       " 'episode',\n",
       " 'events',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'fairly',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'flat',\n",
       " 'franchise',\n",
       " 'front',\n",
       " 'fully',\n",
       " 'gags',\n",
       " 'generic',\n",
       " 'getting',\n",
       " 'grey',\n",
       " 'guys',\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'hes',\n",
       " 'hokum',\n",
       " 'hollow',\n",
       " 'hoped',\n",
       " 'id',\n",
       " 'indeed',\n",
       " 'intended',\n",
       " 'involved',\n",
       " 'involving',\n",
       " 'jump',\n",
       " 'lack',\n",
       " 'length',\n",
       " 'line',\n",
       " 'live',\n",
       " 'looking',\n",
       " 'loses',\n",
       " 'melodrama',\n",
       " 'mess',\n",
       " 'messy',\n",
       " 'michael',\n",
       " 'money',\n",
       " 'muddle',\n",
       " 'needs',\n",
       " 'noah',\n",
       " 'none',\n",
       " 'novel',\n",
       " 'obvious',\n",
       " 'obviously',\n",
       " 'opera',\n",
       " 'overall',\n",
       " 'painful',\n",
       " 'parts',\n",
       " 'paul',\n",
       " 'points',\n",
       " 'possible',\n",
       " 'problem',\n",
       " 'production',\n",
       " 'punch',\n",
       " 'race',\n",
       " 'result',\n",
       " 'resulting',\n",
       " 'revenge',\n",
       " 'routine',\n",
       " 'run',\n",
       " 'ryan',\n",
       " 'sad',\n",
       " 'sadly',\n",
       " 'save',\n",
       " 'scary',\n",
       " 'seeing',\n",
       " 'selfindulgent',\n",
       " 'sequel',\n",
       " 'set',\n",
       " 'shallow',\n",
       " 'short',\n",
       " 'sit',\n",
       " 'slog',\n",
       " 'soap',\n",
       " 'sort',\n",
       " 'soundtrack',\n",
       " 'spend',\n",
       " 'starts',\n",
       " 'stick',\n",
       " 'subjects',\n",
       " 'supporting',\n",
       " 'supposed',\n",
       " 'surface',\n",
       " 'talent',\n",
       " 'terrible',\n",
       " 'theme',\n",
       " 'theyre',\n",
       " 'third',\n",
       " 'thought',\n",
       " 'tom',\n",
       " 'trying',\n",
       " 'tv',\n",
       " 'uneven',\n",
       " 'unfortunately',\n",
       " 'using',\n",
       " 'value',\n",
       " 'violent',\n",
       " 'visually',\n",
       " 'wanted',\n",
       " 'wants',\n",
       " 'waste',\n",
       " 'whatever',\n",
       " 'worse',\n",
       " 'worst',\n",
       " 'written',\n",
       " 'wrong',\n",
       " 'youd']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only negative words \n",
    "top_rotten_words_exclusive_list = top_rotten_words_exclusive['Occurence bad review'].index.tolist()\n",
    "top_rotten_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_rotten_words_exclusive = [\n",
    " 'attempt',\n",
    " 'awkward',\n",
    " 'barely',\n",
    " 'basically',\n",
    " 'bizarre',\n",
    " 'bland',\n",
    " 'boring',\n",
    " 'clumsy',\n",
    " 'comedic',\n",
    " 'disappointing',\n",
    " 'disappointingly',\n",
    " 'disappointment',\n",
    " 'disaster',\n",
    " 'dull',\n",
    " 'effort',\n",
    " 'failed',\n",
    " 'fails',\n",
    " 'generic',\n",
    " 'irritating',\n",
    " 'lacking',\n",
    " 'manic',\n",
    " 'missing',\n",
    " 'nobody',\n",
    " 'noir',\n",
    " 'none',\n",
    " 'painfully',\n",
    " 'pointless',\n",
    " 'poorly',\n",
    " 'problem',\n",
    " 'shallow',\n",
    " 'shame',\n",
    " 'sloppy',\n",
    " 'slow',\n",
    " 'suffers',\n",
    " 'superficial',\n",
    " 'try',\n",
    " 'unfortunately',\n",
    " 'unfunny',\n",
    " 'worst']\n",
    "# top_rotten_words_exclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Word Occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A. Good / bad exclusive words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.apply.spark import SparkLFApplier\n",
    "\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SQLContext \n",
    "import pandas as pd \n",
    "sqlc=SQLContext(sc) \n",
    "df=pd.read_csv('/project/development_split.csv',index_col = 'Unnamed: 0')\n",
    "df_with_punctuation = df.copy()\n",
    "df['Review'] = remove_punctuation(df)\n",
    "development_split=sqlc.createDataFrame(df)\n",
    "development_split_with_punctuation=sqlc.createDataFrame(df_with_punctuation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|              Review|Freshness|\n",
      "+--------------------+---------+\n",
      "|vantage point is ...|        0|\n",
      "|the movie makes i...|        0|\n",
      "|claire denis show...|        0|\n",
      "| the plotting is ...|        1|\n",
      "|the movies two ha...|        0|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "development_split.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "NOTFRESH = 0\n",
    "FRESH = 1\n",
    "\n",
    "@labeling_function()\n",
    "def fresh(x):\n",
    "    for word in top_fresh_words_exclusive:\n",
    "        word = \" \" +word+\" \"\n",
    "        if word in str(x).lower():\n",
    "            return FRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def rotten(x):\n",
    "    for word in top_rotten_words_exclusive:\n",
    "        word = \" \" +word+\" \"\n",
    "        if word in str(x).lower():\n",
    "            return NOTFRESH\n",
    "    return ABSTAIN\n",
    "#return NOTFRESH if \"best\" in x.str.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [fresh]\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       ...,\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresh coverage:33.7%\n"
     ]
    }
   ],
   "source": [
    "coverage_fresh = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"fresh coverage:{:.1%}\".format(coverage_fresh[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [rotten]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten coverage:7.6%\n"
     ]
    }
   ],
   "source": [
    "coverage_rotten = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"rotten coverage:{:.1%}\".format(coverage_rotten[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Word 'too' occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "too                     39"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "too                    46"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def keyword_too(x):\n",
    "    return NOTFRESH if 'too' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [keyword_too]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword too coverage:4.2%\n"
     ]
    }
   ],
   "source": [
    "coverage_keyword_too = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword too coverage:{:.1%}\".format(coverage_keyword_too[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Word 'far' occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "far                     10"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "far                     9"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def keyword_far(x):\n",
    "    return FRESH if 'far' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [keyword_far]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword far coverage:2.7%\n"
     ]
    }
   ],
   "source": [
    "coverage_keyword_far = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword far coverage:{:.1%}\".format(coverage_keyword_far[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. \"n't\" words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration on the n't\n",
    "# Word occurancy that with punctuation with it\n",
    "\n",
    "# Word occurrences dataframe for fresh reviews\n",
    "development_split_fresh_1 = split_fresh.str.split(expand=True).stack().value_counts()\n",
    "development_split_fresh_df = pd.DataFrame(development_split_fresh_1).reset_index()\n",
    "\n",
    "# Words occurrences dataframe for rotten reviews\n",
    "development_split_rotten_1 = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "development_split_rotten_df = pd.DataFrame(development_split_rotten_1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "\n",
    "def t(x):\n",
    "    if re.search(\"'t\",str(x).lower()):\n",
    "        return NOTFRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [t]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword far coverage:16.1%\n"
     ]
    }
   ],
   "source": [
    "coverage_t = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword far coverage:{:.1%}\".format(coverage_t[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Occurenes of good & bad words from external list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "We also want to look at an imported list of postive and negative words and see whether we can base the labelling functions on them.\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing good and bad words & preparing for labelling function \n",
    "\n",
    "#POSITIVE WORDS \n",
    "#positive words from --> DON't DELETE! NEED TO CITE PROPERLY http://ptrckprry.com/course/ssd/data/positive-words.txt\n",
    "positive_word = pd.read_csv('/project/positive_words.csv')\n",
    "\n",
    "#sample 500 words \n",
    "positive_word = positive_word.sample(500)\n",
    "\n",
    "#convert it into a list \n",
    "positive_word= positive_word['a+'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "#NEGATIVE WORDS \n",
    "negative_word = pd.read_csv('/project/negative_words.csv')\n",
    "\n",
    "#sample 500 words \n",
    "negative_word = negative_word.sample(500)\n",
    "\n",
    "#convert it into a list \n",
    "negative_word= negative_word['2-faces'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def negative(x): \n",
    "    for word in negative_word:\n",
    "        word = \" \" + word + \" \"\n",
    "        if word in str(x).lower():\n",
    "            return NOTFRESH \n",
    "    return ABSTAIN \n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def positive(x):\n",
    "    for word in positive_word:\n",
    "        word = \" \" + word + \" \"\n",
    "        if word in str(x).lower():\n",
    "            return FRESH \n",
    "    return ABSTAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [negative]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative words coverage:9.1%\n"
     ]
    }
   ],
   "source": [
    "coverage_negative = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"negative words coverage:{:.1%}\".format(coverage_negative[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [positive]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive words coverage:30.9%\n"
     ]
    }
   ],
   "source": [
    "coverage_positive = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"positive words coverage:{:.1%}\".format(coverage_positive[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Punctuation occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing for punctuation occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn review column into Series\n",
    "development_split_fresh_series = pd.Series(development_split_fresh.Review)\n",
    "development_split_rotten_series = pd.Series(development_split_rotten.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive reviews\n",
    "# Split reviews into word\n",
    "fresh_split = pd.Series(development_split_fresh_series.str.split(expand=True).stack())\n",
    "fresh_words = [i for i in fresh_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in fresh_words]\n",
    "fresh_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative reviews\n",
    "# Split reviews into word\n",
    "rotten_split = pd.Series(development_split_rotten_series.str.split(expand=True).stack())\n",
    "rotten_words = [i for i in rotten_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in rotten_words]\n",
    "rotten_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into a flattened list\n",
    "fresh_flattened_list = [y for x in fresh_split_words for y in x]\n",
    "rotten_flattened_list = [y for x in rotten_split_words for y in x]\n",
    "\n",
    "# Count the occurancy of each character\n",
    "# Positive reviews\n",
    "fresh_split_characters = pd.Series(fresh_flattened_list).value_counts()\n",
    "fresh_split_characters = pd.DataFrame(fresh_split_characters).reset_index()\n",
    "\n",
    "# Negative reviews\n",
    "rotten_split_characters = pd.Series(rotten_flattened_list).value_counts()\n",
    "rotten_split_characters = pd.DataFrame(rotten_split_characters).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Question mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>?</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "63     ?  21"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>?</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "54     ?  26"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"It's like a particularly camp episode of Who Do You Think You Are? complete with dramatic reconstructions.\", ' How do I count the ways this movie goes wrong?', 'If you\\'ve seen the original \"Jacob\\'s Ladder,\" you already know what\\'s going to happen. If you\\'ve never seen \"Jacob\\'s Ladder,\" why on earth would you start with this version?']\n"
     ]
    }
   ],
   "source": [
    "list_with_question_mark = []\n",
    "for review in development_split_rotten.Review:\n",
    "    if '?' in review:\n",
    "        list_with_question_mark.append(review)\n",
    "        \n",
    "print (list_with_question_mark[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def question_mark(x):\n",
    "    return NOTFRESH if '?' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lfs = [question_mark]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split_with_punctuation.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question mark coverage:2.1%\n"
     ]
    }
   ],
   "source": [
    "coverage_question_mark = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"question mark coverage:{:.1%}\".format(coverage_question_mark[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Exclamation mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>!</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  0\n",
       "71     !  8"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>!</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  0\n",
       "69     !  6"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def exclamation_mark(x):\n",
    "    return FRESH if '!' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lfs = [exclamation_mark]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split_with_punctuation.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclamation mark coverage:0.7%\n"
     ]
    }
   ],
   "source": [
    "coverage_exclamation_mark = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"exclamation mark coverage:{:.1%}\".format(coverage_exclamation_mark[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(text):\n",
    "    x = {}\n",
    "    x[\"polarity\"] = TextBlob(text).sentiment.polarity\n",
    "    x[\"subjectivity\"] = TextBlob(text).sentiment.subjectivity\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def textblob_polarity(x):\n",
    "    x = getSentiment(x.Review)\n",
    "    return FRESH if x[\"polarity\"] > 0.8 else ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def textblob_subjectivity(x):\n",
    "    x = getSentiment(x.Review)\n",
    "    return FRESH if x[\"subjectivity\"] >= 0.5 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [\n",
    "       textblob_polarity,\n",
    "       textblob_subjectivity\n",
    "      ]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "\n",
    "sample_L = applier.apply(development_split.rdd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>textblob_polarity</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       j Polarity  Coverage  Overlaps  Conflicts\n",
       "textblob_polarity      0      [1]    0.0120    0.0075        0.0\n",
       "textblob_subjectivity  1      [1]    0.5635    0.0075        0.0"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(sample_L, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Combining labelling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Next, we want to combine all the labelling functions into one and apply them to the training set. However, as the labelling functions around the punctuation have very low coverages, we decided not to include these.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [fresh,\n",
    "       rotten,\n",
    "       keyword_too,\n",
    "       keyword_far,\n",
    "       t,\n",
    "       negative,\n",
    "       positive,\n",
    "       textblob_polarity,\n",
    "       textblob_subjectivity\n",
    "      ]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "\n",
    "sample_L = applier.apply(development_split.rdd)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotten</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_too</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_far</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.0735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.3085</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_polarity</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.1855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       j Polarity  Coverage  Overlaps  Conflicts\n",
       "fresh                  0      [1]    0.3365    0.2800     0.1045\n",
       "rotten                 1      [0]    0.0765    0.0610     0.0585\n",
       "keyword_too            2      [0]    0.0425    0.0370     0.0325\n",
       "keyword_far            3      [1]    0.0270    0.0245     0.0070\n",
       "t                      4      [0]    0.1605    0.1275     0.1230\n",
       "negative               5      [0]    0.0910    0.0785     0.0735\n",
       "positive               6      [1]    0.3085    0.2575     0.0950\n",
       "textblob_polarity      7      [1]    0.0120    0.0085     0.0025\n",
       "textblob_subjectivity  8      [1]    0.5635    0.4100     0.1855"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(sample_L, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "As seen above, with our labelling functions we obtain high conflicts for the \"t\" labelling function, as well as for the \"textblob_subjectivity\" therefore we decided to remove these two lfs from our model. \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New lfs without t & textblob subjectivity \n",
    "lfs = [fresh,\n",
    "       rotten,\n",
    "       keyword_too,\n",
    "       keyword_far,\n",
    "       negative,\n",
    "       positive,\n",
    "       textblob_polarity\n",
    "      ]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "\n",
    "sample_L = applier.apply(development_split.rdd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotten</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_too</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_far</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.0475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.3085</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_polarity</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "fresh              0      [1]    0.3365    0.1840     0.0630\n",
       "rotten             1      [0]    0.0765    0.0385     0.0340\n",
       "keyword_too        2      [0]    0.0425    0.0295     0.0240\n",
       "keyword_far        3      [1]    0.0270    0.0155     0.0045\n",
       "negative           4      [0]    0.0910    0.0535     0.0475\n",
       "positive           5      [1]    0.3085    0.1690     0.0500\n",
       "textblob_polarity  6      [1]    0.0120    0.0050     0.0010"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(sample_L, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuation from training set \n",
    "train_prepared = train.copy()\n",
    "train_prepared['Review'] = remove_punctuation(train_prepared)\n",
    "\n",
    "#Removing punctuation from test set \n",
    "test_prepared = test.copy()\n",
    "test_prepared['Review'] = remove_punctuation(test_prepared)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting in training and testing & applying lfs\n",
    "\n",
    "L_train=sqlc.createDataFrame(train_prepared)\n",
    "\n",
    "L_test = sqlc.createDataFrame(test_prepared)\n",
    "\n",
    "\n",
    "L_train = applier.apply(L_train.rdd)\n",
    "\n",
    "L_test = applier.apply(L_test.rdd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MajorityLabelVoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3'"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#needs to show version 2.3\n",
    "import networkx as nx\n",
    "nx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LabelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelling according to weights \n",
    "from snorkel.labeling import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = test['Freshness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   60.9%\n",
      "Label Model Accuracy:     60.2%\n"
     ]
    }
   ],
   "source": [
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "\n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say something about the drop in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n",
      "<pyspark.sql.session.SparkSession object at 0x7f0dd9209d30>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "# Spark Environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import pyspark\n",
    "\n",
    "number_cores = 4\n",
    "memory_gb = 16\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "print(sc)\n",
    "\n",
    "# get the context\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "print(spark) \n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/faculty/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/faculty/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langid in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (1.1.6)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from langid) (1.18.1)\r\n"
     ]
    }
   ],
   "source": [
    "# Download files\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "!pip install langid\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import preproc as pp\n",
    "\n",
    "# Register all the functions in Preproc with Spark Context\n",
    "check_lang_udf = udf(pp.check_lang, StringType())\n",
    "remove_stops_udf = udf(pp.remove_stops, StringType())\n",
    "remove_features_udf = udf(pp.remove_features, StringType())\n",
    "tag_and_remove_udf = udf(pp.tag_and_remove, StringType())\n",
    "lemmatize_udf = udf(pp.lemmatize, StringType())\n",
    "check_blanks_udf = udf(pp.check_blanks, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|vantage point is ...|    0|\n",
      "|the movie makes i...|    0|\n",
      "|claire denis show...|    0|\n",
      "| the plotting is ...|    1|\n",
      "|the movies two ha...|    0|\n",
      "|the first feature...|    1|\n",
      "|misses the sense ...|    0|\n",
      "|the movie is a fa...|    1|\n",
      "| in the end prett...|    0|\n",
      "|follows some of t...|    1|\n",
      "|even in its most ...|    1|\n",
      "|when the story sh...|    1|\n",
      "|a thrilling but f...|    1|\n",
      "|it remains watcha...|    1|\n",
      "|softness of bodie...|    0|\n",
      "| cusack who selfd...|    1|\n",
      "| knightleys sugar...|    0|\n",
      "| best of all is p...|    1|\n",
      "|none of the filmm...|    0|\n",
      "|filled with clich...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Read the data (Spark)\n",
    "review_df = development_split\n",
    "\n",
    "# Rename Column\n",
    "review_df = review_df.withColumnRenamed('Review','text')\n",
    "review_df = review_df.withColumnRenamed('Freshness','label')\n",
    "review_df = review_df.withColumnRenamed('_c0','index')\n",
    "\n",
    "# Remove Null\n",
    "review_df = review_df.filter(review_df.label. isNotNull())\n",
    "\n",
    "# Change data type to Integer\n",
    "review_df = review_df.withColumn(\"label\", review_df[\"label\"].cast(IntegerType()))\n",
    "\n",
    "# Show df information\n",
    "review_df.show()\n",
    "review_df.printSchema()\n",
    "review_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|vantage point thr...|    0|\n",
      "|movie make point ...|    0|\n",
      "|claire denis show...|    0|\n",
      "|plot predictable ...|    1|\n",
      "|movie halve larde...|    0|\n",
      "|first feature cre...|    1|\n",
      "|miss sense menace...|    0|\n",
      "|movie convince fa...|    1|\n",
      "|end pink fraudule...|    0|\n",
      "|follow drug thril...|    1|\n",
      "|inspired moment s...|    1|\n",
      "|story shift nashv...|    1|\n",
      "|thrill frivolous ...|    1|\n",
      "|remains watchable...|    1|\n",
      "|softness body wor...|    0|\n",
      "|cusack mock iconi...|    1|\n",
      "|knightleys sugar ...|    0|\n",
      "|best parker perfe...|    1|\n",
      "|none filmmaking a...|    0|\n",
      "|fill cliche runof...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove stop words to reduce dimensionality\n",
    "review_df = review_df.withColumn(\"text\", remove_stops_udf(review_df[\"text\"]))\n",
    "\n",
    "# remove other non essential words\n",
    "review_df = review_df.withColumn(\"text\", remove_features_udf(review_df[\"text\"]))\n",
    "\n",
    "# tag the words remaining and keep only Nouns, Verbs and Adjectives\n",
    "review_df = review_df.withColumn(\"text\", tag_and_remove_udf(review_df[\"text\"]))\n",
    "\n",
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "review_df = review_df.withColumn(\"text\", lemmatize_udf(review_df[\"text\"]))\n",
    "\n",
    "review_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Freshness|\n",
      "+---------+\n",
      "|        0|\n",
      "|        1|\n",
      "+---------+\n",
      "\n",
      "+-----+----------+--------------------+-----+\n",
      "|index|Unnamed: 0|                text|label|\n",
      "+-----+----------+--------------------+-----+\n",
      "|    0|         1|A cornball drone ...|    0|\n",
      "|    1|         3|I don't like impo...|    0|\n",
      "|    2|         4| The Void marks a...|    1|\n",
      "|    3|         5|The only way to l...|    0|\n",
      "|    4|         9| a tame and insul...|    0|\n",
      "|    5|        10|How sorry can you...|    0|\n",
      "|    6|        11|\"Though not parti...|    1|\n",
      "|    7|        16|\"\"\"Blood\"\" [chapt...|    1|\n",
      "|    8|        19|The lack of empat...|    0|\n",
      "|    9|        21|This modern fanta...|    1|\n",
      "|   10|        22|The best film I'v...|    0|\n",
      "|   11|        27| After being surp...|    0|\n",
      "|   12|        34|  An inert thriller.|    0|\n",
      "|   13|        35|What cannot be ar...|    1|\n",
      "|   14|        36|Amid the glut of ...|    1|\n",
      "|   15|        38|It is ultimately ...|    0|\n",
      "|   16|        40|I laughed frequen...|    0|\n",
      "|   17|        42|Fighting with My ...|    1|\n",
      "|   18|        46|Weinstein walks a...|    1|\n",
      "|   19|        47|[A] frenetic jumb...|    0|\n",
      "+-----+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[index: string, Unnamed: 0: string, text: string, label: string]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+-----+\n",
      "|index|Unnamed: 0|                text|label|\n",
      "+-----+----------+--------------------+-----+\n",
      "|    0|         1|A cornball drone ...|    0|\n",
      "|    1|         3|I don't like impo...|    0|\n",
      "|    2|         4| The Void marks a...|    1|\n",
      "|    3|         5|The only way to l...|    0|\n",
      "|    4|         9| a tame and insul...|    0|\n",
      "|    5|        10|How sorry can you...|    0|\n",
      "|    6|        11|\"Though not parti...|    1|\n",
      "|    7|        16|\"\"\"Blood\"\" [chapt...|    1|\n",
      "|    8|        19|The lack of empat...|    0|\n",
      "|    9|        21|This modern fanta...|    1|\n",
      "|   10|        22|The best film I'v...|    0|\n",
      "|   11|        27| After being surp...|    0|\n",
      "|   12|        34|  An inert thriller.|    0|\n",
      "|   13|        35|What cannot be ar...|    1|\n",
      "|   14|        36|Amid the glut of ...|    1|\n",
      "|   15|        38|It is ultimately ...|    0|\n",
      "|   16|        40|I laughed frequen...|    0|\n",
      "|   17|        42|Fighting with My ...|    1|\n",
      "|   18|        46|Weinstein walks a...|    1|\n",
      "|   19|        47|[A] frenetic jumb...|    0|\n",
      "+-----+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- Unnamed: 0: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specify Training and Test data\n",
    "training_df = review_df\n",
    "test_df = sqlContext.read.csv('/project/1000_labels_v2.csv', header=True,sep = '~')\n",
    "test_df.select('Freshness').distinct().show()\n",
    "# Rename Column\n",
    "test_df = test_df.withColumnRenamed('Review','text')\n",
    "test_df = test_df.withColumnRenamed('Freshness','label')\n",
    "test_df = test_df.withColumnRenamed('_c0','index')\n",
    "test_df.show()\n",
    "# Remove Null\n",
    "test_df.filter(test_df.label.isNotNull())\n",
    "# Change data type to Integer\n",
    "test_df = test_df.withColumn(\"label\", test_df[\"label\"].cast(IntegerType()))\n",
    "\n",
    "\n",
    "test_df.show()\n",
    "test_df.printSchema()\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|                text|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|A cornball drone ...|    0|       0.0|\n",
      "|I don't like impo...|    0|       1.0|\n",
      "| The Void marks a...|    1|       0.0|\n",
      "|The only way to l...|    0|       1.0|\n",
      "| a tame and insul...|    0|       1.0|\n",
      "|How sorry can you...|    0|       0.0|\n",
      "|\"Though not parti...|    1|       1.0|\n",
      "|\"\"\"Blood\"\" [chapt...|    1|       1.0|\n",
      "|The lack of empat...|    0|       1.0|\n",
      "|This modern fanta...|    1|       1.0|\n",
      "|The best film I'v...|    0|       1.0|\n",
      "| After being surp...|    0|       1.0|\n",
      "|  An inert thriller.|    0|       0.0|\n",
      "|What cannot be ar...|    1|       1.0|\n",
      "|Amid the glut of ...|    1|       0.0|\n",
      "|It is ultimately ...|    0|       0.0|\n",
      "|I laughed frequen...|    0|       1.0|\n",
      "|Fighting with My ...|    1|       1.0|\n",
      "|Weinstein walks a...|    1|       1.0|\n",
      "|[A] frenetic jumb...|    0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol='words', outputCol=\"features\")\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")\n",
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nb])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)\n",
    "\n",
    "# Error\n",
    "cvModel = cv.fit(training_df)\n",
    "\n",
    "result = cvModel.transform(test_df)\n",
    "prediction_df = result.select(\"text\", \"label\", \"prediction\")\n",
    "prediction_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6236236236236237"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Evaluate the Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(result, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|vantage point thr...|    0|\n",
      "|movie make point ...|    0|\n",
      "|claire denis show...|    0|\n",
      "|plot predictable ...|    1|\n",
      "|movie halve larde...|    0|\n",
      "|first feature cre...|    1|\n",
      "|miss sense menace...|    0|\n",
      "|movie convince fa...|    1|\n",
      "|end pink fraudule...|    0|\n",
      "|follow drug thril...|    1|\n",
      "|inspired moment s...|    1|\n",
      "|story shift nashv...|    1|\n",
      "|thrill frivolous ...|    1|\n",
      "|remains watchable...|    1|\n",
      "|softness body wor...|    0|\n",
      "|cusack mock iconi...|    1|\n",
      "|knightleys sugar ...|    0|\n",
      "|best parker perfe...|    1|\n",
      "|none filmmaking a...|    0|\n",
      "|fill cliche runof...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13997"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data (Spark)\n",
    "review_df_2000 = review_df\n",
    "review_df_12000 = sqlContext.read.csv('/project/12000_predicted_labels_v2.csv', header=True,sep='~')\n",
    "\n",
    "# Remove Null\n",
    "review_df_12000 = review_df_12000.filter(review_df_12000.predicted_train.isNotNull())\n",
    "\n",
    "#Change Column name and type\n",
    "review_df_12000 = review_df_12000.withColumnRenamed('Review','text')\n",
    "review_df_12000 = review_df_12000.withColumnRenamed('predicted_train','label')\n",
    "review_df_12000 = review_df_12000.withColumn(\"label\", review_df_12000[\"label\"].cast(IntegerType()))\n",
    "review_df_12000 = review_df_12000.filter(review_df_12000.label.isNotNull())\n",
    "\n",
    "# remove stop words to reduce dimensionality\n",
    "review_df_12000 = review_df_12000.withColumn(\"text\", remove_stops_udf(review_df_12000[\"text\"]))\n",
    "\n",
    "# remove other non essential words\n",
    "review_df_12000 = review_df_12000.withColumn(\"text\", remove_features_udf(review_df_12000[\"text\"]))\n",
    "\n",
    "# tag the words remaining and keep only Nouns, Verbs and Adjectives\n",
    "review_df_12000 = review_df_12000.withColumn(\"text\", tag_and_remove_udf(review_df_12000[\"text\"]))\n",
    "\n",
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "review_df_12000 = review_df_12000.withColumn(\"text\", lemmatize_udf(review_df_12000[\"text\"]))\n",
    "\n",
    "# Create Training_df_2 by combining 12000 weak labeled data points and 2000 labeled data points\n",
    "training_df_2 = review_df_2000.union(review_df_12000.select(['text','label']))\n",
    "\n",
    "training_df_2.show()\n",
    "training_df_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5815815815815816"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol='words', outputCol=\"features\")\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")\n",
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nb])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)\n",
    "\n",
    "cvModel = cv.fit(training_df_2)\n",
    "\n",
    "result = cvModel.transform(test_df)\n",
    "prediction_df = result.select(\"text\", \"label\", \"prediction\")\n",
    "\n",
    "#Evaluate the accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(result, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier we produced with 3000 data points performed with 62% accuracy. Meanwhile, the classifier we created from an extra 10000 weak labeled data points performed with 58% accuracy. This might be due to the accuracy of our labelling function is only around 60% and it instead cause some noises to our dataset which in turn reduced the performance of our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
