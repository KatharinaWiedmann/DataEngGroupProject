{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Functions we have so far: \n",
    "- Exclusive bad (Katie - delete the words that do not make sense and finish up  )\n",
    "- Exclusive good (Katie - delete the words that do not make sense and finish up  )\n",
    "- Exclamation mark (Debbie)\n",
    "- Question mark (Debbie)\n",
    "- Capital letters (Debbie)\n",
    "- too (negative) (Vera)\n",
    "- far (positive) (Vera)\n",
    "- n\\'t (Hong)\n",
    "- positive word (Katie)\n",
    "- negative word (Katie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas==0.24.2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-0.24.2              |   py36he6710b0_0         8.5 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.5 MB\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  pandas                               1.0.1-py36h0573a6f_0 --> 0.24.2-py36he6710b0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pandas-0.24.2        | 8.5 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pandas==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    bottleneck-1.3.2           |   py36heb32a55_0         124 KB\n",
      "    dask-2.11.0                |             py_0          13 KB\n",
      "    dask-core-2.11.0           |             py_0         565 KB\n",
      "    distributed-2.11.0         |           py36_0         943 KB\n",
      "    gunicorn-20.0.4            |           py36_0         125 KB\n",
      "    hypothesis-5.5.4           |             py_0         227 KB\n",
      "    nb_conda_kernels-2.2.2     |           py36_0          39 KB\n",
      "    ncurses-6.2                |       he6710b0_0         1.1 MB\n",
      "    plotly-4.5.2               |             py_0         1.6 MB\n",
      "    pytest-astropy-0.8.0       |             py_0           9 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.7 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  bottleneck                           1.3.1-py36hdd07704_0 --> 1.3.2-py36heb32a55_0\n",
      "  dask                                          2.10.1-py_0 --> 2.11.0-py_0\n",
      "  dask-core                                     2.10.1-py_0 --> 2.11.0-py_0\n",
      "  distributed        pkgs/main/noarch::distributed-2.10.0-~ --> pkgs/main/linux-64::distributed-2.11.0-py36_0\n",
      "  gunicorn                                    19.9.0-py36_0 --> 20.0.4-py36_0\n",
      "  hypothesis                                     5.4.1-py_0 --> 5.5.4-py_0\n",
      "  nb_conda_kernels                             2.1.1-py36_1 --> 2.2.2-py36_0\n",
      "  ncurses                                    6.1-he6710b0_1 --> 6.2-he6710b0_0\n",
      "  pandas                              0.24.2-py36he6710b0_0 --> 1.0.1-py36h0573a6f_0\n",
      "  plotly                                         4.4.1-py_0 --> 4.5.2-py_0\n",
      "  pytest-astropy                                 0.7.0-py_0 --> 0.8.0-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "hypothesis-5.5.4     | 227 KB    | ##################################### | 100% \n",
      "distributed-2.11.0   | 943 KB    | ##################################### | 100% \n",
      "bottleneck-1.3.2     | 124 KB    | ##################################### | 100% \n",
      "ncurses-6.2          | 1.1 MB    | ##################################### | 100% \n",
      "plotly-4.5.2         | 1.6 MB    | ##################################### | 100% \n",
      "nb_conda_kernels-2.2 | 39 KB     | ##################################### | 100% \n",
      "pytest-astropy-0.8.0 | 9 KB      | ##################################### | 100% \n",
      "dask-core-2.11.0     | 565 KB    | ##################################### | 100% \n",
      "dask-2.11.0          | 13 KB     | ##################################### | 100% \n",
      "gunicorn-20.0.4      | 125 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: | b'+ /opt/anaconda/envs/Python3/bin/python -m nb_conda_kernels.install --disable --prefix=/opt/anaconda/envs/Python3\\nDisabling nb_conda_kernels...\\nDisabled nb_conda_kernels\\n'\n",
      "/ b'Enabling nb_conda_kernels...\\nStatus: enabled\\n'\n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda upgrade --all -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - snorkel==0.9.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
      "    certifi-2019.11.28         |           py36_0         149 KB  conda-forge\n",
      "    cudatoolkit-10.0.130       |                0       261.2 MB\n",
      "    cudnn-7.6.5                |       cuda10.0_0       165.0 MB\n",
      "    libprotobuf-3.11.3         |       h8b12597_0         4.8 MB  conda-forge\n",
      "    ninja-1.10.0               |       hc9558a2_0         1.9 MB  conda-forge\n",
      "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
      "    pandas-0.24.2              |   py36hb3f55d8_1        11.1 MB  conda-forge\n",
      "    protobuf-3.11.3            |   py36he1b5a44_0         696 KB  conda-forge\n",
      "    pytorch-1.1.0              |cuda100py36he554f03_0       196.2 MB\n",
      "    scikit-learn-0.21.3        |   py36hd81dba3_0         5.0 MB\n",
      "    snorkel-0.9.0              |             py_0          85 KB  conda-forge\n",
      "    tensorboardx-1.9           |             py_0          75 KB  conda-forge\n",
      "    tqdm-4.43.0                |             py_0          47 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       648.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0\n",
      "  cudnn              pkgs/main/linux-64::cudnn-7.6.5-cuda10.0_0\n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.11.3-h8b12597_0\n",
      "  ninja              conda-forge/linux-64::ninja-1.10.0-hc9558a2_0\n",
      "  protobuf           conda-forge/linux-64::protobuf-3.11.3-py36he1b5a44_0\n",
      "  pytorch            pkgs/main/linux-64::pytorch-1.1.0-cuda100py36he554f03_0\n",
      "  snorkel            conda-forge/noarch::snorkel-0.9.0-py_0\n",
      "  tensorboardx       conda-forge/noarch::tensorboardx-1.9-py_0\n",
      "  tqdm               conda-forge/noarch::tqdm-4.43.0-py_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
      "  certifi                                         pkgs/main --> conda-forge\n",
      "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
      "  pandas             pkgs/main::pandas-1.0.1-py36h0573a6f_0 --> conda-forge::pandas-0.24.2-py36hb3f55d8_1\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  scikit-learn                        0.22.1-py36hd81dba3_0 --> 0.21.3-py36hd81dba3_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openssl-1.1.1d       | 2.1 MB    | ##################################### | 100% \n",
      "protobuf-3.11.3      | 696 KB    | ##################################### | 100% \n",
      "pandas-0.24.2        | 11.1 MB   | ##################################### | 100% \n",
      "snorkel-0.9.0        | 85 KB     | ##################################### | 100% \n",
      "libprotobuf-3.11.3   | 4.8 MB    | ##################################### | 100% \n",
      "certifi-2019.11.28   | 149 KB    | ##################################### | 100% \n",
      "scikit-learn-0.21.3  | 5.0 MB    | ##################################### | 100% \n",
      "tqdm-4.43.0          | 47 KB     | ##################################### | 100% \n",
      "ninja-1.10.0         | 1.9 MB    | ##################################### | 100% \n",
      "cudatoolkit-10.0.130 | 261.2 MB  | ##################################### | 100% \n",
      "tensorboardx-1.9     | 75 KB     | ##################################### | 100% \n",
      "cudnn-7.6.5          | 165.0 MB  | ##################################### | 100% \n",
      "ca-certificates-2019 | 145 KB    | ##################################### | 100% \n",
      "pytorch-1.1.0        | 196.2 MB  | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install snorkel==0.9.0 -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - textblob\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    textblob-0.15.3            |             py_0         595 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         595 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  textblob           conda-forge/noarch::textblob-0.15.3-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "textblob-0.15.3      | 595 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier,LabelModel\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from itertools import repeat\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n",
      "<pyspark.sql.session.SparkSession object at 0x7fcab57e2080>\n"
     ]
    }
   ],
   "source": [
    "#Spark \n",
    "\n",
    "# Spark Environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "import pyspark\n",
    "\n",
    "number_cores = 4\n",
    "memory_gb = 16\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "print(sc)\n",
    "\n",
    "# get the context\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "print(spark) \n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse all from DVD releases page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = 'https://www.rottentomatoes.com/api/private/v2.0/browse?maxTomato=100&services=amazon%3Bhbo_go%3Bitunes%3Bnetflix_iw%3Bvudu%3Bamazon_prime%3Bfandango_now&certified&sortBy=release&type=dvd-streaming-all&page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get movie url\n",
    "movie_url = []\n",
    "start_page = 1 ; end_page = 1\n",
    "while start_page <= end_page:\n",
    "#     time.sleep(7)\n",
    "    url = main + str(start_page)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code !=200:\n",
    "        print('Request error')\n",
    "        break\n",
    "    file = json.loads(response.text)\n",
    "    for i in file['results']:\n",
    "        movie_url = movie_url + [i['url']]\n",
    "    start_page +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples for the url:\n",
      "\n",
      "/m/frozen_ii\n",
      "/m/playmobil_the_movie\n",
      "/m/queen_and_slim\n",
      "\n",
      "Number of movies in list: 32\n"
     ]
    }
   ],
   "source": [
    "print('Examples for the url:\\n')\n",
    "for i in range(3):\n",
    "    print(movie_url[i])\n",
    "print('\\nNumber of movies in list: {}'.format(len(movie_url)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into lists of 50 movies to do the scraping\n",
    "movie_url_split = [movie_url[i:i+50] for i in range(0,600,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_url_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reviews from the web\n",
    "reviews = []\n",
    "titles = []\n",
    "ratings = []\n",
    "for split in movie_url_split: # Loop through each split\n",
    "#     time.sleep(7)\n",
    "    for title in split: # Loop through each movie title\n",
    "        url = 'https://www.rottentomatoes.com'+title\n",
    "#         time.sleep(7)\n",
    "        response = requests.get(url)\n",
    "        # Check the request status code\n",
    "        if response.status_code != 200:\n",
    "            print('Request error')\n",
    "            break\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Get labels from each review (fresh vs. rotten)\n",
    "        fresh_rotten = soup.find_all(class_=\"review_quote\")\n",
    "        \n",
    "        # Get movie title\n",
    "        title = soup.find(class_=\"mop-ratings-wrap__title mop-ratings-wrap__title--top\").getText()\n",
    "        \n",
    "        # Get reviews\n",
    "        review = soup.find_all('blockquote')\n",
    "        for i in review:\n",
    "            j = str(i.contents[1])\n",
    "            j = j.replace(\"<p>\\n                    \\n                        \",\"\")\n",
    "            j = j.replace(\"\\n                    \\n                </p>\",\"\")\n",
    "            reviews = reviews + [j]\n",
    "            titles = titles + [title]\n",
    "        \n",
    "        # Identify labels\n",
    "        for i in fresh_rotten:\n",
    "            temp = str(i.findChildren()[2])\n",
    "            if re.search('rotten',temp):\n",
    "                ratings = ratings + ['rotten']\n",
    "            else:\n",
    "                ratings = ratings + ['fresh']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame to store the scraped data\n",
    "df = pd.DataFrame([titles,reviews,ratings],index = ['title','review','rating']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 330 entries, 0 to 330\n",
      "Data columns (total 3 columns):\n",
      "title     330 non-null object\n",
      "review    330 non-null object\n",
      "rating    330 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 10.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Clean the data (drop duplicates, check missing values etc.)\n",
    "df = df.drop_duplicates()\n",
    "df = df.replace([None],np.nan)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>A distressingly unnecessary (and fairly tediou...</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>Frozen II is the exact kind of sequel that mor...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frozen II</td>\n",
       "      <td>[A]n ultimately satisfying story of more matur...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                             review  rating\n",
       "0  Frozen II  A distressingly unnecessary (and fairly tediou...  rotten\n",
       "1  Frozen II  Frozen II is the exact kind of sequel that mor...   fresh\n",
       "2  Frozen II  [A]n ultimately satisfying story of more matur...   fresh"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV files\n",
    "# df.to_csv('web_scraping_rotten_tomatoes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Preparing TSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TSV file\n",
    "tsv_reviews = pd.read_csv('/project/reviews.tsv', sep='\\t', header=0, encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>fresh</th>\n",
       "      <th>critic</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A distinctly gallows take on contemporary fina...</td>\n",
       "      <td>3/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>PJ Nabarro</td>\n",
       "      <td>0</td>\n",
       "      <td>Patrick Nabarro</td>\n",
       "      <td>November 10, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>It's an allegory in search of a meaning that n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotten</td>\n",
       "      <td>Annalee Newitz</td>\n",
       "      <td>0</td>\n",
       "      <td>io9.com</td>\n",
       "      <td>May 23, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>... life lived in a bubble in financial dealin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Sean Axmaker</td>\n",
       "      <td>0</td>\n",
       "      <td>Stream on Demand</td>\n",
       "      <td>January 4, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Continuing along a line introduced in last yea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Daniel Kasman</td>\n",
       "      <td>0</td>\n",
       "      <td>MUBI</td>\n",
       "      <td>November 16, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>... a perverse twist on neorealism...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Cinema Scope</td>\n",
       "      <td>October 12, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review rating   fresh  \\\n",
       "0   3  A distinctly gallows take on contemporary fina...    3/5   fresh   \n",
       "1   3  It's an allegory in search of a meaning that n...    NaN  rotten   \n",
       "2   3  ... life lived in a bubble in financial dealin...    NaN   fresh   \n",
       "3   3  Continuing along a line introduced in last yea...    NaN   fresh   \n",
       "4   3             ... a perverse twist on neorealism...     NaN   fresh   \n",
       "\n",
       "           critic  top_critic         publisher               date  \n",
       "0      PJ Nabarro           0   Patrick Nabarro  November 10, 2018  \n",
       "1  Annalee Newitz           0           io9.com       May 23, 2018  \n",
       "2    Sean Axmaker           0  Stream on Demand    January 4, 2018  \n",
       "3   Daniel Kasman           0              MUBI  November 16, 2017  \n",
       "4             NaN           0      Cinema Scope   October 12, 2017  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract review and fresh columns\n",
    "tsv_reviews = pd.DataFrame(tsv_reviews, columns = ['review', 'fresh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>fresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A distinctly gallows take on contemporary fina...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's an allegory in search of a meaning that n...</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... life lived in a bubble in financial dealin...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Continuing along a line introduced in last yea...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>... a perverse twist on neorealism...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review   fresh\n",
       "0  A distinctly gallows take on contemporary fina...   fresh\n",
       "1  It's an allegory in search of a meaning that n...  rotten\n",
       "2  ... life lived in a bubble in financial dealin...   fresh\n",
       "3  Continuing along a line introduced in last yea...   fresh\n",
       "4             ... a perverse twist on neorealism...    fresh"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    5563\n",
       "fresh        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN rows in reviews\n",
    "index_name = tsv_reviews[(tsv_reviews['review'].isnull())].index\n",
    "tsv_reviews.drop(index_name, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    0\n",
       "fresh     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename fresh as 1 and rotten as 0\n",
    "tsv_reviews['fresh'].replace({'fresh':'1', 'rotten':'0'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 8753 to 19142\n",
      "Data columns (total 2 columns):\n",
      "Review       5000 non-null object\n",
      "Freshness    5000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Rename columns\n",
    "tsv_reviews.rename(columns={'fresh':'Freshness','review':'Review'},inplace=True)\n",
    "tsv_reviews = tsv_reviews.sample(5000)\n",
    "#take 5000\n",
    "tsv_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Preparing CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Freshness                                             Review\n",
       "0          1   Manakamana doesn't answer any questions, yet ...\n",
       "1          1   Wilfully offensive and powered by a chest-thu...\n",
       "2          0   It would be difficult to imagine material mor...\n",
       "3          0   Despite the gusto its star brings to the role...\n",
       "4          0   If there was a good idea at the core of this ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file\n",
    "csv_reviews= pd.read_csv('/project/rotten_tomatoes_reviews.csv')\n",
    "csv_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137829</th>\n",
       "      <td>Lives spent looking at devices and screens is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307429</th>\n",
       "      <td>An engaging blend of modern-day interviews an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40117</th>\n",
       "      <td>A difficult film to like, an impossible one n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463932</th>\n",
       "      <td>American Ninja was still a compltely awful mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382015</th>\n",
       "      <td>Fame 2009 has turns rather than scenes, and i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "137829   Lives spent looking at devices and screens is...          1\n",
       "307429   An engaging blend of modern-day interviews an...          1\n",
       "40117    A difficult film to like, an impossible one n...          1\n",
       "463932   American Ninja was still a compltely awful mo...          0\n",
       "382015   Fame 2009 has turns rather than scenes, and i...          0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 137829 to 393444\n",
      "Data columns (total 2 columns):\n",
      "Review       5000 non-null object\n",
      "Freshness    5000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Swap Freshness and Review \n",
    "columns_titles = [\"Review\",\"Freshness\"]\n",
    "csv_reviews=csv_reviews.reindex(columns=columns_titles)\n",
    "csv_reviews = csv_reviews.sample(5000)\n",
    "\n",
    "csv_reviews.head()\n",
    "csv_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping & Preparing scrapped data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>Babenco's cinematic farewell isn't perfect by ...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>This is a good film if you are looking for som...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>My Hindu Friend is a celebration of life, love...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>I wouldn't miss it; it's a film that's more th...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>...surreal, reflective (though never sentiment...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              title  \\\n",
       "0           0  My Hindu Friend (Meu amigo Hindu)   \n",
       "1           1  My Hindu Friend (Meu amigo Hindu)   \n",
       "2           2  My Hindu Friend (Meu amigo Hindu)   \n",
       "3           3  My Hindu Friend (Meu amigo Hindu)   \n",
       "4           4  My Hindu Friend (Meu amigo Hindu)   \n",
       "\n",
       "                                              review rating  \n",
       "0  Babenco's cinematic farewell isn't perfect by ...  fresh  \n",
       "1  This is a good film if you are looking for som...  fresh  \n",
       "2  My Hindu Friend is a celebration of life, love...  fresh  \n",
       "3  I wouldn't miss it; it's a film that's more th...  fresh  \n",
       "4  ...surreal, reflective (though never sentiment...  fresh  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Web Scraping Data\n",
    "web_scraping_reviews= pd.read_csv('/project/web_scraping_rotten_tomatoes.csv')\n",
    "web_scraping_reviews.head()\n",
    "\n",
    "web_scraping_reviews = web_scraping_reviews.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>2295</td>\n",
       "      <td>The Day Shall Come</td>\n",
       "      <td>It's a case of distance guiding the film, with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>3529</td>\n",
       "      <td>Charlie Says</td>\n",
       "      <td>Charlie Says, for all its contemplative trappi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>5194</td>\n",
       "      <td>Avengement</td>\n",
       "      <td>The \"New Jason Statham\" Adkins is still great ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>4484</td>\n",
       "      <td>Us</td>\n",
       "      <td>Us revolves around an allegory that's more ela...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1471</td>\n",
       "      <td>The Return of Martin Guerre (Le Retour de Mart...</td>\n",
       "      <td>A sobering account not only Medieval provincia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              title  \\\n",
       "2295        2295                                 The Day Shall Come   \n",
       "3529        3529                                       Charlie Says   \n",
       "5194        5194                                         Avengement   \n",
       "4484        4484                                                 Us   \n",
       "1471        1471  The Return of Martin Guerre (Le Retour de Mart...   \n",
       "\n",
       "                                                 Review Freshness  \n",
       "2295  It's a case of distance guiding the film, with...         0  \n",
       "3529  Charlie Says, for all its contemplative trappi...         1  \n",
       "5194  The \"New Jason Statham\" Adkins is still great ...         0  \n",
       "4484  Us revolves around an allegory that's more ela...         1  \n",
       "1471  A sobering account not only Medieval provincia...         1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename fresh as 1 and rotten as 0\n",
    "web_scraping_reviews['rating'].replace({'fresh':'1', 'rotten':'0'}, inplace = True)\n",
    "\n",
    "#Rename Rating to Review \n",
    "web_scraping_reviews.rename(columns={'rating':'Freshness', 'review':'Review'},inplace=True)\n",
    "web_scraping_reviews.head()\n",
    "\n",
    "# Extract Review and Freshness columns\n",
    "web_scraping_reviews= pd.DataFrame(web_scraping_reviews, columns = ['Review', 'Freshness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>It's a case of distance guiding the film, with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>Charlie Says, for all its contemplative trappi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>The \"New Jason Statham\" Adkins is still great ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>Us revolves around an allegory that's more ela...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>A sobering account not only Medieval provincia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review Freshness\n",
       "2295  It's a case of distance guiding the film, with...         0\n",
       "3529  Charlie Says, for all its contemplative trappi...         1\n",
       "5194  The \"New Jason Statham\" Adkins is still great ...         0\n",
       "4484  Us revolves around an allegory that's more ela...         1\n",
       "1471  A sobering account not only Medieval provincia...         1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_scraping_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all the data together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137829</th>\n",
       "      <td>Lives spent looking at devices and screens is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307429</th>\n",
       "      <td>An engaging blend of modern-day interviews an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40117</th>\n",
       "      <td>A difficult film to like, an impossible one n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463932</th>\n",
       "      <td>American Ninja was still a compltely awful mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382015</th>\n",
       "      <td>Fame 2009 has turns rather than scenes, and i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review Freshness\n",
       "137829   Lives spent looking at devices and screens is...         1\n",
       "307429   An engaging blend of modern-day interviews an...         1\n",
       "40117    A difficult film to like, an impossible one n...         1\n",
       "463932   American Ninja was still a compltely awful mo...         0\n",
       "382015   Fame 2009 has turns rather than scenes, and i...         0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv_reviews.info()\n",
    "# tsv_reviews.info()\n",
    "# web_scraping_reviews.info()\n",
    "\n",
    "\n",
    "\n",
    "# Concat two files into all_reviews\n",
    "all_reviews=pd.concat([csv_reviews, tsv_reviews,web_scraping_reviews],axis=0, sort=False)\n",
    "all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into test and training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews['Freshness'] = all_reviews['Freshness'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(all_reviews,test_size=0.2,stratify = all_reviews['Freshness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 4195 to 43860\n",
      "Data columns (total 2 columns):\n",
      "Review       12000 non-null object\n",
      "Freshness    12000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 281.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000 entries, 2360 to 1116\n",
      "Data columns (total 2 columns):\n",
      "Review       3000 non-null object\n",
      "Freshness    3000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 70.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>A sobering portrait of human trafficking for s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>Solid hip hop genre picture that gives \"Black-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92900</th>\n",
       "      <td>Superbly directed, thought-provoking blend of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28943</th>\n",
       "      <td>Dumb comedy should be cited for bad taste.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>Before an inexpressible and unreachable realit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Freshness\n",
       "4195   A sobering portrait of human trafficking for s...          1\n",
       "4495   Solid hip hop genre picture that gives \"Black-...          1\n",
       "92900   Superbly directed, thought-provoking blend of...          1\n",
       "28943         Dumb comedy should be cited for bad taste.          0\n",
       "2455   Before an inexpressible and unreachable realit...          1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid off training labels \n",
    "train = train.drop('Freshness', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1758\n",
       "0    1242\n",
       "Name: Freshness, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Freshness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52316</th>\n",
       "      <td>With its distinctive voice, the irreverent com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>A shameless crowd-pleaser delivered with such ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94817</th>\n",
       "      <td>Those who love it as passionately as I do rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>There's great satisfaction and hope in Darlin'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>A first date gone bad...then good...then bad.....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Freshness\n",
       "52316  With its distinctive voice, the irreverent com...          1\n",
       "1195   A shameless crowd-pleaser delivered with such ...          1\n",
       "94817   Those who love it as passionately as I do rea...          1\n",
       "2883   There's great satisfaction and hope in Darlin'...          1\n",
       "3323   A first date gone bad...then good...then bad.....          1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From labelled test set, extract a sample to find out about which labelling functions could be written\n",
    "#Not sure how big the development split_ can be --> take sample of 1000 data points \n",
    "\n",
    "development_split = test.sample(2000,random_state=42)\n",
    "development_split.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52316</th>\n",
       "      <td>With its distinctive voice, the irreverent com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>A shameless crowd-pleaser delivered with such ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94817</th>\n",
       "      <td>Those who love it as passionately as I do rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>There's great satisfaction and hope in Darlin'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>A first date gone bad...then good...then bad.....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143</th>\n",
       "      <td>The way every ruffle of a dress or lace embell...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>This is one of those movies that you have to w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467842</th>\n",
       "      <td>A very stupid, very nasty and very messy horr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469998</th>\n",
       "      <td>The sharp comic timing and devil-may-care bre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>From his time in the wilderness, Almodvar has...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235302</th>\n",
       "      <td>Rooney's Lisbeth takes matters large and smal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31503</th>\n",
       "      <td>It's nowhere near classic stuff. However, the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Modern horror comedy that resonates due to the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>Even undemanding kids in need of distraction m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>This is surely a special that's worth being pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>I've always been a fan of her music. With Lind...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21320</th>\n",
       "      <td>Once things get going, you might wonder why th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>The world is fantastically realized. From the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315056</th>\n",
       "      <td>A lot of those [stand-alone] episodes have be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334673</th>\n",
       "      <td>Drug use and cliches mar unoriginal indie dra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>This dramedy is at its best when it puts its c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381196</th>\n",
       "      <td>Brolin adds another feather in the cap that i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173733</th>\n",
       "      <td>With moments of true greatness and strong per...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4762</th>\n",
       "      <td>I Am Mother exudes visual sophistication-speci...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32047</th>\n",
       "      <td>It's a disturbingly conventional and painfully...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11249</th>\n",
       "      <td>Matt Damon proves he's more than up to the tas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>...is competent enough to embrace its thrill-s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>The Weekend gets off to a decidedly rough star...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Teen comic-horror tale with gory violence, may...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>In the end, Candy Corn is not a bad film - it'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>Childhood curiosity clashes with dystopian per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87501</th>\n",
       "      <td>Detail-packed but never dull, with dialogue t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298110</th>\n",
       "      <td>It could be the greatest freak-out of all time.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406673</th>\n",
       "      <td>They stumble onto a vacant house that, like a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>Writer-director Grant Sputore does a nice job ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293128</th>\n",
       "      <td>Loud, crude and outlandish, Rollerball is a p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>It's hard to say who's more at fault: writer, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>A loosely wound thriller of the dime-a-dozen, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>It's all perfectly watchable but hampered by c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62529</th>\n",
       "      <td>To say of someone that they were born to play...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29803</th>\n",
       "      <td>In many ways it is a very clever film, but it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141228</th>\n",
       "      <td>I could load you up with more plot details, b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>Lambert stages it with a matter-of-factness th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5354</th>\n",
       "      <td>Gritty and ultra-real look at the present day ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39773</th>\n",
       "      <td>...a very funny heist caper.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>The minute the credits roll, you'll just want ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54403</th>\n",
       "      <td>Reno does what he can in a thankless situation...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198828</th>\n",
       "      <td>A brash departure from the legend that retain...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279499</th>\n",
       "      <td>Eyes Wide Shut turns into a series of haphaza...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43234</th>\n",
       "      <td>To broaden the commercial appeal of House of F...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>It's undeniably a good thing that it exists, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>The script is sometimes funny, but the movie n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>Without the star charisma or narrative ingenui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>A major Marvel/Avengers star turns up in the s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252799</th>\n",
       "      <td>The colors are stitched and the black and whi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391345</th>\n",
       "      <td>The streamlined narrative and the film's cons...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297367</th>\n",
       "      <td>In spite of the mess, Zellweger remains winso...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268133</th>\n",
       "      <td>I look forward to returning to Roma once more...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47597</th>\n",
       "      <td>There is a positively chilling performance fro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36181</th>\n",
       "      <td>A movie so goofy and affable about its willful...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "52316   With its distinctive voice, the irreverent com...          1\n",
       "1195    A shameless crowd-pleaser delivered with such ...          1\n",
       "94817    Those who love it as passionately as I do rea...          1\n",
       "2883    There's great satisfaction and hope in Darlin'...          1\n",
       "3323    A first date gone bad...then good...then bad.....          1\n",
       "5143    The way every ruffle of a dress or lace embell...          1\n",
       "673     This is one of those movies that you have to w...          1\n",
       "467842   A very stupid, very nasty and very messy horr...          0\n",
       "469998   The sharp comic timing and devil-may-care bre...          0\n",
       "409     From his time in the wilderness, Almodvar has...          1\n",
       "235302   Rooney's Lisbeth takes matters large and smal...          1\n",
       "31503   It's nowhere near classic stuff. However, the ...          1\n",
       "944     Modern horror comedy that resonates due to the...          1\n",
       "3672    Even undemanding kids in need of distraction m...          0\n",
       "544     This is surely a special that's worth being pr...          1\n",
       "1030    I've always been a fan of her music. With Lind...          1\n",
       "21320   Once things get going, you might wonder why th...          0\n",
       "4048    The world is fantastically realized. From the ...          0\n",
       "315056   A lot of those [stand-alone] episodes have be...          1\n",
       "334673   Drug use and cliches mar unoriginal indie dra...          0\n",
       "5712    This dramedy is at its best when it puts its c...          1\n",
       "381196   Brolin adds another feather in the cap that i...          1\n",
       "173733   With moments of true greatness and strong per...          0\n",
       "4762    I Am Mother exudes visual sophistication-speci...          1\n",
       "32047   It's a disturbingly conventional and painfully...          0\n",
       "11249   Matt Damon proves he's more than up to the tas...          1\n",
       "4284    ...is competent enough to embrace its thrill-s...          0\n",
       "2479    The Weekend gets off to a decidedly rough star...          1\n",
       "267     Teen comic-horror tale with gory violence, may...          1\n",
       "2668    In the end, Candy Corn is not a bad film - it'...          0\n",
       "...                                                   ...        ...\n",
       "938     Childhood curiosity clashes with dystopian per...          1\n",
       "87501    Detail-packed but never dull, with dialogue t...          1\n",
       "298110    It could be the greatest freak-out of all time.          1\n",
       "406673   They stumble onto a vacant house that, like a...          0\n",
       "4766    Writer-director Grant Sputore does a nice job ...          1\n",
       "293128   Loud, crude and outlandish, Rollerball is a p...          0\n",
       "2750    It's hard to say who's more at fault: writer, ...          0\n",
       "5144    A loosely wound thriller of the dime-a-dozen, ...          0\n",
       "4561    It's all perfectly watchable but hampered by c...          1\n",
       "62529    To say of someone that they were born to play...          1\n",
       "29803   In many ways it is a very clever film, but it ...          0\n",
       "141228   I could load you up with more plot details, b...          0\n",
       "2356    Lambert stages it with a matter-of-factness th...          1\n",
       "5354    Gritty and ultra-real look at the present day ...          1\n",
       "39773                        ...a very funny heist caper.          1\n",
       "4306    The minute the credits roll, you'll just want ...          0\n",
       "54403   Reno does what he can in a thankless situation...          0\n",
       "198828   A brash departure from the legend that retain...          1\n",
       "279499   Eyes Wide Shut turns into a series of haphaza...          0\n",
       "43234   To broaden the commercial appeal of House of F...          1\n",
       "10267   It's undeniably a good thing that it exists, t...          0\n",
       "3313    The script is sometimes funny, but the movie n...          0\n",
       "2023    Without the star charisma or narrative ingenui...          0\n",
       "115     A major Marvel/Avengers star turns up in the s...          1\n",
       "252799   The colors are stitched and the black and whi...          1\n",
       "391345   The streamlined narrative and the film's cons...          1\n",
       "297367   In spite of the mess, Zellweger remains winso...          0\n",
       "268133   I look forward to returning to Roma once more...          1\n",
       "47597   There is a positively chilling performance fro...          1\n",
       "36181   A movie so goofy and affable about its willful...          1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For finding labelling functions: \n",
    "development_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       2000\n",
       "Freshness    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_split.to_csv('development_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       2000\n",
       "Freshness    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52316</th>\n",
       "      <td>With its distinctive voice, the irreverent com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>A shameless crowd-pleaser delivered with such ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94817</th>\n",
       "      <td>Those who love it as passionately as I do rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>There's great satisfaction and hope in Darlin'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>A first date gone bad...then good...then bad.....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Freshness\n",
       "52316  With its distinctive voice, the irreverent com...          1\n",
       "1195   A shameless crowd-pleaser delivered with such ...          1\n",
       "94817   Those who love it as passionately as I do rea...          1\n",
       "2883   There's great satisfaction and hope in Darlin'...          1\n",
       "3323   A first date gone bad...then good...then bad.....          1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       843\n",
       "Freshness    843\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Might have to get rid off index?\n",
    "\n",
    "development_split[development_split['Freshness'] !=1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1157\n",
       "0     843\n",
       "Name: Freshness, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split['Freshness'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52316</th>\n",
       "      <td>With its distinctive voice, the irreverent com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>A shameless crowd-pleaser delivered with such ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94817</th>\n",
       "      <td>Those who love it as passionately as I do rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>There's great satisfaction and hope in Darlin'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>A first date gone bad...then good...then bad.....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Freshness\n",
       "52316  With its distinctive voice, the irreverent com...          1\n",
       "1195   A shameless crowd-pleaser delivered with such ...          1\n",
       "94817   Those who love it as passionately as I do rea...          1\n",
       "2883   There's great satisfaction and hope in Darlin'...          1\n",
       "3323   A first date gone bad...then good...then bad.....          1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>467842</th>\n",
       "      <td>A very stupid, very nasty and very messy horr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469998</th>\n",
       "      <td>The sharp comic timing and devil-may-care bre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>Even undemanding kids in need of distraction m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21320</th>\n",
       "      <td>Once things get going, you might wonder why th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>The world is fantastically realized. From the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "467842   A very stupid, very nasty and very messy horr...          0\n",
       "469998   The sharp comic timing and devil-may-care bre...          0\n",
       "3672    Even undemanding kids in need of distraction m...          0\n",
       "21320   Once things get going, you might wonder why th...          0\n",
       "4048    The world is fantastically realized. From the ...          0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split_fresh = development_split[development_split['Freshness'] == 1]\n",
    "development_split_rotten = development_split[development_split['Freshness'] == 0]\n",
    "development_split_fresh.head()\n",
    "development_split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1157 entries, 52316 to 36181\n",
      "Data columns (total 2 columns):\n",
      "Review       1157 non-null object\n",
      "Freshness    1157 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 27.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 843 entries, 467842 to 297367\n",
      "Data columns (total 2 columns):\n",
      "Review       843 non-null object\n",
      "Freshness    843 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 19.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# fresh reviews \n",
    "development_split_fresh.info()\n",
    "# rotten reviews \n",
    "development_split_rotten.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation \n",
    "def remove_punctuation(dataframe):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in dataframe.Review.str.lower():\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    with its distinctive voice the irreverent come...\n",
       "1    a shameless crowdpleaser delivered with such p...\n",
       "2     those who love it as passionately as i do rea...\n",
       "3    theres great satisfaction and hope in darlin b...\n",
       "4    a first date gone badthen goodthen badthen goo...\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from fresh reviews & turn into Series\n",
    "split_fresh= pd.Series(remove_punctuation(development_split_fresh))\n",
    "split_fresh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordList = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\\\n",
    "                \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\\\n",
    "                \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\",\\\n",
    "                \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\",\\\n",
    "                \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\",\\\n",
    "                \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\",\\\n",
    "                \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\",\\\n",
    "                \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\\\n",
    "                \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords from fresh\n",
    "\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_fresh.replace(replacements, regex=True, inplace=True)\n",
    "split_fresh.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization and Count again\n",
    "def stem_recount(df):\n",
    "    import pandas as pd\n",
    "    # Lemmatization\n",
    "    from nltk import LancasterStemmer\n",
    "    st = LancasterStemmer()\n",
    "    newdf = df.copy()\n",
    "    for i in range(0,len(df)):\n",
    "        newdf.iloc[i,0] = st.stem(str(df.iloc[i,0])) \n",
    "        # Plz make sure the word column is the first column in df when using this function\n",
    "    \n",
    "    # Recount\n",
    "    duplicate = newdf[newdf.duplicated(['index'])]\n",
    "    # Plz make sure the 'index' is the column name consisting of words\n",
    "    for i in range(0,len(newdf)):\n",
    "        if i >= len(duplicate):\n",
    "            break\n",
    "        if newdf.iloc[i,0] == duplicate.iloc[i,0]:\n",
    "            newdf.iloc[i,1] = newdf.iloc[i,1] + duplicate.iloc[i,1]\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_fresh = split_fresh.str.split(expand=True).stack().value_counts()\n",
    "common_words_fresh_df = pd.DataFrame(common_words_fresh)\n",
    "common_words_fresh_df = common_words_fresh_df.rename({0:'Occurence good review'}, axis='columns')\n",
    "new_common_words_fresh_df = common_words_fresh_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movy</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lik</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ful</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ev</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>span</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>review</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>good</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gre</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tim</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>film</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>perform</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>best</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>funny</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>first</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fun</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lif</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>comedy</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mak</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>charact</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wel</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>stil</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>work</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>doesnt</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>perform</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>way</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mak</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lov</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>reaffirm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>corny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>blanchet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>tint</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>wwe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>threats</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>observ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>mukdeeprom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>zomby</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>transcend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>turajl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>stumbl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>chiwetel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>wellfit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>homeland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>roy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>mcteers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>ready</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>sympathet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>postconvert</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>soak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>hoechlin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>vuln</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>lansbury</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>sin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6091</th>\n",
       "      <td>kan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6092</th>\n",
       "      <td>antiabort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093</th>\n",
       "      <td>boy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6094</th>\n",
       "      <td>scum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>westfeldt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6096 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  Occurence good review\n",
       "0            film                    240\n",
       "1            movy                    110\n",
       "2              on                    105\n",
       "3             lik                     72\n",
       "4           story                     64\n",
       "5             ful                     55\n",
       "6              ev                     52\n",
       "7            span                     48\n",
       "8          review                     47\n",
       "9            good                     45\n",
       "10            gre                     45\n",
       "11            tim                     41\n",
       "12           film                     41\n",
       "13        perform                     41\n",
       "14           best                     39\n",
       "15          funny                     38\n",
       "16          first                     38\n",
       "17            fun                     38\n",
       "18            lif                     37\n",
       "19         comedy                     36\n",
       "20            mak                     35\n",
       "21        charact                     35\n",
       "22            wel                     33\n",
       "23           stil                     33\n",
       "24           work                     33\n",
       "25         doesnt                     33\n",
       "26        perform                     32\n",
       "27            way                     32\n",
       "28            mak                     32\n",
       "29            lov                     32\n",
       "...           ...                    ...\n",
       "6066     reaffirm                      1\n",
       "6067        corny                      1\n",
       "6068     blanchet                      1\n",
       "6069         tint                      1\n",
       "6070          wwe                      1\n",
       "6071      threats                      1\n",
       "6072       observ                      1\n",
       "6073   mukdeeprom                      1\n",
       "6074        zomby                      1\n",
       "6075    transcend                      1\n",
       "6076       turajl                      1\n",
       "6077       stumbl                      1\n",
       "6078     chiwetel                      1\n",
       "6079      wellfit                      1\n",
       "6080     homeland                      1\n",
       "6081          roy                      1\n",
       "6082      mcteers                      1\n",
       "6083        ready                      1\n",
       "6084    sympathet                      1\n",
       "6085  postconvert                      1\n",
       "6086         soak                      1\n",
       "6087     hoechlin                      1\n",
       "6088         vuln                      1\n",
       "6089     lansbury                      1\n",
       "6090          sin                      1\n",
       "6091          kan                      1\n",
       "6092    antiabort                      1\n",
       "6093          boy                      1\n",
       "6094         scum                      1\n",
       "6095    westfeldt                      1\n",
       "\n",
       "[6096 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_recount(new_common_words_fresh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>films</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makes</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characters</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doesnt</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performances</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekend</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alien</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landscape</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generation</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pieces</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>despair</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>questions</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>somehow</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valuable</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setting</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welcome</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>several</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redemption</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blockbuster</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insight</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doubt</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stuff</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uses</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realism</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memorable</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>793 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Occurence good review\n",
       "film                            199\n",
       "movie                           110\n",
       "one                             105\n",
       "like                             72\n",
       "story                            64\n",
       "full                             55\n",
       "even                             52\n",
       "spanish                          48\n",
       "review                           47\n",
       "good                             45\n",
       "great                            45\n",
       "time                             41\n",
       "films                            41\n",
       "performance                      41\n",
       "best                             39\n",
       "funny                            38\n",
       "first                            38\n",
       "fun                              38\n",
       "life                             37\n",
       "comedy                           36\n",
       "makes                            35\n",
       "characters                       35\n",
       "well                             33\n",
       "still                            33\n",
       "work                             33\n",
       "doesnt                           33\n",
       "performances                     32\n",
       "way                              32\n",
       "make                             32\n",
       "love                             32\n",
       "...                             ...\n",
       "flair                             4\n",
       "weekend                           4\n",
       "fare                              4\n",
       "step                              4\n",
       "alien                             4\n",
       "landscape                         4\n",
       "drive                             4\n",
       "generation                        4\n",
       "pieces                            4\n",
       "despair                           4\n",
       "questions                         4\n",
       "somehow                           4\n",
       "valuable                          4\n",
       "baseball                          4\n",
       "emotion                           4\n",
       "setting                           4\n",
       "welcome                           4\n",
       "four                              4\n",
       "several                           4\n",
       "redemption                        4\n",
       "today                             4\n",
       "blockbuster                       4\n",
       "insight                           4\n",
       "images                            4\n",
       "doubt                             4\n",
       "stuff                             4\n",
       "version                           4\n",
       "uses                              4\n",
       "realism                           4\n",
       "memorable                         4\n",
       "\n",
       "[793 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get most common words in positive reviews \n",
    "top_common_words_fresh = common_words_fresh_df[common_words_fresh_df['Occurence good review'] >=4]\n",
    "top_common_words_fresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** EXPLAIN WHY WE DONT USE LEMMATIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b> Reason for not using Lemmatization </b>\n",
    "\n",
    "<p>\n",
    "    Before counting the occurance of words in the movie review, we noticed that inflections in words may result in different occurances and thus generating bias during counting. For example, \"enjoy\" and \"enjoyed\" share the same root but would be counted separately if not using Lemmatization.\n",
    "    </p> \n",
    "    \n",
    "<p>\n",
    "    The function \"stem_recount\" takes the root of a word and recounts the occurences. However, it posed a disadvantage of mis-normalizing words into other completely different words. For example, \"movie\" was identified as \"movy\", and \"like\" was identified as \"lik\". We thought this disadvantage exceeds the benefits of correcting word inflection, so we decided to not implement it.\n",
    "    </p> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a very stupid very nasty and very messy horro...\n",
       "1     the sharp comic timing and devilmaycare breez...\n",
       "2    even undemanding kids in need of distraction m...\n",
       "3    once things get going you might wonder why the...\n",
       "4    the world is fantastically realized from the c...\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from rotten & turn into Series\n",
    "split_rotten= pd.Series(remove_punctuation(development_split_rotten))\n",
    "split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords from negative reviews\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_rotten.replace(replacements, regex=True, inplace=True)\n",
    "split_rotten.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get most common words in negative reviews \n",
    "\n",
    "common_words_rotten = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "common_words_rotten_df = pd.DataFrame(common_words_rotten)\n",
    "common_words_rotten_df = common_words_rotten_df.rename({0:'Occurence bad review'}, axis='columns')\n",
    "top_common_words_rotten = common_words_rotten_df[common_words_rotten_df['Occurence bad review'] >=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Occurence bad review\n",
       "film                    119\n",
       "movie                   103\n",
       "like                     74\n",
       "one                      53\n",
       "good                     47"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_common_words_rotten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of good and bad reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "We want to find out which of the words in the good list only appear in the good movies (and not in the bad movies), vice versa and base labeling functions on these findings. We first ened to prepare the data accordingly, before we can write the labelling functions.\n",
    "    <div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fresh_words_exclusive = top_common_words_fresh.merge(top_common_words_rotten, indicator='i', how='outer', left_index=True,\\\n",
    "                                                         right_index=True).query('i == \"left_only\"').drop('i', 1)\n",
    "\n",
    "top_rotten_words_exclusive = top_common_words_rotten.merge(top_common_words_fresh, indicator='i', how='outer', left_index=True,\\\n",
    "                                                           right_index=True).query('i == \"left_only\"').drop('i', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolutely</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absorbing</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actions</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Occurence good review  Occurence bad review\n",
       "2019                          5.0                   NaN\n",
       "able                          5.0                   NaN\n",
       "absolutely                    4.0                   NaN\n",
       "absorbing                     7.0                   NaN\n",
       "actions                       5.0                   NaN"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_fresh_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>across</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>already</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusing</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anyone</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awful</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Occurence bad review  Occurence good review\n",
       "across                    4.0                    NaN\n",
       "already                   6.0                    NaN\n",
       "amusing                   4.0                    NaN\n",
       "anyone                    5.0                    NaN\n",
       "awful                     4.0                    NaN"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rotten_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019',\n",
       " 'able',\n",
       " 'absolutely',\n",
       " 'absorbing',\n",
       " 'actions',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'adaptation',\n",
       " 'age',\n",
       " 'aging',\n",
       " 'air',\n",
       " 'alien',\n",
       " 'although',\n",
       " 'always',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'angry',\n",
       " 'animation',\n",
       " 'apart',\n",
       " 'art',\n",
       " 'artist',\n",
       " 'attention',\n",
       " 'aussie',\n",
       " 'authentic',\n",
       " 'away',\n",
       " 'baby',\n",
       " 'baseball',\n",
       " 'beats',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'behind',\n",
       " 'believe',\n",
       " 'bittersweet',\n",
       " 'black',\n",
       " 'bleak',\n",
       " 'blockbuster',\n",
       " 'bloody',\n",
       " 'blue',\n",
       " 'bmovie',\n",
       " 'body',\n",
       " 'books',\n",
       " 'boys',\n",
       " 'breath',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'brutal',\n",
       " 'camera',\n",
       " 'captivating',\n",
       " 'captures',\n",
       " 'center',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'changes',\n",
       " 'chemistry',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'chilling',\n",
       " 'cinema',\n",
       " 'cinematography',\n",
       " 'class',\n",
       " 'clearly',\n",
       " 'cold',\n",
       " 'color',\n",
       " 'commercial',\n",
       " 'commitment',\n",
       " 'complex',\n",
       " 'concerned',\n",
       " 'consistently',\n",
       " 'contemporary',\n",
       " 'content',\n",
       " 'cool',\n",
       " 'core',\n",
       " 'country',\n",
       " 'crafted',\n",
       " 'created',\n",
       " 'creative',\n",
       " 'credits',\n",
       " 'cultural',\n",
       " 'culture',\n",
       " 'dance',\n",
       " 'debut',\n",
       " 'decades',\n",
       " 'definitely',\n",
       " 'depth',\n",
       " 'despair',\n",
       " 'detail',\n",
       " 'determination',\n",
       " 'devastating',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'directors',\n",
       " 'disney',\n",
       " 'disturbing',\n",
       " 'documentary',\n",
       " 'dramedy',\n",
       " 'dreams',\n",
       " 'drive',\n",
       " 'drug',\n",
       " 'early',\n",
       " 'easily',\n",
       " 'effective',\n",
       " 'effectively',\n",
       " 'elements',\n",
       " 'emotion',\n",
       " 'endearing',\n",
       " 'energy',\n",
       " 'english',\n",
       " 'engrossing',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'entertain',\n",
       " 'entertaining',\n",
       " 'entertainment',\n",
       " 'entirely',\n",
       " 'epic',\n",
       " 'everything',\n",
       " 'exactly',\n",
       " 'excellent',\n",
       " 'exceptional',\n",
       " 'exists',\n",
       " 'expected',\n",
       " 'experience',\n",
       " 'expertly',\n",
       " 'extraordinary',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'fall',\n",
       " 'fan',\n",
       " 'fantastic',\n",
       " 'fantasy',\n",
       " 'farce',\n",
       " 'fare',\n",
       " 'fascinating',\n",
       " 'fear',\n",
       " 'female',\n",
       " 'fiction',\n",
       " 'fight',\n",
       " 'filmmaker',\n",
       " 'filmmaking',\n",
       " 'fit',\n",
       " 'flair',\n",
       " 'flawed',\n",
       " 'flaws',\n",
       " 'flick',\n",
       " 'forced',\n",
       " 'foreign',\n",
       " 'form',\n",
       " 'four',\n",
       " 'friends',\n",
       " 'frightening',\n",
       " 'fully',\n",
       " 'gem',\n",
       " 'general',\n",
       " 'generation',\n",
       " 'genuine',\n",
       " 'genuinely',\n",
       " 'ghosts',\n",
       " 'girl',\n",
       " 'glorious',\n",
       " 'greatest',\n",
       " 'grim',\n",
       " 'gripping',\n",
       " 'guy',\n",
       " 'happy',\n",
       " 'heartbreaking',\n",
       " 'heat',\n",
       " 'heavy',\n",
       " 'hell',\n",
       " 'helped',\n",
       " 'hero',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highly',\n",
       " 'hilarious',\n",
       " 'hits',\n",
       " 'hold',\n",
       " 'hours',\n",
       " 'huge',\n",
       " 'im',\n",
       " 'images',\n",
       " 'imaginative',\n",
       " 'impossible',\n",
       " 'infectious',\n",
       " 'inside',\n",
       " 'inspiring',\n",
       " 'intelligent',\n",
       " 'intense',\n",
       " 'interest',\n",
       " 'intimate',\n",
       " 'inventive',\n",
       " 'issue',\n",
       " 'issues',\n",
       " 'james',\n",
       " 'job',\n",
       " 'joy',\n",
       " 'justice',\n",
       " 'keeps',\n",
       " 'key',\n",
       " 'killer',\n",
       " 'knowing',\n",
       " 'knows',\n",
       " 'la',\n",
       " 'landscape',\n",
       " 'last',\n",
       " 'leading',\n",
       " 'leaving',\n",
       " 'lee',\n",
       " 'legacy',\n",
       " 'light',\n",
       " 'likable',\n",
       " 'limited',\n",
       " 'list',\n",
       " 'looking',\n",
       " 'loss',\n",
       " 'lovely',\n",
       " 'magic',\n",
       " 'main',\n",
       " 'major',\n",
       " 'manages',\n",
       " 'martin',\n",
       " 'master',\n",
       " 'maybe',\n",
       " 'merely',\n",
       " 'message',\n",
       " 'minute',\n",
       " 'mix',\n",
       " 'modern',\n",
       " 'monster',\n",
       " 'mood',\n",
       " 'moon',\n",
       " 'moral',\n",
       " 'mother',\n",
       " 'move',\n",
       " 'multiple',\n",
       " 'murder',\n",
       " 'musical',\n",
       " 'nebraska',\n",
       " 'necessarily',\n",
       " 'netflix',\n",
       " 'nevertheless',\n",
       " 'noir',\n",
       " 'nostalgia',\n",
       " 'novel',\n",
       " 'o',\n",
       " 'occasionally',\n",
       " 'older',\n",
       " 'onto',\n",
       " 'order',\n",
       " 'oscar',\n",
       " 'others',\n",
       " 'outcome',\n",
       " 'paced',\n",
       " 'pacing',\n",
       " 'packed',\n",
       " 'parents',\n",
       " 'past',\n",
       " 'paul',\n",
       " 'perfectly',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'perspective',\n",
       " 'piece',\n",
       " 'pieces',\n",
       " 'play',\n",
       " 'played',\n",
       " 'playful',\n",
       " 'playing',\n",
       " 'pleasure',\n",
       " 'poignant',\n",
       " 'politics',\n",
       " 'pop',\n",
       " 'popular',\n",
       " 'portrait',\n",
       " 'power',\n",
       " 'powerful',\n",
       " 'present',\n",
       " 'pretty',\n",
       " 'process',\n",
       " 'proves',\n",
       " 'provides',\n",
       " 'provocative',\n",
       " 'public',\n",
       " 'pure',\n",
       " 'puts',\n",
       " 'quality',\n",
       " 'questionable',\n",
       " 'questions',\n",
       " 'quiet',\n",
       " 'quietly',\n",
       " 'quirky',\n",
       " 'rare',\n",
       " 'raw',\n",
       " 'reach',\n",
       " 'read',\n",
       " 'realism',\n",
       " 'recent',\n",
       " 'redemption',\n",
       " 'relationship',\n",
       " 'relevant',\n",
       " 'remarkable',\n",
       " 'remarkably',\n",
       " 'reminder',\n",
       " 'result',\n",
       " 'return',\n",
       " 'rich',\n",
       " 'ride',\n",
       " 'riveting',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'said',\n",
       " 'satire',\n",
       " 'satisfy',\n",
       " 'satisfying',\n",
       " 'scene',\n",
       " 'sciencefiction',\n",
       " 'score',\n",
       " 'screenplay',\n",
       " 'screenwriter',\n",
       " 'season',\n",
       " 'seeing',\n",
       " 'seemed',\n",
       " 'sensitive',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'sets',\n",
       " 'setting',\n",
       " 'several',\n",
       " 'sexual',\n",
       " 'shared',\n",
       " 'shot',\n",
       " 'shows',\n",
       " 'side',\n",
       " 'simple',\n",
       " 'since',\n",
       " 'sinister',\n",
       " 'sit',\n",
       " 'skill',\n",
       " 'skin',\n",
       " 'slightly',\n",
       " 'slow',\n",
       " 'small',\n",
       " 'social',\n",
       " 'society',\n",
       " 'somehow',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'source',\n",
       " 'space',\n",
       " 'sports',\n",
       " 'stands',\n",
       " 'stellar',\n",
       " 'step',\n",
       " 'stories',\n",
       " 'strength',\n",
       " 'study',\n",
       " 'stuff',\n",
       " 'stunning',\n",
       " 'style',\n",
       " 'summer',\n",
       " 'superb',\n",
       " 'superhero',\n",
       " 'surface',\n",
       " 'surprise',\n",
       " 'surprises',\n",
       " 'surprisingly',\n",
       " 'suspense',\n",
       " 'sweet',\n",
       " 'taking',\n",
       " 'taut',\n",
       " 'team',\n",
       " 'technical',\n",
       " 'teen',\n",
       " 'tender',\n",
       " 'tenderness',\n",
       " 'terms',\n",
       " 'terrific',\n",
       " 'terror',\n",
       " 'thanks',\n",
       " 'themes',\n",
       " 'theyre',\n",
       " 'thoroughly',\n",
       " 'thought',\n",
       " 'thoughtful',\n",
       " 'thrills',\n",
       " 'throughout',\n",
       " 'throwback',\n",
       " 'tight',\n",
       " 'title',\n",
       " 'today',\n",
       " 'told',\n",
       " 'top',\n",
       " 'total',\n",
       " 'touching',\n",
       " 'traditional',\n",
       " 'tragedy',\n",
       " 'transcendent',\n",
       " 'trip',\n",
       " 'triumph',\n",
       " 'truly',\n",
       " 'twist',\n",
       " 'twists',\n",
       " 'type',\n",
       " 'understanding',\n",
       " 'unique',\n",
       " 'universe',\n",
       " 'used',\n",
       " 'uses',\n",
       " 'usually',\n",
       " 'valuable',\n",
       " 'value',\n",
       " 'victims',\n",
       " 'viewing',\n",
       " 'violent',\n",
       " 'vision',\n",
       " 'visual',\n",
       " 'visuals',\n",
       " 'war',\n",
       " 'warm',\n",
       " 'watchable',\n",
       " 'weekend',\n",
       " 'welcome',\n",
       " 'wellacted',\n",
       " 'western',\n",
       " 'whats',\n",
       " 'white',\n",
       " 'whose',\n",
       " 'wild',\n",
       " 'win',\n",
       " 'woman',\n",
       " 'wonderful',\n",
       " 'wonderfully',\n",
       " 'worthy',\n",
       " 'wouldnt',\n",
       " 'writerdirector',\n",
       " 'youll']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only positive words \n",
    "top_fresh_words_exclusive_list = top_fresh_words_exclusive['Occurence good review'].index.tolist()\n",
    "top_fresh_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolutely',\n",
       " 'addition',\n",
       " 'adventure',\n",
       " 'affectionate',\n",
       " 'amazing',\n",
       " 'ambition',\n",
       " 'art',\n",
       " 'artist',\n",
       " 'arts',\n",
       " 'atmosphere',\n",
       " 'attractive',\n",
       " 'awards',\n",
       " 'balance',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'bond',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'captivating',\n",
       " 'captures',\n",
       " 'celebration',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'christmas',\n",
       " 'classic',\n",
       " 'clever',\n",
       " 'committed',\n",
       " 'consistently',\n",
       " 'contemporary',\n",
       " 'conventional',\n",
       " 'convincingly',\n",
       " 'creates',\n",
       " 'creating',\n",
       " 'crowdpleaser',\n",
       " 'cult',\n",
       " 'decade',\n",
       " 'decades',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'deeply',\n",
       " 'definitely',\n",
       " 'delightful',\n",
       " 'delightfully',\n",
       " 'depth',\n",
       " 'deserves',\n",
       " 'design',\n",
       " 'details',\n",
       " 'different',\n",
       " 'diverse',\n",
       " 'dramatic',\n",
       " 'early',\n",
       " 'elegant',\n",
       " 'emotionally',\n",
       " 'engaging',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'equal',\n",
       " 'especially',\n",
       " 'exploration',\n",
       " 'extraordinary',\n",
       " 'extremely',\n",
       " 'familiar',\n",
       " 'famous',\n",
       " 'fan',\n",
       " 'fantastic',\n",
       " 'fantasy',\n",
       " 'fascinating',\n",
       " 'felt',\n",
       " 'filled',\n",
       " 'finest',\n",
       " 'frank',\n",
       " 'fresh',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'gags',\n",
       " 'gorgeous',\n",
       " 'grand',\n",
       " 'happy',\n",
       " 'heart',\n",
       " 'hilarious',\n",
       " 'honest',\n",
       " 'hope',\n",
       " 'huge',\n",
       " 'impact',\n",
       " 'insightful',\n",
       " 'inspiring',\n",
       " 'intelligent',\n",
       " 'intense',\n",
       " 'intrigue',\n",
       " 'joy',\n",
       " 'laugh',\n",
       " 'loved',\n",
       " 'mature',\n",
       " 'mind',\n",
       " 'mystery',\n",
       " 'nostalgia',\n",
       " 'novel',\n",
       " 'opening',\n",
       " 'passion',\n",
       " 'perfect',\n",
       " 'performers',\n",
       " 'personal',\n",
       " 'pleasure',\n",
       " 'poignant',\n",
       " 'power',\n",
       " 'powerful',\n",
       " 'precisely',\n",
       " 'profound',\n",
       " 'project',\n",
       " 'proves',\n",
       " 'provide',\n",
       " 'provocative',\n",
       " 'psychological',\n",
       " 'quality',\n",
       " 'remarkable',\n",
       " 'reveals',\n",
       " 'rich',\n",
       " 'riveting',\n",
       " 'satisfying',\n",
       " 'sharp',\n",
       " 'simple',\n",
       " 'smart',\n",
       " 'smile',\n",
       " 'stunning',\n",
       " 'succeeds',\n",
       " 'supernatural',\n",
       " 'surprise',\n",
       " 'surprises',\n",
       " 'surprising',\n",
       " 'surprisingly',\n",
       " 'sweet',\n",
       " 'talents',\n",
       " 'thoughtful',\n",
       " 'thrills',\n",
       " 'touch',\n",
       " 'touching',\n",
       " 'tragedy',\n",
       " 'tragic',\n",
       " 'tribute',\n",
       " 'unique',\n",
       " 'universal',\n",
       " 'warm',\n",
       " 'watchable',\n",
       " 'welcome',\n",
       " 'wit',\n",
       " 'witty',\n",
       " 'wonderful',\n",
       " 'worthwhile',\n",
       " 'worthy']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_fresh_words_exclusive = ['absolutely',\n",
    " 'addition',\n",
    " 'adventure',\n",
    " 'affectionate',\n",
    " 'amazing',\n",
    " 'ambition',\n",
    " 'art',\n",
    " 'artist',\n",
    " 'arts',\n",
    " 'atmosphere',\n",
    " 'attractive',\n",
    " 'awards',\n",
    " 'balance',\n",
    " 'beautiful',\n",
    " 'beautifully',\n",
    " 'beauty',\n",
    " 'bond',\n",
    " 'bright',\n",
    " 'brilliant',\n",
    " 'captivating',\n",
    " 'captures',\n",
    " 'celebration',\n",
    " 'charm',\n",
    " 'charming',\n",
    " 'christmas',\n",
    " 'classic',\n",
    " 'clever',\n",
    " 'committed',\n",
    " 'consistently',\n",
    " 'contemporary',\n",
    " 'conventional',\n",
    " 'convincingly',\n",
    " 'creates',\n",
    " 'creating',\n",
    " 'crowdpleaser',\n",
    " 'cult',\n",
    " 'decade',\n",
    " 'decades',\n",
    " 'deep',\n",
    " 'deeper',\n",
    " 'deeply',\n",
    " 'definitely',\n",
    " 'delightful',\n",
    " 'delightfully',\n",
    " 'depth',\n",
    " 'deserves',\n",
    " 'design',\n",
    " 'details',\n",
    " 'different',\n",
    " 'diverse',\n",
    " 'dramatic',\n",
    " 'early',\n",
    " 'elegant',\n",
    " 'emotionally',\n",
    " 'engaging',\n",
    " 'enjoyable',\n",
    " 'enjoyed',\n",
    " 'equal',\n",
    " 'especially',\n",
    " 'exploration',\n",
    " 'extraordinary',\n",
    " 'extremely',\n",
    " 'familiar',\n",
    " 'famous',\n",
    " 'fan',\n",
    " 'fantastic',\n",
    " 'fantasy',\n",
    " 'fascinating',\n",
    " 'felt',\n",
    " 'filled',\n",
    " 'finest',\n",
    " 'frank',\n",
    " 'fresh',\n",
    " 'friends',\n",
    " 'friendship',\n",
    " 'gags',\n",
    " 'gorgeous',\n",
    " 'grand',\n",
    " 'happy',\n",
    " 'heart',\n",
    " 'hilarious',\n",
    " 'honest',\n",
    " 'hope',\n",
    " 'huge',\n",
    " 'impact',\n",
    " 'insightful',\n",
    " 'inspiring',\n",
    " 'intelligent',\n",
    " 'intense',\n",
    " 'intrigue',\n",
    " 'joy',\n",
    " 'laugh',\n",
    " 'loved',\n",
    " 'mature',\n",
    " 'mind',\n",
    " 'mystery',\n",
    " 'nostalgia',\n",
    " 'novel',\n",
    " 'opening',\n",
    " 'passion',\n",
    " 'perfect',\n",
    " 'performers',\n",
    " 'personal',\n",
    " 'pleasure',\n",
    " 'poignant',\n",
    " 'power',\n",
    " 'powerful',\n",
    " 'precisely',\n",
    " 'profound',\n",
    " 'project',\n",
    " 'proves',\n",
    " 'provide',\n",
    " 'provocative',\n",
    " 'psychological',\n",
    " 'quality',\n",
    " 'remarkable',\n",
    " 'reveals',\n",
    " 'rich',\n",
    " 'riveting',\n",
    " 'satisfying',\n",
    " 'sharp',\n",
    " 'simple',\n",
    " 'smart',\n",
    " 'smile',\n",
    " 'stunning',\n",
    " 'succeeds',\n",
    " 'supernatural',\n",
    " 'surprise',\n",
    " 'surprises',\n",
    " 'surprising',\n",
    " 'surprisingly',\n",
    " 'sweet',\n",
    " 'talents',\n",
    " 'thoughtful',\n",
    " 'thrills',\n",
    " 'touch',\n",
    " 'touching',\n",
    " 'tragedy',\n",
    " 'tragic',\n",
    " 'tribute',\n",
    " 'unique',\n",
    " 'universal',\n",
    " 'warm',\n",
    " 'watchable',\n",
    " 'welcome',\n",
    " 'wit',\n",
    " 'witty',\n",
    " 'wonderful',\n",
    " 'worthwhile',\n",
    " 'worthy']\n",
    "\n",
    "top_fresh_words_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['across',\n",
       " 'already',\n",
       " 'amusing',\n",
       " 'anyone',\n",
       " 'awful',\n",
       " 'bag',\n",
       " 'banter',\n",
       " 'basically',\n",
       " 'battle',\n",
       " 'beyond',\n",
       " 'biggest',\n",
       " 'bland',\n",
       " 'boring',\n",
       " 'brain',\n",
       " 'british',\n",
       " 'capable',\n",
       " 'casting',\n",
       " 'cheap',\n",
       " 'child',\n",
       " 'chris',\n",
       " 'christopher',\n",
       " 'clever',\n",
       " 'completely',\n",
       " 'contrived',\n",
       " 'convincing',\n",
       " 'couldnt',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'dead',\n",
       " 'decent',\n",
       " 'deserve',\n",
       " 'deserves',\n",
       " 'disappointment',\n",
       " 'disaster',\n",
       " 'dog',\n",
       " 'edited',\n",
       " 'else',\n",
       " 'emotionally',\n",
       " 'essentially',\n",
       " 'example',\n",
       " 'except',\n",
       " 'expectations',\n",
       " 'failure',\n",
       " 'felt',\n",
       " 'finally',\n",
       " 'flat',\n",
       " 'forget',\n",
       " 'future',\n",
       " 'halfbaked',\n",
       " 'hannibal',\n",
       " 'help',\n",
       " 'historical',\n",
       " 'home',\n",
       " 'hot',\n",
       " 'humour',\n",
       " 'idea',\n",
       " 'imagination',\n",
       " 'impressive',\n",
       " 'intentions',\n",
       " 'interested',\n",
       " 'involved',\n",
       " 'jennifer',\n",
       " 'jokes',\n",
       " 'kill',\n",
       " 'king',\n",
       " 'lazy',\n",
       " 'lessons',\n",
       " 'lets',\n",
       " 'limp',\n",
       " 'lots',\n",
       " 'low',\n",
       " 'male',\n",
       " 'mark',\n",
       " 'means',\n",
       " 'meant',\n",
       " 'mediocre',\n",
       " 'mediocrity',\n",
       " 'middle',\n",
       " 'misguided',\n",
       " 'mistakes',\n",
       " 'modest',\n",
       " 'moment',\n",
       " 'momentum',\n",
       " 'money',\n",
       " 'moving',\n",
       " 'mr',\n",
       " 'name',\n",
       " 'necessary',\n",
       " 'neither',\n",
       " 'normal',\n",
       " 'nowhere',\n",
       " 'number',\n",
       " 'offensive',\n",
       " 'opportunity',\n",
       " 'painfully',\n",
       " 'particularly',\n",
       " 'peter',\n",
       " 'pointless',\n",
       " 'political',\n",
       " 'poorly',\n",
       " 'possible',\n",
       " 'possibly',\n",
       " 'potential',\n",
       " 'predictable',\n",
       " 'premise',\n",
       " 'problem',\n",
       " 'punch',\n",
       " 'que',\n",
       " 'quickly',\n",
       " 'realized',\n",
       " 'reasons',\n",
       " 'remains',\n",
       " 'remake',\n",
       " 'rest',\n",
       " 'sarah',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'scary',\n",
       " 'scifi',\n",
       " 'sea',\n",
       " 'sequel',\n",
       " 'serve',\n",
       " 'sex',\n",
       " 'share',\n",
       " 'silly',\n",
       " 'sitcom',\n",
       " 'situation',\n",
       " 'slapstick',\n",
       " 'slick',\n",
       " 'solid',\n",
       " 'someone',\n",
       " 'storytelling',\n",
       " 'stupid',\n",
       " 'subtlety',\n",
       " 'suffers',\n",
       " 'surprising',\n",
       " 'tedious',\n",
       " 'thin',\n",
       " 'thrilling',\n",
       " 'totally',\n",
       " 'tries',\n",
       " 'truth',\n",
       " 'tv',\n",
       " 'um',\n",
       " 'unfortunately',\n",
       " 'unfunny',\n",
       " 'uninspired',\n",
       " 'vice',\n",
       " 'walking',\n",
       " 'wants',\n",
       " 'waste',\n",
       " 'wish',\n",
       " 'wit',\n",
       " 'wonder',\n",
       " 'worst',\n",
       " 'writer',\n",
       " 'writing']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only negative words \n",
    "top_rotten_words_exclusive_list = top_rotten_words_exclusive['Occurence bad review'].index.tolist()\n",
    "top_rotten_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attempt',\n",
       " 'awkward',\n",
       " 'barely',\n",
       " 'basically',\n",
       " 'bizarre',\n",
       " 'bland',\n",
       " 'boring',\n",
       " 'clumsy',\n",
       " 'comedic',\n",
       " 'disappointing',\n",
       " 'disappointingly',\n",
       " 'disappointment',\n",
       " 'disaster',\n",
       " 'dull',\n",
       " 'effort',\n",
       " 'failed',\n",
       " 'fails',\n",
       " 'generic',\n",
       " 'irritating',\n",
       " 'lacking',\n",
       " 'manic',\n",
       " 'missing',\n",
       " 'nobody',\n",
       " 'noir',\n",
       " 'none',\n",
       " 'painfully',\n",
       " 'pointless',\n",
       " 'poorly',\n",
       " 'problem',\n",
       " 'shallow',\n",
       " 'shame',\n",
       " 'sloppy',\n",
       " 'slow',\n",
       " 'suffers',\n",
       " 'superficial',\n",
       " 'try',\n",
       " 'unfortunately',\n",
       " 'unfunny',\n",
       " 'worst']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_rotten_words_exclusive = [\n",
    " 'attempt',\n",
    " 'awkward',\n",
    " 'barely',\n",
    " 'basically',\n",
    " 'bizarre',\n",
    " 'bland',\n",
    " 'boring',\n",
    " 'clumsy',\n",
    " 'comedic',\n",
    " 'disappointing',\n",
    " 'disappointingly',\n",
    " 'disappointment',\n",
    " 'disaster',\n",
    " 'dull',\n",
    " 'effort',\n",
    " 'failed',\n",
    " 'fails',\n",
    " 'generic',\n",
    " 'irritating',\n",
    " 'lacking',\n",
    " 'manic',\n",
    " 'missing',\n",
    " 'nobody',\n",
    " 'noir',\n",
    " 'none',\n",
    " 'painfully',\n",
    " 'pointless',\n",
    " 'poorly',\n",
    " 'problem',\n",
    " 'shallow',\n",
    " 'shame',\n",
    " 'sloppy',\n",
    " 'slow',\n",
    " 'suffers',\n",
    " 'superficial',\n",
    " 'try',\n",
    " 'unfortunately',\n",
    " 'unfunny',\n",
    " 'worst']\n",
    "top_rotten_words_exclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A. Good / bad exclusive words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_split = pd.read_csv('/project/development_split.csv')\n",
    "ABSTAIN = -1\n",
    "NOTFRESH = 0\n",
    "FRESH = 1\n",
    "\n",
    "@labeling_function()\n",
    "def fresh(x):\n",
    "    for word in top_fresh_words_exclusive:\n",
    "        if word in str(x).lower():\n",
    "            return FRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def rotten(x):\n",
    "    for word in top_rotten_words_exclusive:\n",
    "        if word in str(x).lower():\n",
    "            return NOTFRESH\n",
    "    return ABSTAIN\n",
    "#return NOTFRESH if \"best\" in x.str.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lfs = [fresh]\n",
    "\n",
    "# applier = PandasLFApplier(lfs=lfs)\n",
    "# sample_L = applier.apply(development_split)\n",
    "\n",
    "\n",
    "from snorkel.labeling.apply.spark import SparkLFApplier\n",
    "\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SQLContext \n",
    "import pandas as pd \n",
    "sqlc=SQLContext(sc) \n",
    "df=pd.read_csv('/project/development_split.csv') \n",
    "development_split=sqlc.createDataFrame(df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [fresh]\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresh coverage:100.0%\n"
     ]
    }
   ],
   "source": [
    "coverage_fresh = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"fresh coverage:{:.1%}\".format(coverage_fresh[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [rotten]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten coverage:15.1%\n"
     ]
    }
   ],
   "source": [
    "coverage_rotten = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"rotten coverage:{:.1%}\".format(coverage_rotten[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Word 'too' occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "too                     29"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "too                    29"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def keyword_too(x):\n",
    "    return NOTFRESH if 'too' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [keyword_too]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword too coverage:3.9%\n"
     ]
    }
   ],
   "source": [
    "coverage_keyword_too = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword too coverage:{:.1%}\".format(coverage_keyword_too[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Word 'far' occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "far                     18"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "far                    11"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def keyword_far(x):\n",
    "    return FRESH if 'far' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [keyword_far]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword far coverage:3.0%\n"
     ]
    }
   ],
   "source": [
    "coverage_keyword_far = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword far coverage:{:.1%}\".format(coverage_keyword_far[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. \"n't\" words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "\n",
    "def t(x):\n",
    "    if re.search(\"'t\",x.review.lower()):\n",
    "        return NOTFRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [t]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word occurancy that with punctuation with it\n",
    "\n",
    "# Word occurrences dataframe for fresh reviews\n",
    "development_split_fresh_1 = split_fresh.str.split(expand=True).stack().value_counts()\n",
    "development_split_fresh_df = pd.DataFrame(development_split_fresh_1).reset_index()\n",
    "\n",
    "# Words occurrences dataframe for rotten reviews\n",
    "development_split_rotten_1 = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "development_split_rotten_df = pd.DataFrame(development_split_rotten_1).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Occurenes of good & bad words from external list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "We also want to look at an imported list of postive and negative words and see whether we can base the labelling functions on them.\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing good and bad words & preparing for labelling function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POSITIVE WORDS \n",
    "#positive words from --> DON't DELETE! NEED TO CITE PROPERLY http://ptrckprry.com/course/ssd/data/positive-words.txt\n",
    "positive_word = pd.read_csv('/project/positive_words.csv')\n",
    "\n",
    "#sample 500 words \n",
    "positive_word = positive_word.sample(500)\n",
    "\n",
    "#convert it into a list \n",
    "positive_word= positive_word['a+'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "#NEGATIVE WORDS \n",
    "#negative words from --> HONG?? \n",
    "negative_word = pd.read_csv('/project/negative_words.csv')\n",
    "\n",
    "#sample 500 words \n",
    "negative_word = negative_word.sample(500)\n",
    "\n",
    "#convert it into a list \n",
    "negative_word= negative_word['2-faces'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def negative(x): \n",
    "    for word in negative_word:\n",
    "        if word in str(x).lower():\n",
    "            return NOTFRESH \n",
    "    return ABSTAIN \n",
    "\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def positive(x):\n",
    "    for word in positive_word:\n",
    "        if word in str(x).lower():\n",
    "            return FRESH \n",
    "    return ABSTAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [negative]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative words coverage:20.2%\n"
     ]
    }
   ],
   "source": [
    "coverage_negative = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"negative words coverage:{:.1%}\".format(coverage_negative[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [positive]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive words coverage:100.0%\n"
     ]
    }
   ],
   "source": [
    "coverage_positive = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"positive words coverage:{:.1%}\".format(coverage_positive[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Punctuation occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn review column into Series\n",
    "development_split_fresh_series = pd.Series(development_split_fresh.Review)\n",
    "development_split_rotten_series = pd.Series(development_split_rotten.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive reviews\n",
    "# Split reviews into word\n",
    "fresh_split = pd.Series(development_split_fresh_series.str.split(expand=True).stack())\n",
    "fresh_words = [i for i in fresh_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in fresh_words]\n",
    "fresh_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative reviews\n",
    "# Split reviews into word\n",
    "rotten_split = pd.Series(development_split_rotten_series.str.split(expand=True).stack())\n",
    "rotten_words = [i for i in rotten_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in rotten_words]\n",
    "rotten_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into a flattened list\n",
    "fresh_flattened_list = [y for x in fresh_split_words for y in x]\n",
    "rotten_flattened_list = [y for x in rotten_split_words for y in x]\n",
    "\n",
    "# Count the occurancy of each character\n",
    "# Positive reviews\n",
    "fresh_split_characters = pd.Series(fresh_flattened_list).value_counts()\n",
    "fresh_split_characters = pd.DataFrame(fresh_split_characters).reset_index()\n",
    "\n",
    "# Negative reviews\n",
    "rotten_split_characters = pd.Series(rotten_flattened_list).value_counts()\n",
    "rotten_split_characters = pd.DataFrame(rotten_split_characters).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Question mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>?</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "64     ?  17"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>?</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "53     ?  26"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Critters Attack! might entertain the biggest B-movie horror fans, but with a script this vapid, what's the point?\", \"Smug? Damn, this is a self-satisfied, arrogant excuse for a film, in which the red-herringness is piled on with outrageous aplomb till there can be no doubt that Twohy is daring you to guess what's up and hoping you're not up to it, or not caring if you a\", 'Preposterous? Yes. Ridiculous? That, too.']\n"
     ]
    }
   ],
   "source": [
    "list_with_question_mark = []\n",
    "for review in development_split_rotten.Review:\n",
    "    if '?' in review:\n",
    "        list_with_question_mark.append(review)\n",
    "        \n",
    "print (list_with_question_mark[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def question_mark(x):\n",
    "    return NOTFRESH if '?' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lfs = [question_mark]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question mark coverage:1.8%\n"
     ]
    }
   ],
   "source": [
    "coverage_question_mark = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"question mark coverage:{:.1%}\".format(coverage_question_mark[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###B. Exclaimation mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>!</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  0\n",
       "69     !  9"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>!</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  0\n",
       "68     !  6"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def exclamation_mark(x):\n",
    "    return NOTFRESH if '!' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lfs = [exclamation_mark]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclaimation mark coverage:0.7%\n"
     ]
    }
   ],
   "source": [
    "coverage_exclamation_mark = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"exclaimation mark coverage:{:.1%}\".format(coverage_exclamation_mark[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(str(x))\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return FRESH if x.polarity > 0.8 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_subjectivity(x):\n",
    "    return FRESH if x.subjectivity >= 0.5 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 28.0 failed 1 times, most recent failure: Lost task 1.0 in stage 28.0 (TID 113, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/spark.py\", line 36, in map_fn\n    return apply_lfs_to_data_point(*args, lfs=self._lfs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/core.py\", line 83, in apply_lfs_to_data_point\n    y = lf(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 84, in __call__\n    x = self._preprocess_data_point(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 62, in _preprocess_data_point\n    x = preprocessor(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 152, in __call__\n    x_mapped = self._generate_mapped_data_point(x_mapped)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 304, in _generate_mapped_data_point\n    return self._f(x)\n  File \"<ipython-input-160-5106c698ef72>\", line 4, in textblob_sentiment\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1536, in __setattr__\n    raise Exception(\"Row is read-only\")\nException: Row is read-only\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor63.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/spark.py\", line 36, in map_fn\n    return apply_lfs_to_data_point(*args, lfs=self._lfs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/core.py\", line 83, in apply_lfs_to_data_point\n    y = lf(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 84, in __call__\n    x = self._preprocess_data_point(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 62, in _preprocess_data_point\n    x = preprocessor(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 152, in __call__\n    x_mapped = self._generate_mapped_data_point(x_mapped)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 304, in _generate_mapped_data_point\n    return self._f(x)\n  File \"<ipython-input-160-5106c698ef72>\", line 4, in textblob_sentiment\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1536, in __setattr__\n    raise Exception(\"Row is read-only\")\nException: Row is read-only\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-00d6405862f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mapplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkLFApplier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msample_L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevelopment_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/spark.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, data_points)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mapply_lfs_to_data_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzipWithIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_from_row_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \"\"\"\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 28.0 failed 1 times, most recent failure: Lost task 1.0 in stage 28.0 (TID 113, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/spark.py\", line 36, in map_fn\n    return apply_lfs_to_data_point(*args, lfs=self._lfs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/core.py\", line 83, in apply_lfs_to_data_point\n    y = lf(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 84, in __call__\n    x = self._preprocess_data_point(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 62, in _preprocess_data_point\n    x = preprocessor(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 152, in __call__\n    x_mapped = self._generate_mapped_data_point(x_mapped)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 304, in _generate_mapped_data_point\n    return self._f(x)\n  File \"<ipython-input-160-5106c698ef72>\", line 4, in textblob_sentiment\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1536, in __setattr__\n    raise Exception(\"Row is read-only\")\nException: Row is read-only\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor63.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/spark.py\", line 36, in map_fn\n    return apply_lfs_to_data_point(*args, lfs=self._lfs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/apply/core.py\", line 83, in apply_lfs_to_data_point\n    y = lf(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 84, in __call__\n    x = self._preprocess_data_point(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/lf/core.py\", line 62, in _preprocess_data_point\n    x = preprocessor(x)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 152, in __call__\n    x_mapped = self._generate_mapped_data_point(x_mapped)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/map/core.py\", line 304, in _generate_mapped_data_point\n    return self._f(x)\n  File \"<ipython-input-160-5106c698ef72>\", line 4, in textblob_sentiment\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1536, in __setattr__\n    raise Exception(\"Row is read-only\")\nException: Row is read-only\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "lfs = [textblob_polarity, textblob_subjectivity]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LFAnalysis(L_sample, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
